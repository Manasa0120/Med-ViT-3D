{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eAI9r5x9Mjhw"
   },
   "source": [
    "Med-Vit-3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qe8mtlWoU9yI"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "## reduce GPU\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UFtychH7MlvN",
    "outputId": "6e69f9cb-cc2c-4a7c-8c21-e9313c47384d"
   },
   "outputs": [],
   "source": [
    "!pip install medmnist==3.0.1 \\\n",
    "    torchattacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uCXwum690QjK",
    "outputId": "9a2bf32f-2456-43a2-c008-71c27f69fe1b"
   },
   "outputs": [],
   "source": [
    "pip install torchio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_aD3CYXqM06G"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "\n",
    "import torchvision.utils\n",
    "from torchvision import models\n",
    "import torchvision.datasets as dsets\n",
    "from torchsummary import summary\n",
    "\n",
    "from tqdm import tqdm\n",
    "import medmnist\n",
    "from medmnist import INFO, Evaluator\n",
    "\n",
    "import torchattacks\n",
    "from torchattacks import PGD, FGSM\n",
    "from torch.utils.data import Subset, random_split, DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "from torchvision.transforms.transforms import Resize\n",
    "\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import torchio as tio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2CsEux3TNGoi",
    "outputId": "4f5647ba-fd3a-41aa-8c73-1b3c23bc8165"
   },
   "outputs": [],
   "source": [
    "print(\"PyTorch\", torch.__version__)\n",
    "print(\"Torchvision\", torchvision.__version__)\n",
    "print(\"Torchattacks\", torchattacks.__version__)\n",
    "print(\"Numpy\", np.__version__)\n",
    "print(\"Medmnist\", medmnist.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nV9CLSzIewnI"
   },
   "outputs": [],
   "source": [
    "### lower down sample: 1000 sample\n",
    "\n",
    "import torchio as tio   # for 3D augmentations\n",
    "\n",
    "def med3dfulldata(DataClass, BATCH_SIZE=15, downsample=1000):\n",
    "    # Safe base transform (keeps shape as 1Ã—DÃ—HÃ—W)\n",
    "    def base_transform(x):\n",
    "        if isinstance(x, np.ndarray):\n",
    "            x = torch.from_numpy(x)\n",
    "        x = x.float()\n",
    "        if x.ndim == 3:   # (D,H,W) â†’ add channel\n",
    "            x = x.unsqueeze(0)\n",
    "        return x  # (1,D,H,W)\n",
    "\n",
    "    # TorchIO augmentations for training\n",
    "    train_transform = tio.Compose([\n",
    "        tio.RandomFlip(axes=(0, 1, 2), flip_probability=0.5),\n",
    "        tio.RandomAffine(scales=(0.9, 1.1), degrees=(0, 15), translation=(0, 5)),\n",
    "        tio.RandomNoise(mean=0, std=0.05),\n",
    "        tio.RandomBiasField(coefficients=0.3),\n",
    "        tio.Lambda(base_transform)  # final tensor conversion\n",
    "    ])\n",
    "\n",
    "    # Only tensor conversion for val/test\n",
    "    test_transform = tio.Lambda(base_transform)\n",
    "\n",
    "    # Load datasets\n",
    "    train_dataset = DataClass(split='train', transform=train_transform, download=True)\n",
    "    val_dataset   = DataClass(split='val', transform=test_transform, download=True)\n",
    "    test_dataset  = DataClass(split='test', transform=test_transform, download=True)\n",
    "\n",
    "    # Optional downsampling\n",
    "    if downsample and downsample < len(train_dataset):\n",
    "        indices = random.sample(range(len(train_dataset)), downsample)\n",
    "        train_dataset = Subset(train_dataset, indices)\n",
    "\n",
    "    # Dataloaders\n",
    "    train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
    "    test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
    "    return train_loader, train_loader_at_eval, test_loader\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# --- Helper to create a single batch with all classes ---\n",
    "def get_one_batch_with_all_classes(dataset, num_classes, batch_size=32):\n",
    "    loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False)\n",
    "    all_inputs, all_targets = [], []\n",
    "    seen_classes = set()\n",
    "\n",
    "    for x, y in loader:\n",
    "        all_inputs.append(x)\n",
    "        all_targets.append(y)\n",
    "        seen_classes.update(y.squeeze().tolist())\n",
    "\n",
    "        if len(seen_classes) == num_classes:\n",
    "            all_inputs = torch.cat(all_inputs, dim=0)\n",
    "            all_targets = torch.cat(all_targets, dim=0)\n",
    "            return [(all_inputs, all_targets)]\n",
    "    raise ValueError(f\"Could not find all {num_classes} classes in the dataset.\")\n",
    "'''\n",
    "def data_input_loading(data_flag, BATCH_SIZE=15, lr=0.0005, NUM_EPOCHS=5, total_samples=1500, med3d = False):\n",
    "    download = True\n",
    "    info = INFO[data_flag]\n",
    "    task = info['task']\n",
    "    n_channels = info['n_channels']\n",
    "    n_classes = len(info['label'])\n",
    "    DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "    if med3d:\n",
    "      train_loader, train_loader_at_eval, test_loader = med3dfulldata(DataClass)\n",
    "    else:\n",
    "      # preprocessing\n",
    "      train_transform = transforms.Compose([\n",
    "          transforms.Resize(224),\n",
    "          transforms.Lambda(lambda image: image.convert('RGB')),\n",
    "          torchvision.transforms.AugMix(),\n",
    "          transforms.ToTensor(),\n",
    "          transforms.Normalize(mean=[.5], std=[.5])\n",
    "      ])\n",
    "      test_transform = transforms.Compose([\n",
    "          transforms.Resize(224),\n",
    "          transforms.Lambda(lambda image: image.convert('RGB')),\n",
    "          transforms.ToTensor(),\n",
    "          transforms.Normalize(mean=[.5], std=[.5])\n",
    "      ])\n",
    "\n",
    "      # Load full dataset first (train + test combined)\n",
    "      full_dataset = DataClass(split='train', transform=train_transform, download=download)\n",
    "      test_dataset_full = DataClass(split='test', transform=test_transform, download=download)\n",
    "      combined_dataset = torch.utils.data.ConcatDataset([full_dataset, test_dataset_full])\n",
    "\n",
    "      # Randomly select only total_samples items\n",
    "      if total_samples > len(combined_dataset):\n",
    "        total_samples = len(combined_dataset)\n",
    "      indices = random.sample(range(len(combined_dataset)), total_samples)\n",
    "      small_dataset = Subset(combined_dataset, indices)\n",
    "\n",
    "      # Split into train / val / test (e.g., 70/15/15 split)\n",
    "      train_size = int(0.7 * total_samples)\n",
    "      val_size = int(0.15 * total_samples)\n",
    "      test_size = total_samples - train_size - val_size\n",
    "      train_dataset, val_dataset, test_dataset = random_split(small_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "      # Dataloaders\n",
    "      train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "      train_loader_at_eval = get_one_batch_with_all_classes(train_dataset, n_classes, batch_size=2*BATCH_SIZE)\n",
    "      test_loader = get_one_batch_with_all_classes(test_dataset, n_classes, batch_size=2*BATCH_SIZE)\n",
    "\n",
    "    return data_flag, NUM_EPOCHS, BATCH_SIZE, lr, task, train_loader, train_loader_at_eval, test_loader, n_classes\n",
    "  '''\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset, random_split, WeightedRandomSampler\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import medmnist\n",
    "\n",
    "# Balanced DataLoader helper\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "def make_hybrid_loader(dataset, batch_size, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Hybrid sampler:\n",
    "    - alpha = 1.0 â†’ fully balanced (1/count)\n",
    "    - alpha = 0.0 â†’ natural distribution\n",
    "    - e.g., alpha=0.5 â†’ softer balance (1/sqrt(count))\n",
    "    \"\"\"\n",
    "    labels = [dataset[i][1] for i in range(len(dataset))]\n",
    "    class_counts = np.bincount(labels)\n",
    "\n",
    "    # hybrid weighting: count^(-alpha)\n",
    "    class_weights = 1. / (class_counts ** alpha)\n",
    "    sample_weights = [class_weights[label] for label in labels]\n",
    "\n",
    "    sampler = WeightedRandomSampler(\n",
    "        weights=sample_weights,\n",
    "        num_samples=len(sample_weights),\n",
    "        replacement=True\n",
    "    )\n",
    "    return DataLoader(dataset, batch_size=batch_size, sampler=sampler)\n",
    "\n",
    "\n",
    "# Full pipeline with augmentation + balancing\n",
    "def data_input_loading(data_flag, BATCH_SIZE=15, lr=0.0005, NUM_EPOCHS=5, total_samples=1500, med3d=False):\n",
    "    download = True\n",
    "    info = INFO[data_flag]\n",
    "    task = info['task']\n",
    "    n_channels = info['n_channels']\n",
    "    n_classes = len(info['label'])\n",
    "    DataClass = getattr(medmnist, info['python_class'])\n",
    "\n",
    "    if med3d:\n",
    "        # keep med3d as is (need TorchIO/MONAI for 3D aug)\n",
    "        train_loader, train_loader_at_eval, test_loader = med3dfulldata(DataClass)\n",
    "\n",
    "    else:\n",
    "        # Augmentation for training\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.Lambda(lambda image: image.convert('RGB')),\n",
    "            transforms.RandomHorizontalFlip(p=0.5),\n",
    "            transforms.RandomRotation(degrees=15),\n",
    "            transforms.RandomAffine(\n",
    "                degrees=0,\n",
    "                translate=(0.1, 0.1),\n",
    "                scale=(0.9, 1.1)\n",
    "            ),\n",
    "            transforms.ColorJitter(\n",
    "                brightness=0.2,\n",
    "                contrast=0.2,\n",
    "                saturation=0.2,\n",
    "                hue=0.1\n",
    "            ),\n",
    "            transforms.AugMix(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5])\n",
    "        ])\n",
    "\n",
    "        # No augmentation for test/val\n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.Resize(224),\n",
    "            transforms.Lambda(lambda image: image.convert('RGB')),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[.5, .5, .5], std=[.5, .5, .5])\n",
    "        ])\n",
    "\n",
    "        # Load full dataset first\n",
    "        full_dataset = DataClass(split='train', transform=train_transform, download=download)\n",
    "        test_dataset_full = DataClass(split='test', transform=test_transform, download=download)\n",
    "        combined_dataset = torch.utils.data.ConcatDataset([full_dataset, test_dataset_full])\n",
    "\n",
    "        # Randomly select only total_samples items\n",
    "        if total_samples > len(combined_dataset):\n",
    "            total_samples = len(combined_dataset)\n",
    "        indices = random.sample(range(len(combined_dataset)), total_samples)\n",
    "        small_dataset = Subset(combined_dataset, indices)\n",
    "\n",
    "        # Split into train / val / test\n",
    "        train_size = int(0.7 * total_samples)\n",
    "        val_size = int(0.15 * total_samples)\n",
    "        test_size = total_samples - train_size - val_size\n",
    "        train_dataset, val_dataset, test_dataset = random_split(small_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "        # Balanced training loader\n",
    "        train_loader = make_hybrid_loader(train_dataset, BATCH_SIZE)\n",
    "\n",
    "        # Regular loaders for eval\n",
    "        train_loader_at_eval = DataLoader(train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    return data_flag, NUM_EPOCHS, BATCH_SIZE, lr, task, train_loader, train_loader_at_eval, test_loader, n_classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SPMzgtGCkL23",
    "outputId": "94756ea4-3d3b-4daa-b3c5-8e293b6ba93f"
   },
   "outputs": [],
   "source": [
    "## loading model\n",
    "from MedVit3D import MedViT3D_small\n",
    "from MedViT import MedViT_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t6WY6oNAk-G7"
   },
   "outputs": [],
   "source": [
    "## loading history\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "def getPrecision(y_true, y_score, task, threshold=0.5):\n",
    "    y_true = y_true.squeeze()\n",
    "    y_score = y_score.squeeze()\n",
    "\n",
    "    if task == \"multi-label, binary-class\":\n",
    "        y_pred = (y_score > threshold).astype(int)\n",
    "        return precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    elif task == \"binary-class\":\n",
    "        if y_score.ndim == 2:\n",
    "            y_score = y_score[:, -1]\n",
    "        y_pred = (y_score > threshold).astype(int)\n",
    "        return precision_score(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "    else:\n",
    "        y_pred = np.argmax(y_score, axis=-1)\n",
    "        return precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "\n",
    "def getRecall(y_true, y_score, task, threshold=0.5):\n",
    "    y_true = y_true.squeeze()\n",
    "    y_score = y_score.squeeze()\n",
    "\n",
    "    if task == \"multi-label, binary-class\":\n",
    "        y_pred = (y_score > threshold).astype(int)\n",
    "        return recall_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    elif task == \"binary-class\":\n",
    "        if y_score.ndim == 2:\n",
    "            y_score = y_score[:, -1]\n",
    "        y_pred = (y_score > threshold).astype(int)\n",
    "        return recall_score(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "    else:\n",
    "        y_pred = np.argmax(y_score, axis=-1)\n",
    "        return recall_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "\n",
    "def getF1(y_true, y_score, task, threshold=0.5):\n",
    "    y_true = y_true.squeeze()\n",
    "    y_score = y_score.squeeze()\n",
    "\n",
    "    if task == \"multi-label, binary-class\":\n",
    "        y_pred = (y_score > threshold).astype(int)\n",
    "        return f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "    elif task == \"binary-class\":\n",
    "        if y_score.ndim == 2:\n",
    "            y_score = y_score[:, -1]\n",
    "        y_pred = (y_score > threshold).astype(int)\n",
    "        return f1_score(y_true, y_pred, average=\"binary\", zero_division=0)\n",
    "    else:\n",
    "        y_pred = np.argmax(y_score, axis=-1)\n",
    "        return f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "# evaluation\n",
    "def getAUC(y_true, y_score, task):\n",
    "    \"\"\"AUC metric.\n",
    "    :param y_true: the ground truth labels, shape: (n_samples, n_labels) or (n_samples,) if n_labels==1\n",
    "    :param y_score: the predicted score of each class,\n",
    "    shape: (n_samples, n_labels) or (n_samples, n_classes) or (n_samples,) if n_labels==1 or n_classes==1\n",
    "    :param task: the task of current dataset\n",
    "    \"\"\"\n",
    "    y_true = y_true.squeeze()\n",
    "    y_score = y_score.squeeze()\n",
    "\n",
    "    if task == \"multi-label, binary-class\":\n",
    "        auc = 0\n",
    "        for i in range(y_score.shape[1]):\n",
    "            label_auc = roc_auc_score(y_true[:, i], y_score[:, i])\n",
    "            auc += label_auc\n",
    "        ret = auc / y_score.shape[1]\n",
    "    elif task == \"binary-class\":\n",
    "        if y_score.ndim == 2:\n",
    "            y_score = y_score[:, -1]\n",
    "        else:\n",
    "            assert y_score.ndim == 1\n",
    "        ret = roc_auc_score(y_true, y_score)\n",
    "    else:\n",
    "        auc = 0\n",
    "        for i in range(y_score.shape[1]):\n",
    "            y_true_binary = (y_true == i).astype(float)\n",
    "            y_score_binary = y_score[:, i]\n",
    "            auc += roc_auc_score(y_true_binary, y_score_binary)\n",
    "        ret = auc / y_score.shape[1]\n",
    "\n",
    "    return ret\n",
    "\n",
    "\n",
    "def getACC(y_true, y_score, task, threshold=0.5):\n",
    "    \"\"\"Accuracy metric.\n",
    "    :param y_true: the ground truth labels, shape: (n_samples, n_labels) or (n_samples,) if n_labels==1\n",
    "    :param y_score: the predicted score of each class,\n",
    "    shape: (n_samples, n_labels) or (n_samples, n_classes) or (n_samples,) if n_labels==1 or n_classes==1\n",
    "    :param task: the task of current dataset\n",
    "    :param threshold: the threshold for multilabel and binary-class tasks\n",
    "    \"\"\"\n",
    "    y_true = y_true.squeeze()\n",
    "    y_score = y_score.squeeze()\n",
    "\n",
    "    if task == \"multi-label, binary-class\":\n",
    "        y_pre = y_score > threshold\n",
    "        acc = 0\n",
    "        for label in range(y_true.shape[1]):\n",
    "            label_acc = accuracy_score(y_true[:, label], y_pre[:, label])\n",
    "            acc += label_acc\n",
    "        ret = acc / y_true.shape[1]\n",
    "    elif task == \"binary-class\":\n",
    "        if y_score.ndim == 2:\n",
    "            y_score = y_score[:, -1]\n",
    "        else:\n",
    "            assert y_score.ndim == 1\n",
    "        ret = accuracy_score(y_true, y_score > threshold)\n",
    "    else:\n",
    "        ret = accuracy_score(y_true, np.argmax(y_score, axis=-1))\n",
    "\n",
    "    return ret\n",
    "\n",
    "def test(data_loader, model, criterion, task):\n",
    "    model.eval()\n",
    "    y_true = torch.tensor([]).to(device)\n",
    "    y_score = torch.tensor([]).to(device)\n",
    "    data_loader = data_loader\n",
    "    total_loss = 0.0\n",
    "    num_batches = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in data_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            if task == 'multi-label, binary-class':\n",
    "                targets = targets.to(torch.float32)\n",
    "                loss = criterion(outputs, targets)\n",
    "                outputs = outputs.softmax(dim=-1)\n",
    "            else:\n",
    "                targets = targets.squeeze().long()\n",
    "                loss = criterion(outputs, targets)\n",
    "                outputs = outputs.softmax(dim=-1)\n",
    "                targets = targets.float().resize_(len(targets), 1)\n",
    "\n",
    "            y_true = torch.cat((y_true, targets), 0)\n",
    "            y_score = torch.cat((y_score, outputs), 0)\n",
    "            total_loss += loss.item()\n",
    "            num_batches += 1\n",
    "\n",
    "        y_true = y_true.cpu().numpy()\n",
    "        y_score = y_score.detach().cpu().numpy()\n",
    "\n",
    "        auc = getAUC(y_true, y_score, task)\n",
    "        acc = getACC(y_true, y_score, task)\n",
    "        avg_loss = total_loss / num_batches\n",
    "\n",
    "        precision = getPrecision(y_true, y_score, task)\n",
    "        recall = getRecall(y_true, y_score, task)\n",
    "        f1 = getF1(y_true, y_score, task)\n",
    "\n",
    "        return auc, acc ,avg_loss, precision, recall, f1 #, y_true, y_score\n",
    "\n",
    "\n",
    "def load_or_initialize_model(model_class, model_name, optimizer_class, lr, momentum, n_classes, task):\n",
    "    model_dir = \"./history_record\"\n",
    "    os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "    model_path = os.path.join(model_dir, f\"{model_name}.pth\")\n",
    "    history_path = os.path.join(model_dir, f\"{model_name}.csv\")\n",
    "\n",
    "    if \"3d\" in model_name.lower():\n",
    "      model = MedViT3D_small(num_classes = n_classes).to(device)\n",
    "    else:\n",
    "      model = MedViT_small(num_classes = n_classes).to(device)\n",
    "\n",
    "    optimizer = optimizer_class(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "    start_epoch = 0\n",
    "    best_val_auc = 0\n",
    "    history = {\n",
    "        \"train_auc\": [], \"train_acc\": [],\n",
    "        \"val_auc\": [], \"val_acc\": [],\n",
    "        \"train_loss\": [], \"val_loss\": [],\n",
    "        \"epoch_time\": []\n",
    "    }\n",
    "\n",
    "    if os.path.exists(model_path) and os.path.exists(history_path):\n",
    "        print(f\"Loading existing model: {model_name}\")\n",
    "        checkpoint = torch.load(model_path, map_location=device)\n",
    "        model.load_state_dict(checkpoint['model_state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        history = pd.read_csv(history_path).to_dict(orient='list')\n",
    "        start_epoch = len(history[\"train_loss\"])\n",
    "        best_val_auc = max(history[\"val_auc\"]) if history[\"val_auc\"] else 0\n",
    "\n",
    "    return model, optimizer, history, start_epoch, best_val_auc\n",
    "def training_and_record(model_class,\n",
    "                        model_name,\n",
    "                        NUM_EPOCHS, lr,\n",
    "                        momentum, train_loader,\n",
    "                        train_loader_at_eval,\n",
    "                        test_loader,\n",
    "                        n_classes,\n",
    "                        task,\n",
    "                        steps):\n",
    "    model, optimizer, history, start_epoch, best_val_auc = load_or_initialize_model(\n",
    "        model_class, model_name, optimizer_class=torch.optim.SGD, lr=lr, momentum=momentum, n_classes = n_classes,\n",
    "        task = task\n",
    "    )\n",
    "    if task == \"multi-label, binary-class\":\n",
    "        criterion = nn.BCEWithLogitsLoss()\n",
    "    else:\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    total_loss = 0\n",
    "    step_count = 0  # counter for batch steps\n",
    "    for epoch in range(start_epoch, start_epoch + NUM_EPOCHS):\n",
    "        print(f'\\nEpoch [{epoch + 1}/{start_epoch + NUM_EPOCHS}]')\n",
    "        start_time = time.time()\n",
    "        model.train()\n",
    "\n",
    "        for inputs, targets in tqdm(train_loader):\n",
    "            step_count += 1\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            unique_classes = np.unique(targets.cpu().numpy())\n",
    "            # print(f\"Unique class in target data batch is: {unique_classes.tolist()}  | Count: {len(unique_classes)}\")\n",
    "            if task == 'multi-label, binary-class':\n",
    "                # print(\"Going to multi-label, bunary-class branch\")\n",
    "                # Ensure targets become [B, n_classes] float\n",
    "                targets = torch.nn.functional.one_hot(\n",
    "                    targets.squeeze().long(), num_classes=n_classes\n",
    "                ).float().to(device)\n",
    "                # print(\"target shape of original data before loss \", targets.shape)\n",
    "                # print(\"output shape after model, before loss: \", outputs.shape)\n",
    "                loss = criterion(outputs, targets)\n",
    "            else:\n",
    "                # print(\"going to ther branch\")\n",
    "                targets = targets.squeeze().long()  # labels become long\n",
    "                # print(\"target shape of original data before loss \", targets.shape)\n",
    "                # print(\"output shape after model, before loss: \", outputs.shape)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "            # stop after 20 steps per epoch\n",
    "            # if step_count >= steps:\n",
    "            #     print(f\"Breaking after {step_count} steps in this epoch.\")\n",
    "            #     break\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        # Logging\n",
    "        train_loss = total_loss / len(train_loader)\n",
    "        # validation loss\n",
    "\n",
    "        # train loss\n",
    "        train_auc, train_acc, train_loss, precision, recall, f1 = test( train_loader_at_eval, model, criterion, task)\n",
    "        val_auc, val_acc, val_loss, precision, recall, f1 = test(test_loader, model, criterion, task)\n",
    "\n",
    "        print (f\"Val ACC: {val_acc} | Val AUC: {val_auc} | Precision: {precision} | Recall {recall} | F1 Score: {f1}\")\n",
    "\n",
    "\n",
    "        history[\"train_auc\"].append(train_auc)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"val_auc\"].append(val_auc)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "        # Log epoch time\n",
    "        epoch_time = time.time() - start_time\n",
    "        history[\"epoch_time\"].append(epoch_time)\n",
    "        print(f\"Epoch {epoch+1} finished in {epoch_time:.2f} seconds\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_auc > best_val_auc:\n",
    "            best_val_auc = val_auc\n",
    "            print(\"ðŸ“Œ New best AUC â€” saving model\")\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict()\n",
    "            }, f\"./history_record/{model_name}.pth\")\n",
    "\n",
    "        pd.DataFrame(history).to_csv(f\"./history_record/{model_name}.csv\", index=False)\n",
    "\n",
    "    print(\"âœ… Training complete.\")\n",
    "    return history\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WbPIK-D50tZa"
   },
   "outputs": [],
   "source": [
    "## Define same parameters\n",
    "NUM_EPOCHS = 50\n",
    "BATCH_SIZE = 42\n",
    "lr = 0.0005\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOBufE9F-il8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YYMNuK9o2a2B",
    "outputId": "604199fd-80a6-46d1-bef8-c662fbb7cfbc"
   },
   "outputs": [],
   "source": [
    "data_flag = \"synapsemnist3d\"\n",
    "med3d = True\n",
    "model_name = f\"MedViT3D_{data_flag}_aug_1\"\n",
    "## loading data\n",
    "(data_flag,\n",
    " NUM_EPOCHS,\n",
    " BATCH_SIZE,\n",
    " lr,\n",
    " task,\n",
    " train_loader,\n",
    " train_loader_at_eval,\n",
    " test_loader,\n",
    " n_classes) = data_input_loading(data_flag=data_flag,\n",
    "                                NUM_EPOCHS = NUM_EPOCHS,\n",
    "                                BATCH_SIZE=BATCH_SIZE,\n",
    "                                lr=lr,\n",
    "                                med3d= med3d)\n",
    "## train and record\n",
    "history = training_and_record(\n",
    "    model_class=MedViT3D_small,\n",
    "    model_name= model_name,\n",
    "    NUM_EPOCHS=NUM_EPOCHS,\n",
    "    lr=lr,\n",
    "    momentum=0.9,\n",
    "    train_loader=train_loader,\n",
    "    train_loader_at_eval=train_loader_at_eval,\n",
    "    test_loader=test_loader,\n",
    "    n_classes = n_classes,\n",
    "    task = task,\n",
    "    steps = len(train_loader)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mSUvGQYON-Af",
    "outputId": "04615995-9fa9-4940-e962-a2d9297a402d"
   },
   "outputs": [],
   "source": [
    "history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KmKeDYPAOjts",
    "outputId": "c1d571df-e8d0-404e-a166-01e989cc99e3"
   },
   "outputs": [],
   "source": [
    "print (max(history['val_acc']), max(history['val_auc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "zjFSrP-mMmtV",
    "outputId": "dc2e2f5e-0dae-4c23-c1a8-49c5fca304e9"
   },
   "outputs": [],
   "source": [
    "#model.train()\n",
    "total_loss = 0\n",
    "\n",
    "for inputs, targets in train_loader:\n",
    "    inputs = inputs.to(device)\n",
    "    targets = targets.squeeze().long().to(device)\n",
    "    outputs = history(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "    loss.backward()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "\n",
    "train_loss = total_loss / len(train_loader)\n",
    "val_loss, val_acc, val_auc, precision, recall, f1 = test(model, test_loader, device)\n",
    "_, train_acc, train_aucm, precision, recall, f1 = test(model, train_loader, device)\n",
    "\n",
    "print (f\"Model: {model_name} | Epochs: {NUM_EPOCHS} | Batch Size: {BATCH_SIZE}\")\n",
    "#print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Train AUC: {train_auc:.4f}\")\n",
    "print(f\"Val Acc:   {val_acc:.4f} | Val AUC:   {val_auc:.4f}\")\n",
    "print(f\"Precision:   {precision:.4f} | Recall:   {recall:.4f} | F1 Score:   {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1RWBAzW43K8Q",
    "outputId": "dde7e4d2-0d9f-4529-b239-c3aed4321ee0"
   },
   "outputs": [],
   "source": [
    "data_flag = \"organmnist3d\"\n",
    "med3d = True\n",
    "model_name = f\"MedViT3D_{data_flag}\"\n",
    "## loading data\n",
    "(data_flag,\n",
    " NUM_EPOCHS,\n",
    " BATCH_SIZE,\n",
    " lr,\n",
    " task,\n",
    " train_loader,\n",
    " train_loader_at_eval,\n",
    " test_loader,\n",
    " n_classes) = data_input_loading(data_flag=data_flag,\n",
    "                                NUM_EPOCHS = NUM_EPOCHS,\n",
    "                                BATCH_SIZE=BATCH_SIZE,\n",
    "                                lr=lr,\n",
    "                                med3d= med3d)\n",
    "## train and record\n",
    "history = training_and_record(\n",
    "    model_class=MedViT3D_small,\n",
    "    model_name= model_name,\n",
    "    NUM_EPOCHS=NUM_EPOCHS,\n",
    "    lr=lr,\n",
    "    momentum=0.9,\n",
    "    train_loader=train_loader,\n",
    "    train_loader_at_eval=train_loader_at_eval,\n",
    "    test_loader=test_loader,\n",
    "    n_classes = n_classes,\n",
    "    task = task,\n",
    "    steps = len(train_loader)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zA_RtXtVAI7h",
    "outputId": "91db30b0-e6ee-48ce-a853-fa806a96bed7"
   },
   "outputs": [],
   "source": [
    "data_flag = \"adrenalmnist3d\"\n",
    "med3d = True\n",
    "model_name = f\"MedViT3D_{data_flag}_v3\"\n",
    "## loading data\n",
    "(data_flag,\n",
    " NUM_EPOCHS,\n",
    " BATCH_SIZE,\n",
    " lr,\n",
    " task,\n",
    " train_loader,\n",
    " train_loader_at_eval,\n",
    " test_loader,\n",
    " n_classes) = data_input_loading(data_flag=data_flag,\n",
    "                                NUM_EPOCHS = NUM_EPOCHS,\n",
    "                                BATCH_SIZE=BATCH_SIZE,\n",
    "                                lr=lr,\n",
    "                                med3d= med3d)\n",
    "## train and record\n",
    "history = training_and_record(\n",
    "    model_class=MedViT3D_small,\n",
    "    model_name= model_name,\n",
    "    NUM_EPOCHS=NUM_EPOCHS,\n",
    "    lr=lr,\n",
    "    momentum=0.9,\n",
    "    train_loader=train_loader,\n",
    "    train_loader_at_eval=train_loader_at_eval,\n",
    "    test_loader=test_loader,\n",
    "    n_classes = n_classes,\n",
    "    task = task,\n",
    "    steps = len(train_loader)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dw-MENiXO_5l",
    "outputId": "22cd08f5-edd1-496c-cecd-b601568d1f7e"
   },
   "outputs": [],
   "source": [
    "history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ul_bWNpCPDpY",
    "outputId": "d601450c-d411-40e4-e575-9f81d67ddb62"
   },
   "outputs": [],
   "source": [
    "print (max(history['val_acc']), max(history['val_auc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t08_BH2cT9oQ",
    "outputId": "ddf09dfa-4d74-4e85-c140-84129fe80fef"
   },
   "outputs": [],
   "source": [
    "history['val_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "llE092tkA1L-",
    "outputId": "03a38dec-60e7-4eb7-a1ce-b46cc640bb18"
   },
   "outputs": [],
   "source": [
    "data_flag = \"fracturemnist3d\"\n",
    "med3d = True\n",
    "model_name = f\"MedViT3D_{data_flag}_100_1\"\n",
    "## loading data\n",
    "(data_flag,\n",
    " NUM_EPOCHS,\n",
    " BATCH_SIZE,\n",
    " lr,\n",
    " task,\n",
    " train_loader,\n",
    " train_loader_at_eval,\n",
    " test_loader,\n",
    " n_classes) = data_input_loading(data_flag=data_flag,\n",
    "                                NUM_EPOCHS = NUM_EPOCHS,\n",
    "                                BATCH_SIZE=BATCH_SIZE,\n",
    "                                lr=lr,\n",
    "                                med3d= med3d)\n",
    "## train and record\n",
    "history = training_and_record(\n",
    "    model_class=MedViT3D_small,\n",
    "    model_name= model_name,\n",
    "    NUM_EPOCHS=NUM_EPOCHS,\n",
    "    lr=lr,\n",
    "    momentum=0.9,\n",
    "    train_loader=train_loader,\n",
    "    train_loader_at_eval=train_loader_at_eval,\n",
    "    test_loader=test_loader,\n",
    "    n_classes = n_classes,\n",
    "    task = task,\n",
    "    steps = len(train_loader)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ln5u6qdxPzlG",
    "outputId": "3aeeda7d-eeb6-402c-da66-476b5a62de6c"
   },
   "outputs": [],
   "source": [
    "history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2eX6wupsP2JI",
    "outputId": "d0a50593-9dd5-41d6-fe67-e961137586cc"
   },
   "outputs": [],
   "source": [
    "print (max(history['val_auc']), max(history['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uPZnPcQbUDG3",
    "outputId": "400b1df2-844d-4a2f-8924-0ea62ca3cbde"
   },
   "outputs": [],
   "source": [
    "history['val_auc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PMaea8SBBnqk",
    "outputId": "53f3941a-dd0b-4cdf-edfd-aa0d9260efff"
   },
   "outputs": [],
   "source": [
    "data_flag = \"vesselmnist3d\"\n",
    "med3d = True\n",
    "model_name = f\"MedViT3D_{data_flag}\"\n",
    "## loading data\n",
    "(data_flag,\n",
    " NUM_EPOCHS,\n",
    " BATCH_SIZE,\n",
    " lr,\n",
    " task,\n",
    " train_loader,\n",
    " train_loader_at_eval,\n",
    " test_loader,\n",
    " n_classes) = data_input_loading(data_flag=data_flag,\n",
    "                                NUM_EPOCHS = NUM_EPOCHS,\n",
    "                                BATCH_SIZE=BATCH_SIZE,\n",
    "                                lr=lr,\n",
    "                                med3d= med3d)\n",
    "## train and record\n",
    "history = training_and_record(\n",
    "    model_class=MedViT3D_small,\n",
    "    model_name= model_name,\n",
    "    NUM_EPOCHS=NUM_EPOCHS,\n",
    "    lr=lr,\n",
    "    momentum=0.9,\n",
    "    train_loader=train_loader,\n",
    "    train_loader_at_eval=train_loader_at_eval,\n",
    "    test_loader=test_loader,\n",
    "    n_classes = n_classes,\n",
    "    task = task,\n",
    "    steps = len(train_loader)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pvtVnHS-CPPV",
    "outputId": "d7e3eb9d-8754-4170-86a6-78493c192014"
   },
   "outputs": [],
   "source": [
    "data_flag = \"synapsemnist3d\"\n",
    "med3d = True\n",
    "model_name = f\"MedViT3D_{data_flag}\"\n",
    "## loading data\n",
    "(data_flag,\n",
    " NUM_EPOCHS,\n",
    " BATCH_SIZE,\n",
    " lr,\n",
    " task,\n",
    " train_loader,\n",
    " train_loader_at_eval,\n",
    " test_loader,\n",
    " n_classes) = data_input_loading(data_flag=data_flag,\n",
    "                                NUM_EPOCHS = NUM_EPOCHS,\n",
    "                                BATCH_SIZE=BATCH_SIZE,\n",
    "                                lr=lr,\n",
    "                                med3d= med3d)\n",
    "## train and record\n",
    "history = training_and_record(\n",
    "    model_class=MedViT3D_small,\n",
    "    model_name= model_name,\n",
    "    NUM_EPOCHS=NUM_EPOCHS,\n",
    "    lr=lr,\n",
    "    momentum=0.9,\n",
    "    train_loader=train_loader,\n",
    "    train_loader_at_eval=train_loader_at_eval,\n",
    "    test_loader=test_loader,\n",
    "    n_classes = n_classes,\n",
    "    task = task,\n",
    "    steps = len(train_loader)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5qNBKRmsoTU"
   },
   "source": [
    " MedVit2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7CWaRBwgrda2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CP39VaImrdP0"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89HqFIIi7ARz"
   },
   "outputs": [],
   "source": [
    "## Grad CAM for model explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "QXuzYhhSEo8q",
    "outputId": "091e86f9-db26-4ac2-b4cb-61ce85117e85"
   },
   "outputs": [],
   "source": [
    "!pip install torchcam\n",
    "# OR\n",
    "!pip install captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bfQ6I5mK8W1n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8kcpLxy6CGIQ"
   },
   "outputs": [],
   "source": [
    "from torchcam.methods import GradCAM\n",
    "from torchcam.utils import overlay_mask\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "cam_extractor = GradCAM(model, target_layer=\"ltb1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sin1HsuxFsWI"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Select a sample from test loader\n",
    "inputs, targets = next(iter(test_loader))\n",
    "inputs = inputs.to(device)\n",
    "targets = targets.squeeze().long().to(device)\n",
    "\n",
    "# Forward pass and CAM extraction\n",
    "with torch.no_grad():\n",
    "    output = model(inputs)\n",
    "    pred_class = output.argmax(dim=1)\n",
    "\n",
    "# Extract CAM for the first image\n",
    "cam = cam_extractor(pred_class[0].item(), output)  # Automatically registers and removes hooks\n",
    "\n",
    "# Process image and heatmap\n",
    "input_image = inputs[0].cpu().squeeze().numpy()  # [D, H, W]\n",
    "slice_idx = input_image.shape[0] // 2\n",
    "slice_img = input_image[slice_idx]\n",
    "slice_cam = cam[0][slice_idx]\n",
    "\n",
    "# Normalize and overlay\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchcam.utils import overlay_mask\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "norm_slice = (slice_img - slice_img.min()) / (slice_img.max() - slice_img.min())\n",
    "norm_cam = (slice_cam - slice_cam.min()) / (slice_cam.max() - slice_cam.min())\n",
    "\n",
    "overlay = overlay_mask(to_pil_image(norm_slice), to_pil_image(norm_cam), alpha=0.6)\n",
    "\n",
    "plt.imshow(overlay)\n",
    "plt.title(f\"Grad-CAM (Pred: {pred_class[0].item()}, True: {targets[0].item()})\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "_zEnJK3uDlxo",
    "outputId": "4764d851-99be-4127-b733-7d2b110f1e65"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchcam.methods import GradCAM\n",
    "from torchcam.utils import overlay_mask\n",
    "\n",
    "# === Setup ===\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.eval().to(device)\n",
    "\n",
    "# === Choose target layer for GradCAM ===\n",
    "target_layer = 'ltb3.conv.0'  # Change if needed\n",
    "cam_extractor = GradCAM(model, target_layer=target_layer)\n",
    "\n",
    "# === Load 1 test sample ===\n",
    "inputs, targets = next(iter(test_loader))\n",
    "input_tensor = inputs[0].unsqueeze(0).to(device)  # [1, 1, D, H, W]\n",
    "true_label = targets[0].item()\n",
    "\n",
    "# === Forward pass & CAM extraction ===\n",
    "with torch.set_grad_enabled(True):\n",
    "    scores = model(input_tensor)\n",
    "    pred_class = scores.argmax(dim=1).item()\n",
    "    cams = cam_extractor(pred_class, scores)  # list of CAMs\n",
    "\n",
    "# === Get the CAM tensor ===\n",
    "cam = cams[0]  # Could be [1, D, H, W] or [D, H, W]\n",
    "if cam.dim() == 3:\n",
    "    cam = cam.unsqueeze(0).unsqueeze(0)  # â†’ [1, 1, D, H, W]\n",
    "elif cam.dim() == 4:\n",
    "    cam = cam.unsqueeze(0)               # â†’ [1, 1, D, H, W]\n",
    "# Else: already fine\n",
    "\n",
    "# === Interpolate CAM to input shape ===\n",
    "target_shape = input_tensor.shape[2:]  # [D, H, W]\n",
    "cam_upsampled = F.interpolate(cam, size=target_shape, mode=\"trilinear\", align_corners=False)\n",
    "\n",
    "cam_volume = cam_upsampled.squeeze().cpu()  # [D, H, W]\n",
    "\n",
    "# === Get input volume ===\n",
    "input_volume = input_tensor.squeeze().cpu()  # [D, H, W]\n",
    "\n",
    "# === Pick a middle slice ===\n",
    "slice_idx = input_volume.shape[0] // 2\n",
    "input_slice = input_volume[slice_idx]  # [H, W]\n",
    "cam_slice = cam_volume[slice_idx]      # [H, W]\n",
    "\n",
    "# === Normalize both slices ===\n",
    "input_norm = (input_slice - input_slice.min()) / (input_slice.max() - input_slice.min() + 1e-6)\n",
    "cam_norm = (cam_slice - cam_slice.min()) / (cam_slice.max() - cam_slice.min() + 1e-6)\n",
    "\n",
    "# === Convert to PIL images ===\n",
    "input_pil = to_pil_image(input_slice)\n",
    "cam_pil = to_pil_image(cam_slice)\n",
    "\n",
    "# Convert grayscale input to RGB for overlay\n",
    "input_pil = input_pil.convert(\"RGB\")\n",
    "\n",
    "# === Overlay CAM ===\n",
    "overlay = overlay_mask(input_pil, cam_pil, alpha=0.5)\n",
    "\n",
    "# === Plot ===\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(overlay)\n",
    "plt.title(f\"Grad-CAM Overlay (slice {slice_idx}) | Pred: {pred_class} | GT: {target_class}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "id": "Y-eeHmrDD3N9",
    "outputId": "1edd4a61-d082-488f-c309-3d533d6c3e74"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "from torchcam.methods import GradCAM\n",
    "from torchcam.utils import overlay_mask\n",
    "\n",
    "# === Prepare your model ===\n",
    "model.eval()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Choose a target layer name from your model â€” ltb3 is good\n",
    "target_layer = \"ltb3\"\n",
    "\n",
    "# Initialize GradCAM\n",
    "cam_extractor = GradCAM(model, target_layer=target_layer)\n",
    "\n",
    "# === Pick one test sample ===\n",
    "inputs, targets = next(iter(test_loader))\n",
    "inputs = inputs.to(device)\n",
    "input_tensor = inputs[0].unsqueeze(0)  # [1, C, D, H, W]\n",
    "target_class = targets[0].item()\n",
    "\n",
    "# === Forward pass and CAM generation ===\n",
    "output = model(input_tensor)\n",
    "pred_class = output.argmax(dim=1).item()\n",
    "\n",
    "# Generate CAM\n",
    "cams = cam_extractor(pred_class, output)\n",
    "cam = cams[0]\n",
    "\n",
    "if cam.dim() == 3:\n",
    "    cam = cam.unsqueeze(0).unsqueeze(0)  # â†’ [1, 1, D, H, W]\n",
    "elif cam.dim() == 4:\n",
    "    cam = cam.unsqueeze(0)               # â†’ [1, 1, D, H, W]\n",
    "# === Interpolate CAM to match input size ===\n",
    "target_shape = input_tensor.shape[2:]  # [D, H, W]\n",
    "cam_upsampled = F.interpolate(cam, size=target_shape, mode=\"trilinear\", align_corners=False)\n",
    "\n",
    "cam_volume = cam_upsampled.squeeze().cpu()  # [D, H, W]\n",
    "\n",
    "\n",
    "# === Normalize input volume ===\n",
    "input_volume = input_tensor.squeeze().cpu()  # [D, H, W]\n",
    "input_volume = (input_volume - input_volume.min()) / (input_volume.max() - input_volume.min())\n",
    "\n",
    "# === Choose center slice ===\n",
    "slice_idx = input_volume.shape[0] // 2\n",
    "input_slice = input_volume[slice_idx]  # [H, W]\n",
    "cam_slice = cam_volume[slice_idx]      # [H, W]\n",
    "\n",
    "# Normalize CAM slice\n",
    "cam_slice = (cam_slice - cam_slice.min()) / (cam_slice.max() - cam_slice.min())\n",
    "\n",
    "# Convert grayscale input to RGB for overlay\n",
    "input_pil = input_pil.convert(\"RGB\")\n",
    "\n",
    "# === Overlay CAM ===\n",
    "overlay = overlay_mask(input_pil, cam_pil, alpha=0.5)\n",
    "\n",
    "# === Plot result ===\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(overlay)\n",
    "plt.title(f\"Grad-CAM (target: {target_class}, pred: {pred_class})\")\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OAxSMlFfBlU5"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
