{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2155d5e7"
      },
      "source": [
        "Now you can run the previous cell to import `torch` and `make_dot`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAI9r5x9Mjhw"
      },
      "source": [
        "Base MedVit Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qe8mtlWoU9yI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "## reduce GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnAlms8PQ-Af",
        "outputId": "ab10fc93-80b5-4778-b852-f65b2377bd83"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/drive/MyDrive/Colab\\ Notebooks/Med-ViT-3D-main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ekAYkrARuXk",
        "outputId": "127d580a-05f7-4072-dc1b-e2d93bf4da76"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Med-ViT-3D-main\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UFtychH7MlvN",
        "outputId": "97be54b2-dbe5-4ab2-b93a-1312c7370dad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting medmnist==3.0.1\n",
            "  Downloading medmnist-3.0.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting torchattacks\n",
            "  Downloading torchattacks-3.5.1-py3-none-any.whl.metadata (927 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (11.3.0)\n",
            "Collecting fire (from medmnist==3.0.1)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (0.21.0+cu124)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from torchattacks) (1.16.1)\n",
            "Collecting requests~=2.25.1 (from torchattacks)\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting chardet<5,>=3.0.2 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting idna<3,>=2.5 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.25.1->torchattacks) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->medmnist==3.0.1) (1.3.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->medmnist==3.0.1) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist==3.0.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist==3.0.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist==3.0.1) (2025.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist==3.0.1) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist==3.0.1) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist==3.0.1) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist==3.0.1) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist==3.0.1) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist==3.0.1) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist==3.0.1) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->medmnist==3.0.1) (3.0.2)\n",
            "Downloading medmnist-3.0.1-py3-none-any.whl (25 kB)\n",
            "Downloading torchattacks-3.5.1-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.0/142.0 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=e6d8bec6bcf077df2c1c6fbe64d6fdb516238c3edd0b63325f3d315033767df7\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: urllib3, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, idna, fire, chardet, requests, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchattacks, medmnist\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.25.1 which is incompatible.\n",
            "datasets 4.0.0 requires requests>=2.32.2, but you have requests 2.25.1 which is incompatible.\n",
            "google-genai 1.28.0 requires requests<3.0.0,>=2.28.1, but you have requests 2.25.1 which is incompatible.\n",
            "sphinx 8.2.3 requires requests>=2.30.0, but you have requests 2.25.1 which is incompatible.\n",
            "tweepy 4.16.0 requires requests<3,>=2.27.0, but you have requests 2.25.1 which is incompatible.\n",
            "yfinance 0.2.65 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\n",
            "bigframes 2.13.0 requires requests>=2.27.1, but you have requests 2.25.1 which is incompatible.\n",
            "libpysal 4.13.0 requires requests>=2.27, but you have requests 2.25.1 which is incompatible.\n",
            "tiktoken 0.10.0 requires requests>=2.26.0, but you have requests 2.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chardet-4.0.0 fire-0.7.0 idna-2.10 medmnist-3.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 requests-2.25.1 torchattacks-3.5.1 urllib3-1.26.20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "chardet",
                  "idna",
                  "nvidia",
                  "requests",
                  "urllib3"
                ]
              },
              "id": "13e011b9fda34ef9a96c19af087a16c6"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install medmnist==3.0.1 \\\n",
        "    torchattacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_aD3CYXqM06G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.utils\n",
        "from torchvision import models\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "from tqdm import tqdm\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "\n",
        "import torchattacks\n",
        "from torchattacks import PGD, FGSM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CsEux3TNGoi",
        "outputId": "7897b23b-40c8-4745-acaa-88733cf72ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch 2.6.0+cu124\n",
            "Torchvision 0.21.0+cu124\n",
            "Torchattacks 3.5.1\n",
            "Numpy 1.26.4\n",
            "Medmnist 3.0.1\n"
          ]
        }
      ],
      "source": [
        "print(\"PyTorch\", torch.__version__)\n",
        "print(\"Torchvision\", torchvision.__version__)\n",
        "print(\"Torchattacks\", torchattacks.__version__)\n",
        "print(\"Numpy\", np.__version__)\n",
        "print(\"Medmnist\", medmnist.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZfjcPbQNdfi"
      },
      "source": [
        "##Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEcZP5e2O18E"
      },
      "source": [
        "## Model loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny4ySw8G2Xyq",
        "outputId": "ee09a84c-ed3d-4f79-82b1-b39730839d86"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EwqJwVrPm0V"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a72X8QrUq1Bk"
      },
      "source": [
        "### Team7: Continue training by loading history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5PGUehVkwl4y"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# evaluation\n",
        "def getAUC(y_true, y_score, task):\n",
        "    \"\"\"AUC metric.\n",
        "    :param y_true: the ground truth labels, shape: (n_samples, n_labels) or (n_samples,) if n_labels==1\n",
        "    :param y_score: the predicted score of each class,\n",
        "    shape: (n_samples, n_labels) or (n_samples, n_classes) or (n_samples,) if n_labels==1 or n_classes==1\n",
        "    :param task: the task of current dataset\n",
        "    \"\"\"\n",
        "    y_true = y_true.squeeze()\n",
        "    y_score = y_score.squeeze()\n",
        "\n",
        "    if task == \"multi-label, binary-class\":\n",
        "        auc = 0\n",
        "        for i in range(y_score.shape[1]):\n",
        "            label_auc = roc_auc_score(y_true[:, i], y_score[:, i])\n",
        "            auc += label_auc\n",
        "        ret = auc / y_score.shape[1]\n",
        "    elif task == \"binary-class\":\n",
        "        if y_score.ndim == 2:\n",
        "            y_score = y_score[:, -1]\n",
        "        else:\n",
        "            assert y_score.ndim == 1\n",
        "        ret = roc_auc_score(y_true, y_score)\n",
        "    else:\n",
        "        auc = 0\n",
        "        for i in range(y_score.shape[1]):\n",
        "            y_true_binary = (y_true == i).astype(float)\n",
        "            y_score_binary = y_score[:, i]\n",
        "            auc += roc_auc_score(y_true_binary, y_score_binary)\n",
        "        ret = auc / y_score.shape[1]\n",
        "\n",
        "    return ret\n",
        "\n",
        "\n",
        "def getACC(y_true, y_score, task, threshold=0.5):\n",
        "    \"\"\"Accuracy metric.\n",
        "    :param y_true: the ground truth labels, shape: (n_samples, n_labels) or (n_samples,) if n_labels==1\n",
        "    :param y_score: the predicted score of each class,\n",
        "    shape: (n_samples, n_labels) or (n_samples, n_classes) or (n_samples,) if n_labels==1 or n_classes==1\n",
        "    :param task: the task of current dataset\n",
        "    :param threshold: the threshold for multilabel and binary-class tasks\n",
        "    \"\"\"\n",
        "    y_true = y_true.squeeze()\n",
        "    y_score = y_score.squeeze()\n",
        "\n",
        "    if task == \"multi-label, binary-class\":\n",
        "        y_pre = y_score > threshold\n",
        "        acc = 0\n",
        "        for label in range(y_true.shape[1]):\n",
        "            label_acc = accuracy_score(y_true[:, label], y_pre[:, label])\n",
        "            acc += label_acc\n",
        "        ret = acc / y_true.shape[1]\n",
        "    elif task == \"binary-class\":\n",
        "        if y_score.ndim == 2:\n",
        "            y_score = y_score[:, -1]\n",
        "        else:\n",
        "            assert y_score.ndim == 1\n",
        "        ret = accuracy_score(y_true, y_score > threshold)\n",
        "    else:\n",
        "        ret = accuracy_score(y_true, np.argmax(y_score, axis=-1))\n",
        "\n",
        "    return ret\n",
        "\n",
        "def test(data_loader, model, criterion, task):\n",
        "    model.eval()\n",
        "    y_true = torch.tensor([]).to(device)\n",
        "    y_score = torch.tensor([]).to(device)\n",
        "    data_loader = data_loader\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            if task == 'multi-label, binary-class':\n",
        "                targets = targets.to(torch.float32)\n",
        "                loss = criterion(outputs, targets)\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "            else:\n",
        "                targets = targets.squeeze().long()\n",
        "                loss = criterion(outputs, targets)\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "                targets = targets.float().resize_(len(targets), 1)\n",
        "\n",
        "            y_true = torch.cat((y_true, targets), 0)\n",
        "            y_score = torch.cat((y_score, outputs), 0)\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "        y_true = y_true.cpu().numpy()\n",
        "        y_score = y_score.detach().cpu().numpy()\n",
        "\n",
        "        auc = getAUC(y_true, y_score, task)\n",
        "        acc = getACC(y_true, y_score, task)\n",
        "        avg_loss = total_loss / num_batches\n",
        "\n",
        "        return auc, acc ,avg_loss #, y_true, y_score\n",
        "\n",
        "\n",
        "def load_or_initialize_model(model_class, model_name, optimizer_class, lr, momentum, n_classes, task):\n",
        "    model_dir = \"./history_record\"\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    model_path = os.path.join(model_dir, f\"{model_name}.pth\")\n",
        "    history_path = os.path.join(model_dir, f\"{model_name}.csv\")\n",
        "\n",
        "\n",
        "    model = MedViT_small(num_classes = n_classes).to(device)\n",
        "\n",
        "    optimizer = optimizer_class(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "    start_epoch = 0\n",
        "    best_val_auc = 0\n",
        "    history = {\n",
        "        \"train_auc\": [], \"train_acc\": [],\n",
        "        \"val_auc\": [], \"val_acc\": [],\n",
        "        \"train_loss\": [], \"val_loss\": []\n",
        "    }\n",
        "\n",
        "    if os.path.exists(model_path) and os.path.exists(history_path):\n",
        "        print(f\"Loading existing model: {model_name}\")\n",
        "        checkpoint = torch.load(model_path, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        history = pd.read_csv(history_path).to_dict(orient='list')\n",
        "        start_epoch = len(history[\"train_loss\"])\n",
        "        best_val_auc = max(history[\"val_auc\"]) if history[\"val_auc\"] else 0\n",
        "\n",
        "    return model, optimizer, history, start_epoch, best_val_auc\n",
        "def training_and_record(model_class,\n",
        "                        model_name,\n",
        "                        NUM_EPOCHS, lr,\n",
        "                        momentum, train_loader,\n",
        "                        train_loader_at_eval,\n",
        "                        test_loader,\n",
        "                        n_classes,\n",
        "                        task,\n",
        "                        steps):\n",
        "    model, optimizer, history, start_epoch, best_val_auc = load_or_initialize_model(\n",
        "        model_class, model_name, optimizer_class=torch.optim.SGD, lr=lr, momentum=momentum, n_classes = n_classes,\n",
        "        task = task\n",
        "    )\n",
        "    if task == \"multi-label, binary-class\":\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    total_loss = 0\n",
        "    step_count = 0  # counter for batch steps\n",
        "    for epoch in range(start_epoch, start_epoch + NUM_EPOCHS):\n",
        "        print(f'\\nEpoch [{epoch + 1}/{start_epoch + NUM_EPOCHS}]')\n",
        "        model.train()\n",
        "\n",
        "        for inputs, targets in tqdm(train_loader):\n",
        "            step_count += 1\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            unique_classes = np.unique(targets.cpu().numpy())\n",
        "            # print(f\"Unique class in target data batch is: {unique_classes.tolist()}  | Count: {len(unique_classes)}\")\n",
        "            if task == 'multi-label, binary-class':\n",
        "                # print(\"Going to multi-label, bunary-class branch\")\n",
        "                # Ensure targets become [B, n_classes] float\n",
        "                targets = torch.nn.functional.one_hot(\n",
        "                    targets.squeeze().long(), num_classes=n_classes\n",
        "                ).float().to(device)\n",
        "                # print(\"target shape of original data before loss \", targets.shape)\n",
        "                # print(\"output shape after model, before loss: \", outputs.shape)\n",
        "                loss = criterion(outputs, targets)\n",
        "            else:\n",
        "                # print(\"going to ther branch\")\n",
        "                targets = targets.squeeze().long()  # labels become long\n",
        "                # print(\"target shape of original data before loss \", targets.shape)\n",
        "                # print(\"output shape after model, before loss: \", outputs.shape)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            # stop after 20 steps per epoch\n",
        "            # if step_count >= steps:\n",
        "            #     print(f\"Breaking after {step_count} steps in this epoch.\")\n",
        "            #     break\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Logging\n",
        "        train_loss = total_loss / len(train_loader)\n",
        "        # validation loss\n",
        "        val_auc, val_acc, val_loss = test(test_loader, model, criterion, task)\n",
        "        # train loss\n",
        "        train_auc, train_acc, train_loss = test( train_loader_at_eval, model, criterion, task)\n",
        "\n",
        "\n",
        "        history[\"train_auc\"].append(train_auc)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"val_auc\"].append(val_auc)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "\n",
        "\n",
        "        # Save best model\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "            print(\"📌 New best AUC — saving model\")\n",
        "            torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict()\n",
        "            }, f\"./history_record/{model_name}.pth\")\n",
        "\n",
        "        pd.DataFrame(history).to_csv(f\"./history_record/{model_name}.csv\", index=False)\n",
        "\n",
        "    print(\"✅ Training complete.\")\n",
        "    return history\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSafnt9RVYe-"
      },
      "source": [
        "## Team7: Fit into MedMNIST-3D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDGis148YeZV"
      },
      "source": [
        "**MedVit3D**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmBgSJ8_AN8B",
        "outputId": "25f0cd06-c367-4b58-ec5c-53f6af3fd5c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of channels :  1\n",
            "number of classes :  11\n"
          ]
        }
      ],
      "source": [
        "data_flag = 'organmnist3d'\n",
        "# [tissuemnist, pathmnist, chestmnist, dermamnist, octmnist,\n",
        "# pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "download = True\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 15\n",
        "lr = 0.005\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "print(\"number of channels : \", n_channels)\n",
        "print(\"number of classes : \", n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RRqLeV7QIy1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "md2Z0wF-8RfK"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms.transforms import Resize\n",
        "# preprocessing\n",
        "transform = lambda x: torch.from_numpy(x).squeeze(1).float()\n",
        "train_dataset = DataClass(split='train', transform=transform, download=True)\n",
        "val_dataset = DataClass(split='val', transform=transform, download=True)\n",
        "test_dataset = DataClass(split='test', transform=transform, download=True)\n",
        "\n",
        "\n",
        "# pil_dataset = DataClass(split='train', download=download)\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0y9S9zC-zTS",
        "outputId": "947dbe31-ac98-4114-e691-2d34bf0f89d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "len(train_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVOgku87rL2F",
        "outputId": "b39116f0-cc5d-4069-f80c-f01a233d8d1e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "n_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "PFWoDxaC2BUo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58a9ebd2-d98c-4349-b160-b7fb2e4f5c51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "from MedVit3D import MedViT3D_small\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MedViT3D_small(num_classes = n_classes).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwZ2Cf5V-6Xi",
        "outputId": "7ea4e464-1e3a-430e-85e8-c31402606f64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 2.4444475173950195\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "model.train()\n",
        "for inputs, targets in train_loader:\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.squeeze()  # Remove extra dimension\n",
        "    if targets.ndim != 1:\n",
        "        targets = targets.view(-1)  # Ensure shape is [B]\n",
        "    targets = targets.long().to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)  # Shape: [B, num_classes]\n",
        "    loss = criterion(outputs, targets)  # targets: [B]\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print(\"Loss:\", loss.item())\n",
        "    break  # Only run 1 batch for testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmEg0ooyZiZ0",
        "outputId": "9d8d16de-4027-4768-ec62-5b2c8ef71c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.1131\n"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.squeeze()\n",
        "        if targets.ndim != 1:\n",
        "            targets = targets.view(-1)\n",
        "        targets = targets.long().to(device)\n",
        "\n",
        "        outputs = model(inputs)  # logits\n",
        "        preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(targets.cpu().numpy())\n",
        "\n",
        "# ✅ Calculate Accuracy\n",
        "acc = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5womIG9paWU3",
        "outputId": "34ebabb1-891b-4ae5-8fa8-0717a96d03ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: 2.1613 | Train Acc: 0.4130 | Train AUC: 0.9146\n",
            "Val Loss:   1.9240 | Val Acc:   0.3869 | Val AUC:   0.8956\n"
          ]
        }
      ],
      "source": [
        "## train full batch\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def evaluate(model, loader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_labels = []\n",
        "    all_outputs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.squeeze().long().to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            all_outputs.append(outputs.softmax(dim=1).cpu().numpy())\n",
        "            all_labels.append(targets.cpu().numpy())\n",
        "\n",
        "    # Flatten\n",
        "    all_preds = np.concatenate(all_outputs, axis=0)\n",
        "    all_labels = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "    # Metrics\n",
        "    acc = accuracy_score(all_labels, all_preds.argmax(axis=1))\n",
        "    try:\n",
        "        auc = roc_auc_score(all_labels, all_preds, multi_class='ovr')\n",
        "    except:\n",
        "        auc = -1  # fallback if AUC fails (e.g., single class present)\n",
        "\n",
        "    avg_loss = total_loss / len(loader)\n",
        "    return avg_loss, acc, auc\n",
        "model.train()\n",
        "total_loss = 0\n",
        "\n",
        "for inputs, targets in train_loader:\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.squeeze().long().to(device)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "\n",
        "train_loss = total_loss / len(train_loader)\n",
        "val_loss, val_acc, val_auc = evaluate(model, test_loader, device)\n",
        "_, train_acc, train_auc = evaluate(model, train_loader, device)\n",
        "\n",
        "print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Train AUC: {train_auc:.4f}\")\n",
        "print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f} | Val AUC:   {val_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rTlH_sYlCPx"
      },
      "outputs": [],
      "source": [
        "## train multiple epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "BJRP5e30lCDW"
      },
      "outputs": [],
      "source": [
        "def load_or_initialize_model(model_class, model_name, optimizer_class, lr, momentum, n_classes):\n",
        "    model_dir = \"./history_record\"\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    model_path = os.path.join(model_dir, f\"{model_name}.pth\")\n",
        "    history_path = os.path.join(model_dir, f\"{model_name}.csv\")\n",
        "\n",
        "    model = MedViT3D_small(num_classes = n_classes).to(device)\n",
        "    optimizer = optimizer_class(model.parameters(), lr=lr, momentum=momentum)\n",
        "    start_epoch = 0\n",
        "    best_val_auc = 0\n",
        "    history = {\n",
        "        \"train_auc\": [], \"train_acc\": [],\n",
        "        \"val_auc\": [], \"val_acc\": [],\n",
        "        \"train_loss\": []\n",
        "    }\n",
        "\n",
        "    if os.path.exists(model_path) and os.path.exists(history_path):\n",
        "        print(f\"Loading existing model: {model_name}\")\n",
        "        checkpoint = torch.load(model_path, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        history = pd.read_csv(history_path).to_dict(orient='list')\n",
        "        start_epoch = len(history[\"train_loss\"])\n",
        "        best_val_auc = max(history[\"val_auc\"]) if history[\"val_auc\"] else 0\n",
        "\n",
        "    return model, optimizer, history, start_epoch, best_val_auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9uRNjKrqcqPs"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "def training_and_record(model_class, model_name, NUM_EPOCHS, lr, momentum, train_loader, train_loader_at_eval, test_loader, n_classes):\n",
        "    model, optimizer, history, start_epoch, best_val_auc = load_or_initialize_model(\n",
        "        model_class, model_name, optimizer_class=torch.optim.SGD, lr=lr, momentum=momentum, n_classes= n_classes\n",
        "    )\n",
        "\n",
        "    for epoch in range(start_epoch, start_epoch + NUM_EPOCHS):\n",
        "        print(f'\\nEpoch [{epoch + 1}/{start_epoch + NUM_EPOCHS}]')\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for inputs, targets in tqdm(train_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.squeeze().long().to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            # print(\"Unique labels:\", targets.unique())\n",
        "            # print(\"Targets shape:\", targets.shape)\n",
        "            # print(\"Output shape:\", outputs.shape)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Logging\n",
        "        train_loss = total_loss / len(train_loader)\n",
        "        val_loss, val_acc, val_auc = evaluate(model, test_loader, device)\n",
        "        _, train_acc, train_auc = evaluate(model, train_loader, device)\n",
        "\n",
        "        history[\"train_auc\"].append(train_auc)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"val_auc\"].append(val_auc)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "\n",
        "        # Save best model\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "            print(\"📌 New best AUC — saving model\")\n",
        "            torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict()\n",
        "            }, f\"./history_record/{model_name}.pth\")\n",
        "\n",
        "        pd.DataFrame(history).to_csv(f\"./history_record/{model_name}.csv\", index=False)\n",
        "\n",
        "    print(\"✅ Training complete.\")\n",
        "    return history, model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGDFXUQZJfPi",
        "outputId": "51c412de-83c8-47a3-8e1f-765d65d1dcdd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.005"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6mm2Y5icqmB",
        "outputId": "ae6c0b59-b8b6-4781-9765-c7beb6fae70d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading existing model: MedViT3D_organmnist3d\n",
            "\n",
            "Epoch [11/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65/65 [00:02<00:00, 24.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [12/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65/65 [00:02<00:00, 30.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 New best AUC — saving model\n",
            "\n",
            "Epoch [13/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65/65 [00:02<00:00, 30.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 New best AUC — saving model\n",
            "\n",
            "Epoch [14/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65/65 [00:02<00:00, 30.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [15/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65/65 [00:02<00:00, 30.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [16/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65/65 [00:02<00:00, 30.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [17/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65/65 [00:02<00:00, 29.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [18/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65/65 [00:02<00:00, 29.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [19/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65/65 [00:02<00:00, 29.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [20/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65/65 [00:02<00:00, 27.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Training complete.\n"
          ]
        }
      ],
      "source": [
        "## Train môre epoch and recording.\n",
        "import os\n",
        "import pandas as pd\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "history, model = training_and_record(\n",
        "    model_class=MedViT3D_small,\n",
        "    model_name=\"MedViT3D_organmnist3d\",\n",
        "    NUM_EPOCHS=NUM_EPOCHS,\n",
        "    lr=lr,\n",
        "    momentum=0.9,\n",
        "    train_loader=train_loader,\n",
        "    train_loader_at_eval=train_loader_at_eval,\n",
        "    test_loader=test_loader,\n",
        "    n_classes = n_classes\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89HqFIIi7ARz"
      },
      "outputs": [],
      "source": [
        "## Grad CAM for model explanation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QXuzYhhSEo8q",
        "outputId": "4b4dce93-34d4-437f-f794-03c892825fb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchcam\n",
            "  Downloading torchcam-0.4.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchcam) (2.6.0+cu124)\n",
            "Collecting numpy<2.0.0,>=1.17.2 (from torchcam)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow!=9.2.0,>=8.4.0 in /usr/local/lib/python3.11/dist-packages (from torchcam) (11.3.0)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from torchcam) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0.0,>=2.0.0->torchcam) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.7.0->torchcam) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0.0,>=2.0.0->torchcam) (3.0.2)\n",
            "Downloading torchcam-0.4.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, torchcam\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 4.0.0 requires requests>=2.32.2, but you have requests 2.25.1 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "yfinance 0.2.65 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\n",
            "bigframes 2.13.0 requires requests>=2.27.1, but you have requests 2.25.1 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "libpysal 4.13.0 requires requests>=2.27, but you have requests 2.25.1 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 torchcam-0.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "c3bd290cac0e4ecba11e24956b880ce1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting captum\n",
            "  Downloading captum-0.8.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from captum) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.11/dist-packages (from captum) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from captum) (25.0)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.11/dist-packages (from captum) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from captum) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10->captum) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10->captum) (3.0.2)\n",
            "Downloading captum-0.8.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.4 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: captum\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip install torchcam\n",
        "# OR\n",
        "!pip install captum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfQ6I5mK8W1n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "8kcpLxy6CGIQ"
      },
      "outputs": [],
      "source": [
        "from torchcam.methods import GradCAM\n",
        "from torchcam.utils import overlay_mask\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "cam_extractor = GradCAM(model, target_layer=\"ltb1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "sin1HsuxFsWI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "outputId": "e57460f8-e160-4b25-fc8e-72d0f0601062"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-538664511.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Extract CAM for the first image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mcam\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcam_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_class\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Automatically registers and removes hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Process image and heatmap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcam/methods/core.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, class_idx, scores, normalized, **kwargs)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0;31m# Compute CAM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_cams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     def compute_cams(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcam/methods/core.py\u001b[0m in \u001b[0;36mcompute_cams\u001b[0;34m(self, class_idx, scores, normalized, **kwargs)\u001b[0m\n\u001b[1;32m    191\u001b[0m         \"\"\"\n\u001b[1;32m    192\u001b[0m         \u001b[0;31m# Get map weight & unsqueeze it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0mcams\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcam/methods/gradient.py\u001b[0m in \u001b[0;36m_get_weights\u001b[0;34m(self, class_idx, scores, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;34m\"\"\"Computes the weight coefficients of the hooked activation maps.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# Backpropagate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backprop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhook_g\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# type: ignore[assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchcam/methods/gradient.py\u001b[0m in \u001b[0;36m_backprop\u001b[0;34m(self, scores, class_idx, retain_graph)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_idx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mList\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
          ]
        }
      ],
      "source": [
        "model.eval()\n",
        "\n",
        "# Select a sample from test loader\n",
        "inputs, targets = next(iter(test_loader))\n",
        "inputs = inputs.to(device)\n",
        "targets = targets.squeeze().long().to(device)\n",
        "\n",
        "# Forward pass and CAM extraction\n",
        "with torch.no_grad():\n",
        "    output = model(inputs)\n",
        "    pred_class = output.argmax(dim=1)\n",
        "\n",
        "# Extract CAM for the first image\n",
        "cam = cam_extractor(pred_class[0].item(), output)  # Automatically registers and removes hooks\n",
        "\n",
        "# Process image and heatmap\n",
        "input_image = inputs[0].cpu().squeeze().numpy()  # [D, H, W]\n",
        "slice_idx = input_image.shape[0] // 2\n",
        "slice_img = input_image[slice_idx]\n",
        "slice_cam = cam[0][slice_idx]\n",
        "\n",
        "# Normalize and overlay\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from torchcam.utils import overlay_mask\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "norm_slice = (slice_img - slice_img.min()) / (slice_img.max() - slice_img.min())\n",
        "norm_cam = (slice_cam - slice_cam.min()) / (slice_cam.max() - slice_cam.min())\n",
        "\n",
        "overlay = overlay_mask(to_pil_image(norm_slice), to_pil_image(norm_cam), alpha=0.6)\n",
        "\n",
        "plt.imshow(overlay)\n",
        "plt.title(f\"Grad-CAM (Pred: {pred_class[0].item()}, True: {targets[0].item()})\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 721
        },
        "id": "_zEnJK3uDlxo",
        "outputId": "5460ef49-4c0b-4c5f-832b-0fee572755cc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'target_class' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2979760078.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverlay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Grad-CAM Overlay (slice {slice_idx}) | Pred: {pred_class} | GT: {target_class}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"off\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'target_class' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from torchcam.methods import GradCAM\n",
        "from torchcam.utils import overlay_mask\n",
        "\n",
        "# === Setup ===\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.eval().to(device)\n",
        "\n",
        "# === Choose target layer for GradCAM ===\n",
        "target_layer = 'ltb3.conv.0'  # Change if needed\n",
        "cam_extractor = GradCAM(model, target_layer=target_layer)\n",
        "\n",
        "# === Load 1 test sample ===\n",
        "inputs, targets = next(iter(test_loader))\n",
        "input_tensor = inputs[0].unsqueeze(0).to(device)  # [1, 1, D, H, W]\n",
        "true_label = targets[0].item()\n",
        "\n",
        "# === Forward pass & CAM extraction ===\n",
        "with torch.set_grad_enabled(True):\n",
        "    scores = model(input_tensor)\n",
        "    pred_class = scores.argmax(dim=1).item()\n",
        "    cams = cam_extractor(pred_class, scores)  # list of CAMs\n",
        "\n",
        "# === Get the CAM tensor ===\n",
        "cam = cams[0]  # Could be [1, D, H, W] or [D, H, W]\n",
        "if cam.dim() == 3:\n",
        "    cam = cam.unsqueeze(0).unsqueeze(0)  # → [1, 1, D, H, W]\n",
        "elif cam.dim() == 4:\n",
        "    cam = cam.unsqueeze(0)               # → [1, 1, D, H, W]\n",
        "# Else: already fine\n",
        "\n",
        "# === Interpolate CAM to input shape ===\n",
        "target_shape = input_tensor.shape[2:]  # [D, H, W]\n",
        "cam_upsampled = F.interpolate(cam, size=target_shape, mode=\"trilinear\", align_corners=False)\n",
        "\n",
        "cam_volume = cam_upsampled.squeeze().cpu()  # [D, H, W]\n",
        "\n",
        "# === Get input volume ===\n",
        "input_volume = input_tensor.squeeze().cpu()  # [D, H, W]\n",
        "\n",
        "# === Pick a middle slice ===\n",
        "slice_idx = input_volume.shape[0] // 2\n",
        "input_slice = input_volume[slice_idx]  # [H, W]\n",
        "cam_slice = cam_volume[slice_idx]      # [H, W]\n",
        "\n",
        "# === Normalize both slices ===\n",
        "input_norm = (input_slice - input_slice.min()) / (input_slice.max() - input_slice.min() + 1e-6)\n",
        "cam_norm = (cam_slice - cam_slice.min()) / (cam_slice.max() - cam_slice.min() + 1e-6)\n",
        "\n",
        "# === Convert to PIL images ===\n",
        "input_pil = to_pil_image(input_slice)\n",
        "cam_pil = to_pil_image(cam_slice)\n",
        "\n",
        "# Convert grayscale input to RGB for overlay\n",
        "input_pil = input_pil.convert(\"RGB\")\n",
        "\n",
        "# === Overlay CAM ===\n",
        "overlay = overlay_mask(input_pil, cam_pil, alpha=0.5)\n",
        "\n",
        "# === Plot ===\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(overlay)\n",
        "plt.title(f\"Grad-CAM Overlay (slice {slice_idx}) | Pred: {pred_class} | GT: {target_class}\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "Y-eeHmrDD3N9",
        "outputId": "750b7b4f-ca84-41a6-c862-ace3df1ac6b5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from torchcam.methods import GradCAM\n",
        "from torchcam.utils import overlay_mask\n",
        "\n",
        "# === Prepare your model ===\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Choose a target layer name from your model — ltb3 is good\n",
        "target_layer = \"ltb3\"\n",
        "\n",
        "# Initialize GradCAM\n",
        "cam_extractor = GradCAM(model, target_layer=target_layer)\n",
        "\n",
        "# === Pick one test sample ===\n",
        "inputs, targets = next(iter(test_loader))\n",
        "inputs = inputs.to(device)\n",
        "input_tensor = inputs[0].unsqueeze(0)  # [1, C, D, H, W]\n",
        "target_class = targets[0].item()\n",
        "\n",
        "# === Forward pass and CAM generation ===\n",
        "output = model(input_tensor)\n",
        "pred_class = output.argmax(dim=1).item()\n",
        "\n",
        "# Generate CAM\n",
        "cams = cam_extractor(pred_class, output)\n",
        "cam = cams[0]\n",
        "\n",
        "if cam.dim() == 3:\n",
        "    cam = cam.unsqueeze(0).unsqueeze(0)  # → [1, 1, D, H, W]\n",
        "elif cam.dim() == 4:\n",
        "    cam = cam.unsqueeze(0)               # → [1, 1, D, H, W]\n",
        "# === Interpolate CAM to match input size ===\n",
        "target_shape = input_tensor.shape[2:]  # [D, H, W]\n",
        "cam_upsampled = F.interpolate(cam, size=target_shape, mode=\"trilinear\", align_corners=False)\n",
        "\n",
        "cam_volume = cam_upsampled.squeeze().cpu()  # [D, H, W]\n",
        "\n",
        "\n",
        "# === Normalize input volume ===\n",
        "input_volume = input_tensor.squeeze().cpu()  # [D, H, W]\n",
        "input_volume = (input_volume - input_volume.min()) / (input_volume.max() - input_volume.min())\n",
        "\n",
        "# === Choose center slice ===\n",
        "slice_idx = input_volume.shape[0] // 2\n",
        "input_slice = input_volume[slice_idx]  # [H, W]\n",
        "cam_slice = cam_volume[slice_idx]      # [H, W]\n",
        "\n",
        "# Normalize CAM slice\n",
        "cam_slice = (cam_slice - cam_slice.min()) / (cam_slice.max() - cam_slice.min())\n",
        "\n",
        "# Convert grayscale input to RGB for overlay\n",
        "input_pil = input_pil.convert(\"RGB\")\n",
        "\n",
        "# === Overlay CAM ===\n",
        "overlay = overlay_mask(input_pil, cam_pil, alpha=0.5)\n",
        "\n",
        "# === Plot result ===\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(overlay)\n",
        "plt.title(f\"Grad-CAM (target: {target_class}, pred: {pred_class})\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAxSMlFfBlU5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}