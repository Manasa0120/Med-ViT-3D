{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DjT5-WOnmhpY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1Zx4KxZQmpKh"
      },
      "outputs": [],
      "source": [
        "## limit the gpu using\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ASkrqPgZ0Yy5"
      },
      "outputs": [],
      "source": [
        "import kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "4g7vY2ae0Z0B"
      },
      "outputs": [],
      "source": [
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"paultimothymooney/chest-xray-pneumonia\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6fFt2I30cvQ",
        "outputId": "663b8273-e4b1-4a21-9860-0fcd4656345b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /kaggle/input/chest-xray-pneumonia\n"
          ]
        }
      ],
      "source": [
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cGS-9bZ1H7w",
        "outputId": "207400fb-4f6b-4c4c-ee49-9c9c9bffb6bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['chest_xray']"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.listdir(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "0xqjHH3P5Etg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4OyFo0Y2WC2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import kagglehub  # ensure this works for your kagglehub utility\n",
        "\n",
        "class DATALOAD:\n",
        "  def __init__(self, flagging, load_mode = \"keras\"):\n",
        "    self.flagging = flagging\n",
        "    self.load_mode = load_mode\n",
        "    self.mri = \"uraninjo/augmented-alzheimer-mri-dataset-v2\"\n",
        "    self.xray = \"paultimothymooney/chest-xray-pneumonia\"\n",
        "    self.data_dir = self.get_data_dir()\n",
        "    self.input_img_size = 224\n",
        "    self.batch_size = 10\n",
        "    self.train_ds, self.val_ds = self.load_data()\n",
        "\n",
        "  def get_data_dir(self):\n",
        "    if self.flagging == \"mri\":\n",
        "      path = kagglehub.dataset_download(self.mri)\n",
        "      path =  os.path.join(path, 'data')\n",
        "    else:\n",
        "      path = kagglehub.dataset_download(self.xray)\n",
        "      path= os.path.join(path, 'chest_xray')\n",
        "    return path\n",
        "\n",
        "  def data_load_keras(self, dir):\n",
        "    data = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "        dir,\n",
        "        image_size=(self.input_img_size, self.input_img_size),\n",
        "        batch_size =self.batch_size,\n",
        "        labels='inferred',\n",
        "        label_mode='categorical',  # for one-hot encoding; use 'int' if you prefer integers\n",
        "        shuffle=True,\n",
        "        seed=42)\n",
        "    return data\n",
        "\n",
        "  def data_load_pytorch(self, dir):\n",
        "     transform = transforms.Compose([\n",
        "            transforms.Grayscale(num_output_channels=3),  # ensure ResNet compatibility\n",
        "            transforms.Resize((self.input_img_size, self.input_img_size)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.5]*3, std=[0.5]*3)  # normalize for all 3 channels\n",
        "        ])\n",
        "     data = datasets.ImageFolder(dir, transform=transform)\n",
        "     loader = DataLoader(data, batch_size=self.batch_size, shuffle=True)\n",
        "     return loader\n",
        "\n",
        "  def load_data(self):\n",
        "    if self.load_mode == \"keras\":\n",
        "      train_ds = self.data_load_keras(self.data_dir + '/train')\n",
        "      val_ds = self.data_load_keras(self.data_dir + '/val')\n",
        "    else:\n",
        "      train_ds = self.data_load_pytorch(self.data_dir + '/train')\n",
        "      val_ds = self.data_load_pytorch(self.data_dir + '/val')\n",
        "    return train_ds, val_ds\n",
        "\n",
        "xu = DATALOAD(\"mri\", load_mode= \"pytorch\")\n",
        "xu.train_ds, xu.val_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXoz7rf-9H4n",
        "outputId": "2b21b1be-6e0a-40c1-ab0d-b109a643dbd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 33984 files belonging to 4 classes.\n",
            "Found 6400 files belonging to 4 classes.\n"
          ]
        }
      ],
      "source": [
        "xu = DATALOAD(\"mri\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cqOWtQJM9Lsa"
      },
      "outputs": [],
      "source": [
        "# xu.train_ds, xu.val_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gK0paM7198JF"
      },
      "outputs": [],
      "source": [
        "# xu = DATALOAD(\"xray\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0_x6yvcv-D1R"
      },
      "outputs": [],
      "source": [
        "# xu.train_ds, xu.val_ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "_VlSSZlj-Ft3"
      },
      "outputs": [],
      "source": [
        "# xu.train_ds.class_names"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
