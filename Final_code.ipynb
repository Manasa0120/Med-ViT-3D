{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2155d5e7"
      },
      "source": [
        "Now you can run the previous cell to import `torch` and `make_dot`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAI9r5x9Mjhw"
      },
      "source": [
        "Replicate original script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qe8mtlWoU9yI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "## reduce GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UFtychH7MlvN",
        "outputId": "49b9f6f9-e118-4442-b879-0fe8e5a4a09b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting medmnist==3.0.1\n",
            "  Downloading medmnist-3.0.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting torchattacks\n",
            "  Downloading torchattacks-3.5.1-py3-none-any.whl.metadata (927 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (11.3.0)\n",
            "Collecting fire (from medmnist==3.0.1)\n",
            "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (0.21.0+cu124)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from torchattacks) (1.16.1)\n",
            "Collecting requests~=2.25.1 (from torchattacks)\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting chardet<5,>=3.0.2 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting idna<3,>=2.5 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.25.1->torchattacks) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->medmnist==3.0.1) (1.3.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->medmnist==3.0.1) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist==3.0.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist==3.0.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist==3.0.1) (2025.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist==3.0.1) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist==3.0.1) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist==3.0.1) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist==3.0.1) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist==3.0.1) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist==3.0.1) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist==3.0.1) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->medmnist==3.0.1) (3.0.2)\n",
            "Downloading medmnist-3.0.1-py3-none-any.whl (25 kB)\n",
            "Downloading torchattacks-3.5.1-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m142.0/142.0 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m115.9/115.9 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: urllib3, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, idna, fire, chardet, requests, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchattacks, medmnist\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.25.1 which is incompatible.\n",
            "tweepy 4.16.0 requires requests<3,>=2.27.0, but you have requests 2.25.1 which is incompatible.\n",
            "google-genai 1.29.0 requires requests<3.0.0,>=2.28.1, but you have requests 2.25.1 which is incompatible.\n",
            "sphinx 8.2.3 requires requests>=2.30.0, but you have requests 2.25.1 which is incompatible.\n",
            "yfinance 0.2.65 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\n",
            "bigframes 2.15.0 requires requests>=2.27.1, but you have requests 2.25.1 which is incompatible.\n",
            "libpysal 4.13.0 requires requests>=2.27, but you have requests 2.25.1 which is incompatible.\n",
            "datasets 4.0.0 requires requests>=2.32.2, but you have requests 2.25.1 which is incompatible.\n",
            "tiktoken 0.11.0 requires requests>=2.26.0, but you have requests 2.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chardet-4.0.0 fire-0.7.1 idna-2.10 medmnist-3.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 requests-2.25.1 torchattacks-3.5.1 urllib3-1.26.20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "chardet",
                  "idna",
                  "nvidia",
                  "requests",
                  "urllib3"
                ]
              },
              "id": "2f4b1b72c0c6408eacb16b826c3a674f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install medmnist==3.0.1 \\\n",
        "    torchattacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_aD3CYXqM06G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.utils\n",
        "from torchvision import models\n",
        "import torchvision.datasets as dsets\n",
        "from torchsummary import summary\n",
        "\n",
        "from tqdm import tqdm\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "\n",
        "import torchattacks\n",
        "from torchattacks import PGD, FGSM\n",
        "from torch.utils.data import Subset, random_split, DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "import random\n",
        "import torch\n",
        "import pandas as pd\n",
        "from torchvision.transforms.transforms import Resize\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "## loading history\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "import pandas as pd\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CsEux3TNGoi",
        "outputId": "ce4ce138-b09b-419f-9501-fd7eb5d18a53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch 2.6.0+cu124\n",
            "Torchvision 0.21.0+cu124\n",
            "Torchattacks 3.5.1\n",
            "Numpy 2.0.2\n",
            "Medmnist 3.0.1\n"
          ]
        }
      ],
      "source": [
        "print(\"PyTorch\", torch.__version__)\n",
        "print(\"Torchvision\", torchvision.__version__)\n",
        "print(\"Torchattacks\", torchattacks.__version__)\n",
        "print(\"Numpy\", np.__version__)\n",
        "print(\"Medmnist\", medmnist.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### lower down sample: 1000 sample\n",
        "\n",
        "def med3dfulldata(DataClass):\n",
        "  transform = lambda x: torch.from_numpy(x).squeeze(1).float()\n",
        "  train_dataset = DataClass(split='train', transform=transform, download=True)\n",
        "  val_dataset = DataClass(split='val', transform=transform, download=True)\n",
        "  test_dataset = DataClass(split='test', transform=transform, download=True)\n",
        "\n",
        "  # encapsulate data into dataloader form\n",
        "  train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "  train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "  test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "  return train_loader, train_loader_at_eval, test_loader\n",
        "\n",
        "# --- Helper to create a single batch with all classes ---\n",
        "def get_one_batch_with_all_classes(dataset, num_classes, batch_size=32):\n",
        "    loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False)\n",
        "    all_inputs, all_targets = [], []\n",
        "    seen_classes = set()\n",
        "\n",
        "    for x, y in loader:\n",
        "        all_inputs.append(x)\n",
        "        all_targets.append(y)\n",
        "        seen_classes.update(y.squeeze().tolist())\n",
        "\n",
        "        if len(seen_classes) == num_classes:\n",
        "            all_inputs = torch.cat(all_inputs, dim=0)\n",
        "            all_targets = torch.cat(all_targets, dim=0)\n",
        "            return [(all_inputs, all_targets)]\n",
        "    raise ValueError(f\"Could not find all {num_classes} classes in the dataset.\")\n",
        "\n",
        "def data_input_loading(data_flag, BATCH_SIZE=15, lr=0.0005, NUM_EPOCHS=5, total_samples=1500, med3d = False):\n",
        "    download = True\n",
        "    info = INFO[data_flag]\n",
        "    task = info['task']\n",
        "    n_channels = info['n_channels']\n",
        "    n_classes = len(info['label'])\n",
        "    DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "    if med3d:\n",
        "      train_loader, train_loader_at_eval, test_loader = med3dfulldata(DataClass)\n",
        "    else:\n",
        "      # preprocessing\n",
        "      train_transform = transforms.Compose([\n",
        "          transforms.Resize(224),\n",
        "          transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "          torchvision.transforms.AugMix(),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(mean=[.5], std=[.5])\n",
        "      ])\n",
        "      test_transform = transforms.Compose([\n",
        "          transforms.Resize(224),\n",
        "          transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "          transforms.ToTensor(),\n",
        "          transforms.Normalize(mean=[.5], std=[.5])\n",
        "      ])\n",
        "\n",
        "      # Load full dataset first (train + test combined)\n",
        "      full_dataset = DataClass(split='train', transform=train_transform, download=download)\n",
        "      test_dataset_full = DataClass(split='test', transform=test_transform, download=download)\n",
        "      combined_dataset = torch.utils.data.ConcatDataset([full_dataset, test_dataset_full])\n",
        "\n",
        "      # Randomly select only total_samples items\n",
        "      if total_samples > len(combined_dataset):\n",
        "        total_samples = len(combined_dataset)\n",
        "      indices = random.sample(range(len(combined_dataset)), total_samples)\n",
        "      small_dataset = Subset(combined_dataset, indices)\n",
        "\n",
        "      # Split into train / val / test (e.g., 70/15/15 split)\n",
        "      train_size = int(0.7 * total_samples)\n",
        "      val_size = int(0.15 * total_samples)\n",
        "      test_size = total_samples - train_size - val_size\n",
        "      train_dataset, val_dataset, test_dataset = random_split(small_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "      # Dataloaders\n",
        "      train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "      train_loader_at_eval = get_one_batch_with_all_classes(train_dataset, n_classes, batch_size=2*BATCH_SIZE)\n",
        "      test_loader = get_one_batch_with_all_classes(test_dataset, n_classes, batch_size=2*BATCH_SIZE)\n",
        "\n",
        "    return data_flag, NUM_EPOCHS, BATCH_SIZE, lr, task, train_loader, train_loader_at_eval, test_loader, n_classes\n"
      ],
      "metadata": {
        "id": "nV9CLSzIewnI"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## loading model\n",
        "from MedVit3D import MedViT3D_small\n",
        "from MedViT import MedViT_small"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPMzgtGCkL23",
        "outputId": "f686af9c-33ea-4bc2-d409-e7b7ec45ed46"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def getPrecision(y_true, y_score, task, threshold=0.5):\n",
        "    y_true = y_true.squeeze()\n",
        "    y_score = y_score.squeeze()\n",
        "\n",
        "    if task == \"multi-label, binary-class\":\n",
        "        y_pred = (y_score > threshold).astype(int)\n",
        "        return precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    elif task == \"binary-class\":\n",
        "        if y_score.ndim == 2:\n",
        "            y_score = y_score[:, -1]\n",
        "        y_pred = (y_score > threshold).astype(int)\n",
        "        return precision_score(y_true, y_pred, average=\"binary\", zero_division=0)\n",
        "    else:\n",
        "        y_pred = np.argmax(y_score, axis=-1)\n",
        "        return precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "\n",
        "\n",
        "def getRecall(y_true, y_score, task, threshold=0.5):\n",
        "    y_true = y_true.squeeze()\n",
        "    y_score = y_score.squeeze()\n",
        "\n",
        "    if task == \"multi-label, binary-class\":\n",
        "        y_pred = (y_score > threshold).astype(int)\n",
        "        return recall_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    elif task == \"binary-class\":\n",
        "        if y_score.ndim == 2:\n",
        "            y_score = y_score[:, -1]\n",
        "        y_pred = (y_score > threshold).astype(int)\n",
        "        return recall_score(y_true, y_pred, average=\"binary\", zero_division=0)\n",
        "    else:\n",
        "        y_pred = np.argmax(y_score, axis=-1)\n",
        "        return recall_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "\n",
        "\n",
        "def getF1(y_true, y_score, task, threshold=0.5):\n",
        "    y_true = y_true.squeeze()\n",
        "    y_score = y_score.squeeze()\n",
        "\n",
        "    if task == \"multi-label, binary-class\":\n",
        "        y_pred = (y_score > threshold).astype(int)\n",
        "        return f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    elif task == \"binary-class\":\n",
        "        if y_score.ndim == 2:\n",
        "            y_score = y_score[:, -1]\n",
        "        y_pred = (y_score > threshold).astype(int)\n",
        "        return f1_score(y_true, y_pred, average=\"binary\", zero_division=0)\n",
        "    else:\n",
        "        y_pred = np.argmax(y_score, axis=-1)\n",
        "        return f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "\n",
        "#######################################################################\n",
        "\n",
        "# evaluation\n",
        "def getAUC(y_true, y_score, task):\n",
        "    \"\"\"AUC metric.\n",
        "    :param y_true: the ground truth labels, shape: (n_samples, n_labels) or (n_samples,) if n_labels==1\n",
        "    :param y_score: the predicted score of each class,\n",
        "    shape: (n_samples, n_labels) or (n_samples, n_classes) or (n_samples,) if n_labels==1 or n_classes==1\n",
        "    :param task: the task of current dataset\n",
        "    \"\"\"\n",
        "    y_true = y_true.squeeze()\n",
        "    y_score = y_score.squeeze()\n",
        "\n",
        "    if task == \"multi-label, binary-class\":\n",
        "        auc = 0\n",
        "        for i in range(y_score.shape[1]):\n",
        "            label_auc = roc_auc_score(y_true[:, i], y_score[:, i])\n",
        "            auc += label_auc\n",
        "        ret = auc / y_score.shape[1]\n",
        "    elif task == \"binary-class\":\n",
        "        if y_score.ndim == 2:\n",
        "            y_score = y_score[:, -1]\n",
        "        else:\n",
        "            assert y_score.ndim == 1\n",
        "        ret = roc_auc_score(y_true, y_score)\n",
        "    else:\n",
        "        auc = 0\n",
        "        for i in range(y_score.shape[1]):\n",
        "            y_true_binary = (y_true == i).astype(float)\n",
        "            y_score_binary = y_score[:, i]\n",
        "            auc += roc_auc_score(y_true_binary, y_score_binary)\n",
        "        ret = auc / y_score.shape[1]\n",
        "\n",
        "    return ret\n",
        "\n",
        "\n",
        "def getACC(y_true, y_score, task, threshold=0.5):\n",
        "    \"\"\"Accuracy metric.\n",
        "    :param y_true: the ground truth labels, shape: (n_samples, n_labels) or (n_samples,) if n_labels==1\n",
        "    :param y_score: the predicted score of each class,\n",
        "    shape: (n_samples, n_labels) or (n_samples, n_classes) or (n_samples,) if n_labels==1 or n_classes==1\n",
        "    :param task: the task of current dataset\n",
        "    :param threshold: the threshold for multilabel and binary-class tasks\n",
        "    \"\"\"\n",
        "    y_true = y_true.squeeze()\n",
        "    y_score = y_score.squeeze()\n",
        "\n",
        "    if task == \"multi-label, binary-class\":\n",
        "        y_pre = y_score > threshold\n",
        "        acc = 0\n",
        "        for label in range(y_true.shape[1]):\n",
        "            label_acc = accuracy_score(y_true[:, label], y_pre[:, label])\n",
        "            acc += label_acc\n",
        "        ret = acc / y_true.shape[1]\n",
        "    elif task == \"binary-class\":\n",
        "        if y_score.ndim == 2:\n",
        "            y_score = y_score[:, -1]\n",
        "        else:\n",
        "            assert y_score.ndim == 1\n",
        "        ret = accuracy_score(y_true, y_score > threshold)\n",
        "    else:\n",
        "        ret = accuracy_score(y_true, np.argmax(y_score, axis=-1))\n",
        "\n",
        "    return ret\n",
        "\n",
        "def test(data_loader, model, criterion, task):\n",
        "    model.eval()\n",
        "    y_true = torch.tensor([]).to(device)\n",
        "    y_score = torch.tensor([]).to(device)\n",
        "    data_loader = data_loader\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            if task == 'multi-label, binary-class':\n",
        "                targets = targets.to(torch.float32)\n",
        "                loss = criterion(outputs, targets)\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "            else:\n",
        "                targets = targets.squeeze().long()\n",
        "                loss = criterion(outputs, targets)\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "                targets = targets.float().resize_(len(targets), 1)\n",
        "\n",
        "            y_true = torch.cat((y_true, targets), 0)\n",
        "            y_score = torch.cat((y_score, outputs), 0)\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "        y_true = y_true.cpu().numpy()\n",
        "        y_score = y_score.detach().cpu().numpy()\n",
        "\n",
        "        auc = getAUC(y_true, y_score, task)\n",
        "        acc = getACC(y_true, y_score, task)\n",
        "        avg_loss = total_loss / num_batches\n",
        "        ########################################################################################\n",
        "        precision = getPrecision(y_true, y_score, task)\n",
        "        recall = getRecall(y_true, y_score, task)\n",
        "        f1 = getF1(y_true, y_score, task)\n",
        "\n",
        "        return auc, acc ,avg_loss, precision, recall, f1 #, y_true, y_score\n",
        "\n",
        "\n",
        "def load_or_initialize_model(model_class, model_name, optimizer_class, lr, momentum, n_classes, task):\n",
        "    model_dir = \"./history_record\"\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    model_path = os.path.join(model_dir, f\"{model_name}.pth\")\n",
        "    history_path = os.path.join(model_dir, f\"{model_name}.csv\")\n",
        "\n",
        "    if \"3d\" in model_name.lower():\n",
        "      model = MedViT3D_small(num_classes = n_classes).to(device)\n",
        "    else:\n",
        "      model = MedViT_small(num_classes = n_classes).to(device)\n",
        "\n",
        "    optimizer = optimizer_class(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "    start_epoch = 0\n",
        "    best_val_auc = 0\n",
        "    history = {\n",
        "        \"train_auc\": [], \"train_acc\": [],\"train_precision\": [], \"train_recall\": [], \"train_f1\": [],\n",
        "        \"val_auc\": [], \"val_acc\": [],\"val_precision\": [], \"val_recall\": [], \"val_f1\": [],\n",
        "        \"train_loss\": [], \"val_loss\": [],\n",
        "        \"epoch_time\": []\n",
        "    }\n",
        "\n",
        "    if os.path.exists(model_path) and os.path.exists(history_path):\n",
        "        print(f\"Loading existing model: {model_name}\")\n",
        "        checkpoint = torch.load(model_path, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        history = pd.read_csv(history_path).to_dict(orient='list')\n",
        "        start_epoch = len(history[\"train_loss\"])\n",
        "        best_val_auc = max(history[\"val_auc\"]) if history[\"val_auc\"] else 0\n",
        "\n",
        "    return model, optimizer, history, start_epoch, best_val_auc\n",
        "def training_and_record(model_class,\n",
        "                        model_name,\n",
        "                        NUM_EPOCHS, lr,\n",
        "                        momentum, train_loader,\n",
        "                        train_loader_at_eval,\n",
        "                        test_loader,\n",
        "                        n_classes,\n",
        "                        task,\n",
        "                        steps):\n",
        "    model, optimizer, history, start_epoch, best_val_auc = load_or_initialize_model(\n",
        "        model_class, model_name, optimizer_class=torch.optim.SGD, lr=lr, momentum=momentum, n_classes = n_classes,\n",
        "        task = task\n",
        "    )\n",
        "    if task == \"multi-label, binary-class\":\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    total_loss = 0\n",
        "    step_count = 0  # counter for batch steps\n",
        "    for epoch in range(start_epoch, start_epoch + NUM_EPOCHS):\n",
        "        print(f'\\nEpoch [{epoch + 1}/{start_epoch + NUM_EPOCHS}]')\n",
        "        start_time = time.time()\n",
        "        model.train()\n",
        "\n",
        "        for inputs, targets in tqdm(train_loader):\n",
        "            step_count += 1\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            unique_classes = np.unique(targets.cpu().numpy())\n",
        "            # print(f\"Unique class in target data batch is: {unique_classes.tolist()}  | Count: {len(unique_classes)}\")\n",
        "            if task == 'multi-label, binary-class':\n",
        "                # print(\"Going to multi-label, bunary-class branch\")\n",
        "                # Ensure targets become [B, n_classes] float\n",
        "                targets = torch.nn.functional.one_hot(\n",
        "                    targets.squeeze().long(), num_classes=n_classes\n",
        "                ).float().to(device)\n",
        "                # print(\"target shape of original data before loss \", targets.shape)\n",
        "                # print(\"output shape after model, before loss: \", outputs.shape)\n",
        "                loss = criterion(outputs, targets)\n",
        "            else:\n",
        "                # print(\"going to ther branch\")\n",
        "                targets = targets.squeeze().long()  # labels become long\n",
        "                # print(\"target shape of original data before loss \", targets.shape)\n",
        "                # print(\"output shape after model, before loss: \", outputs.shape)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            # stop after 20 steps per epoch\n",
        "            # if step_count >= steps:\n",
        "            #     print(f\"Breaking after {step_count} steps in this epoch.\")\n",
        "            #     break\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Logging\n",
        "        train_loss = total_loss / len(train_loader)\n",
        "        # validation loss:  auc, acc ,avg_loss, precision, recall, f1\n",
        "        val_auc, val_acc, val_loss, val_prec, val_rec, val_f1 = test(test_loader, model, criterion, task)\n",
        "        # train loss\n",
        "        train_auc, train_acc, train_loss, train_prec, train_rec, train_f1 = test( train_loader_at_eval, model, criterion, task)\n",
        "\n",
        "\n",
        "        history[\"train_auc\"].append(train_auc)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"train_precision\"].append(train_prec)\n",
        "        history[\"train_recall\"].append(train_rec)\n",
        "        history[\"train_f1\"].append(train_f1)\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "\n",
        "        history[\"val_auc\"].append(val_auc)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "        history[\"val_precision\"].append(val_prec)\n",
        "        history[\"val_recall\"].append(val_rec)\n",
        "        history[\"val_f1\"].append(val_f1)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "\n",
        "        # Log epoch time\n",
        "        epoch_time = time.time() - start_time\n",
        "        history[\"epoch_time\"].append(epoch_time)\n",
        "        print(f\"Epoch {epoch+1} finished in {epoch_time:.2f} seconds\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "            print(\"ğŸ“Œ New best AUC â€” saving model\")\n",
        "            torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict()\n",
        "            }, f\"./history_record/{model_name}.pth\")\n",
        "\n",
        "        pd.DataFrame(history).to_csv(f\"./history_record/{model_name}.csv\", index=False)\n",
        "\n",
        "    print(\"âœ… Training complete.\")\n",
        "    return history\n",
        "\n"
      ],
      "metadata": {
        "id": "t6WY6oNAk-G7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M1G5tgAOExo8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Define same parameters\n",
        "NUM_EPOCHS = 20\n",
        "BATCH_SIZE = 20\n",
        "lr = 0.0005\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "WbPIK-D50tZa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cOBufE9F-il8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "YYMNuK9o2a2B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b232bd5-7618-4b70-eeb6-a00a2da16f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [1/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:02<00:00, 20.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished in 4.00 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [2/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:02<00:00, 20.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 finished in 3.96 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [3/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:02<00:00, 20.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 finished in 3.92 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [4/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:02<00:00, 20.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 finished in 3.93 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [5/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:02<00:00, 20.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 finished in 4.04 seconds\n",
            "\n",
            "Epoch [6/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:02<00:00, 20.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 finished in 3.98 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [7/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:02<00:00, 20.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 finished in 3.99 seconds\n",
            "\n",
            "Epoch [8/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:02<00:00, 20.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 finished in 4.06 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [9/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:02<00:00, 20.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 finished in 3.99 seconds\n",
            "\n",
            "Epoch [10/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:02<00:00, 20.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 finished in 3.97 seconds\n",
            "\n",
            "Epoch [11/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:02<00:00, 20.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 finished in 4.03 seconds\n",
            "\n",
            "Epoch [12/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:02<00:00, 20.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 finished in 3.95 seconds\n",
            "\n",
            "Epoch [13/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:02<00:00, 20.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 finished in 3.95 seconds\n",
            "\n",
            "Epoch [14/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:02<00:00, 20.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 finished in 3.97 seconds\n",
            "\n",
            "Epoch [15/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:02<00:00, 20.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 finished in 3.94 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [16/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:02<00:00, 20.99it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 finished in 3.91 seconds\n",
            "\n",
            "Epoch [17/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:02<00:00, 21.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 finished in 3.93 seconds\n",
            "\n",
            "Epoch [18/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:02<00:00, 20.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 finished in 3.93 seconds\n",
            "\n",
            "Epoch [19/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:02<00:00, 21.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 finished in 3.91 seconds\n",
            "\n",
            "Epoch [20/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 58/58 [00:02<00:00, 21.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 finished in 3.90 seconds\n",
            "âœ… Training complete.\n"
          ]
        }
      ],
      "source": [
        "data_flag = \"nodulemnist3d\"\n",
        "med3d = True\n",
        "model_name = f\"MedViT3D_{data_flag}\"\n",
        "## loading data\n",
        "(data_flag,\n",
        " NUM_EPOCHS,\n",
        " BATCH_SIZE,\n",
        " lr,\n",
        " task,\n",
        " train_loader,\n",
        " train_loader_at_eval,\n",
        " test_loader,\n",
        " n_classes) = data_input_loading(data_flag=data_flag,\n",
        "                                NUM_EPOCHS = NUM_EPOCHS,\n",
        "                                BATCH_SIZE=BATCH_SIZE,\n",
        "                                lr=lr,\n",
        "                                med3d= med3d)\n",
        "## train and record\n",
        "history = training_and_record(\n",
        "    model_class=MedViT3D_small,\n",
        "    model_name= model_name,\n",
        "    NUM_EPOCHS=NUM_EPOCHS,\n",
        "    lr=lr,\n",
        "    momentum=0.9,\n",
        "    train_loader=train_loader,\n",
        "    train_loader_at_eval=train_loader_at_eval,\n",
        "    test_loader=test_loader,\n",
        "    n_classes = n_classes,\n",
        "    task = task,\n",
        "    steps = len(train_loader)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x1xn9Rf1LZZi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RWBAzW43K8Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32cdef97-d226-4cc5-f50c-e1e2989264ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 32.7M/32.7M [00:01<00:00, 16.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [1/2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [02:00<00:00,  1.85s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished in 174.52 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [2/2]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 65/65 [01:58<00:00,  1.82s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 finished in 171.04 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "âœ… Training complete.\n"
          ]
        }
      ],
      "source": [
        "data_flag = \"organmnist3d\"\n",
        "med3d = True\n",
        "model_name = f\"MedViT3D_{data_flag}\"\n",
        "## loading data\n",
        "(data_flag,\n",
        " NUM_EPOCHS,\n",
        " BATCH_SIZE,\n",
        " lr,\n",
        " task,\n",
        " train_loader,\n",
        " train_loader_at_eval,\n",
        " test_loader,\n",
        " n_classes) = data_input_loading(data_flag=data_flag,\n",
        "                                NUM_EPOCHS = NUM_EPOCHS,\n",
        "                                BATCH_SIZE=BATCH_SIZE,\n",
        "                                lr=lr,\n",
        "                                med3d= med3d)\n",
        "## train and record\n",
        "history = training_and_record(\n",
        "    model_class=MedViT3D_small,\n",
        "    model_name= model_name,\n",
        "    NUM_EPOCHS=NUM_EPOCHS,\n",
        "    lr=lr,\n",
        "    momentum=0.9,\n",
        "    train_loader=train_loader,\n",
        "    train_loader_at_eval=train_loader_at_eval,\n",
        "    test_loader=test_loader,\n",
        "    n_classes = n_classes,\n",
        "    task = task,\n",
        "    steps = len(train_loader)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_flag = \"adrenalmnist3d\"\n",
        "med3d = True\n",
        "model_name = f\"MedViT3D_{data_flag}\"\n",
        "## loading data\n",
        "(data_flag,\n",
        " NUM_EPOCHS,\n",
        " BATCH_SIZE,\n",
        " lr,\n",
        " task,\n",
        " train_loader,\n",
        " train_loader_at_eval,\n",
        " test_loader,\n",
        " n_classes) = data_input_loading(data_flag=data_flag,\n",
        "                                NUM_EPOCHS = NUM_EPOCHS,\n",
        "                                BATCH_SIZE=BATCH_SIZE,\n",
        "                                lr=lr,\n",
        "                                med3d= med3d)\n",
        "## train and record\n",
        "history = training_and_record(\n",
        "    model_class=MedViT3D_small,\n",
        "    model_name= model_name,\n",
        "    NUM_EPOCHS=NUM_EPOCHS,\n",
        "    lr=lr,\n",
        "    momentum=0.9,\n",
        "    train_loader=train_loader,\n",
        "    train_loader_at_eval=train_loader_at_eval,\n",
        "    test_loader=test_loader,\n",
        "    n_classes = n_classes,\n",
        "    task = task,\n",
        "    steps = len(train_loader)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zA_RtXtVAI7h",
        "outputId": "59419713-e40e-43f1-a99b-1b678eadb747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 277k/277k [00:00<00:00, 391kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [1/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:02<00:00, 27.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished in 3.91 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [2/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:02<00:00, 28.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 finished in 3.86 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [3/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:02<00:00, 30.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 finished in 3.62 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [4/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:02<00:00, 30.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 finished in 3.63 seconds\n",
            "\n",
            "Epoch [5/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:02<00:00, 29.96it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 finished in 3.73 seconds\n",
            "\n",
            "Epoch [6/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:02<00:00, 30.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 finished in 3.65 seconds\n",
            "\n",
            "Epoch [7/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:02<00:00, 29.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 finished in 3.72 seconds\n",
            "\n",
            "Epoch [8/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:02<00:00, 30.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 finished in 3.68 seconds\n",
            "\n",
            "Epoch [9/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:02<00:00, 29.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 finished in 3.72 seconds\n",
            "\n",
            "Epoch [10/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:02<00:00, 30.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 finished in 3.66 seconds\n",
            "\n",
            "Epoch [11/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:02<00:00, 29.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 finished in 3.77 seconds\n",
            "\n",
            "Epoch [12/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:02<00:00, 29.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 finished in 3.78 seconds\n",
            "\n",
            "Epoch [13/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:02<00:00, 29.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 finished in 3.68 seconds\n",
            "\n",
            "Epoch [14/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:02<00:00, 29.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 finished in 3.71 seconds\n",
            "\n",
            "Epoch [15/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:02<00:00, 29.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 finished in 3.87 seconds\n",
            "\n",
            "Epoch [16/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:02<00:00, 28.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 finished in 3.82 seconds\n",
            "\n",
            "Epoch [17/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:02<00:00, 29.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 finished in 3.92 seconds\n",
            "\n",
            "Epoch [18/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:03<00:00, 25.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 finished in 4.17 seconds\n",
            "\n",
            "Epoch [19/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:02<00:00, 29.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 finished in 3.82 seconds\n",
            "\n",
            "Epoch [20/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:02<00:00, 29.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 finished in 3.76 seconds\n",
            "âœ… Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_flag = \"fracturemnist3d\"\n",
        "med3d = True\n",
        "model_name = f\"MedViT3D_{data_flag}\"\n",
        "## loading data\n",
        "(data_flag,\n",
        " NUM_EPOCHS,\n",
        " BATCH_SIZE,\n",
        " lr,\n",
        " task,\n",
        " train_loader,\n",
        " train_loader_at_eval,\n",
        " test_loader,\n",
        " n_classes) = data_input_loading(data_flag=data_flag,\n",
        "                                NUM_EPOCHS = NUM_EPOCHS,\n",
        "                                BATCH_SIZE=BATCH_SIZE,\n",
        "                                lr=lr,\n",
        "                                med3d= med3d)\n",
        "## train and record\n",
        "history = training_and_record(\n",
        "    model_class=MedViT3D_small,\n",
        "    model_name= model_name,\n",
        "    NUM_EPOCHS=NUM_EPOCHS,\n",
        "    lr=lr,\n",
        "    momentum=0.9,\n",
        "    train_loader=train_loader,\n",
        "    train_loader_at_eval=train_loader_at_eval,\n",
        "    test_loader=test_loader,\n",
        "    n_classes = n_classes,\n",
        "    task = task,\n",
        "    steps = len(train_loader)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llE092tkA1L-",
        "outputId": "7a663a6e-d20c-4f94-98d5-1f90d4b4b663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.28M/3.28M [00:01<00:00, 2.76MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [1/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 28.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished in 3.31 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [2/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 30.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 finished in 3.13 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [3/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 30.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 finished in 3.14 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [4/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 29.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 finished in 3.24 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [5/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 29.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 finished in 3.19 seconds\n",
            "\n",
            "Epoch [6/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 30.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 finished in 3.14 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [7/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 30.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 finished in 3.15 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [8/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 29.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 finished in 3.27 seconds\n",
            "\n",
            "Epoch [9/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 28.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 finished in 3.31 seconds\n",
            "\n",
            "Epoch [10/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 30.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 finished in 3.15 seconds\n",
            "\n",
            "Epoch [11/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 30.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 finished in 3.18 seconds\n",
            "\n",
            "Epoch [12/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 29.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 finished in 3.25 seconds\n",
            "\n",
            "Epoch [13/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 29.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 finished in 3.19 seconds\n",
            "\n",
            "Epoch [14/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 29.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 finished in 3.31 seconds\n",
            "\n",
            "Epoch [15/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 29.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 finished in 3.19 seconds\n",
            "\n",
            "Epoch [16/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 28.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 finished in 3.28 seconds\n",
            "\n",
            "Epoch [17/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 29.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 finished in 3.20 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [18/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 29.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 finished in 3.18 seconds\n",
            "\n",
            "Epoch [19/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 29.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 finished in 3.27 seconds\n",
            "\n",
            "Epoch [20/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 69/69 [00:02<00:00, 27.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 finished in 3.41 seconds\n",
            "âœ… Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_flag = \"vesselmnist3d\"\n",
        "med3d = True\n",
        "model_name = f\"MedViT3D_{data_flag}\"\n",
        "## loading data\n",
        "(data_flag,\n",
        " NUM_EPOCHS,\n",
        " BATCH_SIZE,\n",
        " lr,\n",
        " task,\n",
        " train_loader,\n",
        " train_loader_at_eval,\n",
        " test_loader,\n",
        " n_classes) = data_input_loading(data_flag=data_flag,\n",
        "                                NUM_EPOCHS = NUM_EPOCHS,\n",
        "                                BATCH_SIZE=BATCH_SIZE,\n",
        "                                lr=lr,\n",
        "                                med3d= med3d)\n",
        "## train and record\n",
        "history = training_and_record(\n",
        "    model_class=MedViT3D_small,\n",
        "    model_name= model_name,\n",
        "    NUM_EPOCHS=NUM_EPOCHS,\n",
        "    lr=lr,\n",
        "    momentum=0.9,\n",
        "    train_loader=train_loader,\n",
        "    train_loader_at_eval=train_loader_at_eval,\n",
        "    test_loader=test_loader,\n",
        "    n_classes = n_classes,\n",
        "    task = task,\n",
        "    steps = len(train_loader)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMaea8SBBnqk",
        "outputId": "53f3941a-dd0b-4cdf-edfd-aa0d9260efff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 398k/398k [00:00<00:00, 467kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [1/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:03<00:00, 28.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished in 4.29 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [2/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:02<00:00, 30.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 finished in 4.12 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [3/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:02<00:00, 30.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 finished in 4.09 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [4/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:02<00:00, 30.09it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 finished in 4.15 seconds\n",
            "\n",
            "Epoch [5/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:03<00:00, 28.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 finished in 4.26 seconds\n",
            "\n",
            "Epoch [6/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:02<00:00, 30.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 finished in 4.11 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [7/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:02<00:00, 30.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 finished in 4.15 seconds\n",
            "\n",
            "Epoch [8/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:03<00:00, 29.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 finished in 4.25 seconds\n",
            "\n",
            "Epoch [9/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:02<00:00, 29.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 finished in 4.18 seconds\n",
            "\n",
            "Epoch [10/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:03<00:00, 29.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 finished in 4.19 seconds\n",
            "\n",
            "Epoch [11/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:03<00:00, 29.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 finished in 4.22 seconds\n",
            "\n",
            "Epoch [12/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:03<00:00, 29.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 finished in 4.27 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [13/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:03<00:00, 27.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 finished in 4.84 seconds\n",
            "\n",
            "Epoch [14/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:03<00:00, 29.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 finished in 4.18 seconds\n",
            "\n",
            "Epoch [15/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:03<00:00, 29.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 finished in 4.19 seconds\n",
            "\n",
            "Epoch [16/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:03<00:00, 28.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 finished in 4.40 seconds\n",
            "\n",
            "Epoch [17/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:03<00:00, 28.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 finished in 4.58 seconds\n",
            "\n",
            "Epoch [18/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:03<00:00, 29.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 finished in 4.20 seconds\n",
            "\n",
            "Epoch [19/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:03<00:00, 28.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 finished in 4.33 seconds\n",
            "\n",
            "Epoch [20/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [00:03<00:00, 28.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 finished in 4.29 seconds\n",
            "âœ… Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_flag = \"synapsemnist3d\"\n",
        "med3d = True\n",
        "model_name = f\"MedViT3D_{data_flag}\"\n",
        "## loading data\n",
        "(data_flag,\n",
        " NUM_EPOCHS,\n",
        " BATCH_SIZE,\n",
        " lr,\n",
        " task,\n",
        " train_loader,\n",
        " train_loader_at_eval,\n",
        " test_loader,\n",
        " n_classes) = data_input_loading(data_flag=data_flag,\n",
        "                                NUM_EPOCHS = NUM_EPOCHS,\n",
        "                                BATCH_SIZE=BATCH_SIZE,\n",
        "                                lr=lr,\n",
        "                                med3d= med3d)\n",
        "## train and record\n",
        "history = training_and_record(\n",
        "    model_class=MedViT3D_small,\n",
        "    model_name= model_name,\n",
        "    NUM_EPOCHS=NUM_EPOCHS,\n",
        "    lr=lr,\n",
        "    momentum=0.9,\n",
        "    train_loader=train_loader,\n",
        "    train_loader_at_eval=train_loader_at_eval,\n",
        "    test_loader=test_loader,\n",
        "    n_classes = n_classes,\n",
        "    task = task,\n",
        "    steps = len(train_loader)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pvtVnHS-CPPV",
        "outputId": "d7e3eb9d-8754-4170-86a6-78493c192014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38.0M/38.0M [00:03<00:00, 10.7MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [1/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:02<00:00, 28.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished in 4.00 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [2/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:02<00:00, 30.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 finished in 3.81 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [3/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:02<00:00, 30.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 finished in 3.82 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [4/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:02<00:00, 29.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 finished in 3.97 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [5/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:02<00:00, 29.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 finished in 3.89 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [6/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:02<00:00, 29.73it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 finished in 3.84 seconds\n",
            "\n",
            "Epoch [7/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:02<00:00, 29.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 finished in 3.93 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [8/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:02<00:00, 29.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 finished in 3.88 seconds\n",
            "\n",
            "Epoch [9/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:02<00:00, 28.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 finished in 3.95 seconds\n",
            "\n",
            "Epoch [10/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:02<00:00, 29.32it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 finished in 3.89 seconds\n",
            "\n",
            "Epoch [11/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:02<00:00, 29.07it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 finished in 3.90 seconds\n",
            "\n",
            "Epoch [12/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:02<00:00, 29.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 finished in 3.86 seconds\n",
            "\n",
            "Epoch [13/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:02<00:00, 29.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 finished in 3.89 seconds\n",
            "\n",
            "Epoch [14/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:02<00:00, 28.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 finished in 3.95 seconds\n",
            "\n",
            "Epoch [15/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:02<00:00, 29.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 finished in 3.91 seconds\n",
            "\n",
            "Epoch [16/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:02<00:00, 29.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 finished in 3.95 seconds\n",
            "\n",
            "Epoch [17/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:02<00:00, 28.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 finished in 4.00 seconds\n",
            "\n",
            "Epoch [18/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:02<00:00, 28.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 finished in 3.95 seconds\n",
            "\n",
            "Epoch [19/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:02<00:00, 29.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 finished in 3.94 seconds\n",
            "\n",
            "Epoch [20/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82/82 [00:02<00:00, 28.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 finished in 3.98 seconds\n",
            "âœ… Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " MedVit2D"
      ],
      "metadata": {
        "id": "S5qNBKRmsoTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # [tissuemnist, pathmnist, dermamnist, octmnist,\n",
        "# # pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "data_flag = \"dermamnist\"\n",
        "med3d = False\n",
        "model_name = f\"MedViT2D_{data_flag}\"\n",
        "(data_flag,\n",
        " NUM_EPOCHS,\n",
        " BATCH_SIZE,\n",
        " lr,\n",
        " task,\n",
        " train_loader,\n",
        " train_loader_at_eval,\n",
        " test_loader,\n",
        " n_classes) = data_input_loading(data_flag=data_flag,\n",
        "                                 med3d = False,\n",
        "                                 NUM_EPOCHS = NUM_EPOCHS,\n",
        "                                 BATCH_SIZE=BATCH_SIZE,\n",
        "                                 lr=lr)\n",
        "#print(n_classes)\n",
        "history = training_and_record(\n",
        "    model_class=MedViT_small,\n",
        "    model_name= model_name,\n",
        "    NUM_EPOCHS=NUM_EPOCHS,\n",
        "    lr=lr,\n",
        "    momentum=0.9,\n",
        "    train_loader=train_loader,\n",
        "    train_loader_at_eval=train_loader_at_eval,\n",
        "    test_loader=test_loader,\n",
        "    n_classes = n_classes,\n",
        "    task = task,\n",
        "    steps = len(train_loader)\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qlC7BLPwsnka",
        "outputId": "d3088bdb-5f0b-4e60-b4ae-f815111f6379"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.7M/19.7M [00:00<00:00, 45.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "\n",
            "Epoch [1/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:43<00:00,  1.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished in 48.03 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [2/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:42<00:00,  1.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 finished in 46.96 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [3/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:41<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 finished in 46.01 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [4/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:42<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 finished in 46.39 seconds\n",
            "\n",
            "Epoch [5/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:41<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 finished in 46.05 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [6/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:41<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 finished in 46.08 seconds\n",
            "\n",
            "Epoch [7/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:41<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 finished in 45.96 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [8/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:41<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 finished in 46.13 seconds\n",
            "\n",
            "Epoch [9/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:42<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 finished in 46.28 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [10/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:42<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 finished in 46.21 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [11/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:41<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 finished in 46.02 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [12/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:42<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 finished in 46.32 seconds\n",
            "\n",
            "Epoch [13/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:41<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 finished in 46.16 seconds\n",
            "\n",
            "Epoch [14/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:41<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 finished in 46.09 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [15/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:41<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 finished in 46.11 seconds\n",
            "\n",
            "Epoch [16/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:41<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 finished in 45.80 seconds\n",
            "\n",
            "Epoch [17/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:41<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 finished in 45.86 seconds\n",
            "\n",
            "Epoch [18/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:41<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 finished in 45.96 seconds\n",
            "\n",
            "Epoch [19/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:41<00:00,  1.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 finished in 46.11 seconds\n",
            "\n",
            "Epoch [20/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 53/53 [00:41<00:00,  1.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 finished in 46.07 seconds\n",
            "âœ… Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # [tissuemnist, pathmnist, dermamnist, octmnist,\n",
        "# # pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "data_flag = \"tissuemnist\"\n",
        "med3d = False\n",
        "model_name = f\"MedViT2D_{data_flag}\"\n",
        "(data_flag,\n",
        " NUM_EPOCHS,\n",
        " BATCH_SIZE,\n",
        " lr,\n",
        " task,\n",
        " train_loader,\n",
        " train_loader_at_eval,\n",
        " test_loader,\n",
        " n_classes) = data_input_loading(data_flag=data_flag,\n",
        "                                 med3d = False,\n",
        "                                 NUM_EPOCHS = NUM_EPOCHS,\n",
        "                                 BATCH_SIZE=BATCH_SIZE,\n",
        "                                 lr=lr)\n",
        "\n",
        "history = training_and_record(\n",
        "    model_class=MedViT_small,\n",
        "    model_name= model_name,\n",
        "    NUM_EPOCHS=NUM_EPOCHS,\n",
        "    lr=lr,\n",
        "    momentum=0.9,\n",
        "    train_loader=train_loader,\n",
        "    train_loader_at_eval=train_loader_at_eval,\n",
        "    test_loader=test_loader,\n",
        "    n_classes = n_classes,\n",
        "    task = task,\n",
        "    steps = len(train_loader)\n",
        ")\n"
      ],
      "metadata": {
        "id": "oNE3p63bsnev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfdc4a7b-d0eb-44f2-b3fc-09e08c256502"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 125M/125M [03:16<00:00, 637kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "\n",
            "Epoch [1/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished in 46.15 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [2/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:44<00:00,  1.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 finished in 45.93 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [3/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 finished in 46.51 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [4/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 finished in 46.35 seconds\n",
            "\n",
            "Epoch [5/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 finished in 46.71 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [6/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 finished in 46.81 seconds\n",
            "\n",
            "Epoch [7/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 finished in 46.55 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [8/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 finished in 46.55 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [9/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 finished in 46.73 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [10/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 finished in 46.49 seconds\n",
            "\n",
            "Epoch [11/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 finished in 46.73 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [12/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 finished in 46.60 seconds\n",
            "\n",
            "Epoch [13/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 finished in 46.79 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [14/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:46<00:00,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 finished in 47.02 seconds\n",
            "\n",
            "Epoch [15/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 finished in 46.61 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [16/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 finished in 46.87 seconds\n",
            "\n",
            "Epoch [17/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 finished in 46.80 seconds\n",
            "\n",
            "Epoch [18/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 finished in 46.93 seconds\n",
            "\n",
            "Epoch [19/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 finished in 46.61 seconds\n",
            "\n",
            "Epoch [20/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 finished in 46.82 seconds\n",
            "âœ… Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # [tissuemnist, pathmnist, dermamnist, octmnist,\n",
        "# # pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "data_flag = \"pathmnist\"\n",
        "med3d = False\n",
        "model_name = f\"MedViT2D_{data_flag}\"\n",
        "(data_flag,\n",
        " NUM_EPOCHS,\n",
        " BATCH_SIZE,\n",
        " lr,\n",
        " task,\n",
        " train_loader,\n",
        " train_loader_at_eval,\n",
        " test_loader,\n",
        " n_classes) = data_input_loading(data_flag=data_flag,\n",
        "                                 med3d = False,\n",
        "                                 NUM_EPOCHS = NUM_EPOCHS,\n",
        "                                 BATCH_SIZE=BATCH_SIZE,\n",
        "                                 lr=lr)\n",
        "\n",
        "history = training_and_record(\n",
        "    model_class=MedViT_small,\n",
        "    model_name= model_name,\n",
        "    NUM_EPOCHS=NUM_EPOCHS,\n",
        "    lr=lr,\n",
        "    momentum=0.9,\n",
        "    train_loader=train_loader,\n",
        "    train_loader_at_eval=train_loader_at_eval,\n",
        "    test_loader=test_loader,\n",
        "    n_classes = n_classes,\n",
        "    task = task,\n",
        "    steps = len(train_loader)\n",
        ")"
      ],
      "metadata": {
        "id": "jE7C4XjhsnWp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27618eba-8133-4aaa-89c5-721172d35310"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 206M/206M [00:13<00:00, 15.8MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initialize_weights...\n",
            "\n",
            "Epoch [1/20]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 finished in 48.39 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [2/20]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 finished in 48.79 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [3/20]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 finished in 48.57 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [4/20]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 finished in 48.78 seconds\n",
            "\n",
            "Epoch [5/20]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 finished in 49.02 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [6/20]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 finished in 48.98 seconds\n",
            "\n",
            "Epoch [7/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 finished in 48.72 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [8/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 finished in 48.87 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [9/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 finished in 48.83 seconds\n",
            "\n",
            "Epoch [10/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 finished in 48.81 seconds\n",
            "\n",
            "Epoch [11/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 finished in 49.28 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [12/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 finished in 48.91 seconds\n",
            "\n",
            "Epoch [13/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 finished in 49.31 seconds\n",
            "\n",
            "Epoch [14/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 finished in 49.03 seconds\n",
            "\n",
            "Epoch [15/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 finished in 48.97 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [16/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 finished in 49.08 seconds\n",
            "\n",
            "Epoch [17/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 finished in 48.63 seconds\n",
            "\n",
            "Epoch [18/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 finished in 49.07 seconds\n",
            "\n",
            "Epoch [19/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 finished in 48.96 seconds\n",
            "\n",
            "Epoch [20/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 finished in 49.06 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "âœ… Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # [tissuemnist, pathmnist, dermamnist, octmnist,\n",
        "# # pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "data_flag = \"octmnist\"\n",
        "med3d = False\n",
        "model_name = f\"MedViT2D_{data_flag}\"\n",
        "(data_flag,\n",
        " NUM_EPOCHS,\n",
        " BATCH_SIZE,\n",
        " lr,\n",
        " task,\n",
        " train_loader,\n",
        " train_loader_at_eval,\n",
        " test_loader,\n",
        " n_classes) = data_input_loading(data_flag=data_flag,\n",
        "                                 med3d = False,\n",
        "                                 NUM_EPOCHS = NUM_EPOCHS,\n",
        "                                 BATCH_SIZE=BATCH_SIZE,\n",
        "                                 lr=lr)\n",
        "\n",
        "history = training_and_record(\n",
        "    model_class=MedViT_small,\n",
        "    model_name= model_name,\n",
        "    NUM_EPOCHS=NUM_EPOCHS,\n",
        "    lr=lr,\n",
        "    momentum=0.9,\n",
        "    train_loader=train_loader,\n",
        "    train_loader_at_eval=train_loader_at_eval,\n",
        "    test_loader=test_loader,\n",
        "    n_classes = n_classes,\n",
        "    task = task,\n",
        "    steps = len(train_loader)\n",
        ")"
      ],
      "metadata": {
        "id": "GW8d1DuwsnDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ebd3a169-ed91-4a8d-a7e5-aa2bf669d15c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54.9M/54.9M [00:04<00:00, 13.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "\n",
            "Epoch [1/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished in 48.57 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [2/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 finished in 49.46 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [3/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 finished in 48.73 seconds\n",
            "\n",
            "Epoch [4/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 finished in 49.03 seconds\n",
            "\n",
            "Epoch [5/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 finished in 49.51 seconds\n",
            "\n",
            "Epoch [6/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 finished in 49.22 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [7/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 finished in 49.39 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [8/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 finished in 49.45 seconds\n",
            "\n",
            "Epoch [9/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 finished in 49.19 seconds\n",
            "\n",
            "Epoch [10/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 finished in 49.23 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [11/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 finished in 49.05 seconds\n",
            "\n",
            "Epoch [12/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 finished in 49.22 seconds\n",
            "\n",
            "Epoch [13/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 finished in 49.23 seconds\n",
            "\n",
            "Epoch [14/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 finished in 49.14 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [15/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 finished in 49.32 seconds\n",
            "\n",
            "Epoch [16/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 finished in 49.28 seconds\n",
            "\n",
            "Epoch [17/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 finished in 49.30 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [18/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 finished in 49.09 seconds\n",
            "\n",
            "Epoch [19/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 finished in 49.45 seconds\n",
            "\n",
            "Epoch [20/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.43it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 finished in 49.55 seconds\n",
            "âœ… Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # [tissuemnist, pathmnist, dermamnist, octmnist,\n",
        "# # pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "data_flag = \"pneumoniamnist\"\n",
        "med3d = False\n",
        "model_name = f\"MedViT2D_{data_flag}\"\n",
        "(data_flag,\n",
        " NUM_EPOCHS,\n",
        " BATCH_SIZE,\n",
        " lr,\n",
        " task,\n",
        " train_loader,\n",
        " train_loader_at_eval,\n",
        " test_loader,\n",
        " n_classes) = data_input_loading(data_flag=data_flag,\n",
        "                                 med3d = False,\n",
        "                                 NUM_EPOCHS = NUM_EPOCHS,\n",
        "                                 BATCH_SIZE=BATCH_SIZE,\n",
        "                                 lr=lr)\n",
        "\n",
        "history = training_and_record(\n",
        "    model_class=MedViT_small,\n",
        "    model_name= model_name,\n",
        "    NUM_EPOCHS=NUM_EPOCHS,\n",
        "    lr=lr,\n",
        "    momentum=0.9,\n",
        "    train_loader=train_loader,\n",
        "    train_loader_at_eval=train_loader_at_eval,\n",
        "    test_loader=test_loader,\n",
        "    n_classes = n_classes,\n",
        "    task = task,\n",
        "    steps = len(train_loader)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9u8_SPKTV2Fv",
        "outputId": "f9bebab6-841a-4ecb-f87f-e7812fa36f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.17M/4.17M [00:01<00:00, 3.03MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "\n",
            "Epoch [1/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished in 49.13 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [2/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 finished in 48.70 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [3/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 finished in 49.02 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [4/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 finished in 48.92 seconds\n",
            "\n",
            "Epoch [5/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 finished in 49.01 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [6/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 finished in 49.14 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [7/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 finished in 48.67 seconds\n",
            "\n",
            "Epoch [8/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 finished in 48.96 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [9/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 finished in 49.23 seconds\n",
            "\n",
            "Epoch [10/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 finished in 48.70 seconds\n",
            "\n",
            "Epoch [11/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 finished in 49.33 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [12/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 finished in 48.58 seconds\n",
            "\n",
            "Epoch [13/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 finished in 49.24 seconds\n",
            "\n",
            "Epoch [14/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 finished in 48.99 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [15/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 finished in 48.94 seconds\n",
            "\n",
            "Epoch [16/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 finished in 48.65 seconds\n",
            "\n",
            "Epoch [17/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 finished in 48.81 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [18/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 finished in 49.06 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [19/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:49<00:00,  1.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 finished in 50.54 seconds\n",
            "\n",
            "Epoch [20/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:48<00:00,  1.44it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 finished in 49.32 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "âœ… Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # [tissuemnist, pathmnist, dermamnist, octmnist,\n",
        "# # pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "data_flag = \"breastmnist\"\n",
        "med3d = False\n",
        "model_name = f\"MedViT2D_{data_flag}\"\n",
        "(data_flag,\n",
        " NUM_EPOCHS,\n",
        " BATCH_SIZE,\n",
        " lr,\n",
        " task,\n",
        " train_loader,\n",
        " train_loader_at_eval,\n",
        " test_loader,\n",
        " n_classes) = data_input_loading(data_flag=data_flag,\n",
        "                                 med3d = False,\n",
        "                                 NUM_EPOCHS = NUM_EPOCHS,\n",
        "                                 BATCH_SIZE=BATCH_SIZE,\n",
        "                                 lr=lr)\n",
        "\n",
        "history = training_and_record(\n",
        "    model_class=MedViT_small,\n",
        "    model_name= model_name,\n",
        "    NUM_EPOCHS=NUM_EPOCHS,\n",
        "    lr=lr,\n",
        "    momentum=0.9,\n",
        "    train_loader=train_loader,\n",
        "    train_loader_at_eval=train_loader_at_eval,\n",
        "    test_loader=test_loader,\n",
        "    n_classes = n_classes,\n",
        "    task = task,\n",
        "    steps = len(train_loader)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98I7462mV1-g",
        "outputId": "1cfa75e1-9434-4656-8d28-b434872dc06b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "\n",
            "Epoch [1/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished in 23.01 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [2/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 finished in 23.20 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [3/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 finished in 22.96 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [4/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:21<00:00,  1.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 finished in 22.76 seconds\n",
            "\n",
            "Epoch [5/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:23<00:00,  1.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 finished in 24.25 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [6/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 finished in 23.04 seconds\n",
            "\n",
            "Epoch [7/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 finished in 22.92 seconds\n",
            "\n",
            "Epoch [8/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 finished in 23.32 seconds\n",
            "\n",
            "Epoch [9/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 finished in 23.32 seconds\n",
            "\n",
            "Epoch [10/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 finished in 23.17 seconds\n",
            "\n",
            "Epoch [11/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 finished in 23.19 seconds\n",
            "\n",
            "Epoch [12/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 finished in 23.25 seconds\n",
            "\n",
            "Epoch [13/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 finished in 22.89 seconds\n",
            "\n",
            "Epoch [14/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 finished in 23.14 seconds\n",
            "\n",
            "Epoch [15/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 finished in 23.11 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [16/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 finished in 23.15 seconds\n",
            "\n",
            "Epoch [17/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 finished in 23.22 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [18/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 finished in 23.08 seconds\n",
            "\n",
            "Epoch [19/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 finished in 22.86 seconds\n",
            "\n",
            "Epoch [20/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 33/33 [00:22<00:00,  1.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 finished in 22.99 seconds\n",
            "âœ… Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # [tissuemnist, pathmnist, dermamnist, octmnist,\n",
        "# # pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "data_flag = \"bloodmnist\"\n",
        "med3d = False\n",
        "model_name = f\"MedViT2D_{data_flag}\"\n",
        "(data_flag,\n",
        " NUM_EPOCHS,\n",
        " BATCH_SIZE,\n",
        " lr,\n",
        " task,\n",
        " train_loader,\n",
        " train_loader_at_eval,\n",
        " test_loader,\n",
        " n_classes) = data_input_loading(data_flag=data_flag,\n",
        "                                 med3d = False,\n",
        "                                 NUM_EPOCHS = NUM_EPOCHS,\n",
        "                                 BATCH_SIZE=BATCH_SIZE,\n",
        "                                 lr=lr)\n",
        "\n",
        "history = training_and_record(\n",
        "    model_class=MedViT_small,\n",
        "    model_name= model_name,\n",
        "    NUM_EPOCHS=NUM_EPOCHS,\n",
        "    lr=lr,\n",
        "    momentum=0.9,\n",
        "    train_loader=train_loader,\n",
        "    train_loader_at_eval=train_loader_at_eval,\n",
        "    test_loader=test_loader,\n",
        "    n_classes = n_classes,\n",
        "    task = task,\n",
        "    steps = len(train_loader)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OS8X2a4V10S",
        "outputId": "db056c16-d239-457a-918a-61db6108f3bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35.5M/35.5M [00:03<00:00, 11.8MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "\n",
            "Epoch [1/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished in 48.82 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [2/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 finished in 48.64 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [3/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 finished in 48.58 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [4/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 finished in 48.63 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [5/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 finished in 48.45 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [6/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 finished in 48.70 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [7/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 finished in 48.54 seconds\n",
            "\n",
            "Epoch [8/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 finished in 48.70 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [9/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 finished in 48.83 seconds\n",
            "\n",
            "Epoch [10/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 finished in 48.51 seconds\n",
            "\n",
            "Epoch [11/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 finished in 48.55 seconds\n",
            "\n",
            "Epoch [12/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 finished in 48.67 seconds\n",
            "\n",
            "Epoch [13/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 finished in 48.38 seconds\n",
            "\n",
            "Epoch [14/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 finished in 48.29 seconds\n",
            "\n",
            "Epoch [15/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 finished in 48.89 seconds\n",
            "\n",
            "Epoch [16/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 finished in 48.76 seconds\n",
            "\n",
            "Epoch [17/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 finished in 48.43 seconds\n",
            "\n",
            "Epoch [18/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.46it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 finished in 48.94 seconds\n",
            "\n",
            "Epoch [19/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.47it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 finished in 48.75 seconds\n",
            "\n",
            "Epoch [20/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:47<00:00,  1.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 finished in 48.35 seconds\n",
            "âœ… Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # [tissuemnist, pathmnist, dermamnist, octmnist,\n",
        "# # pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "data_flag = \"organamnist\"\n",
        "med3d = False\n",
        "model_name = f\"MedViT2D_{data_flag}\"\n",
        "(data_flag,\n",
        " NUM_EPOCHS,\n",
        " BATCH_SIZE,\n",
        " lr,\n",
        " task,\n",
        " train_loader,\n",
        " train_loader_at_eval,\n",
        " test_loader,\n",
        " n_classes) = data_input_loading(data_flag=data_flag,\n",
        "                                 med3d = False,\n",
        "                                 NUM_EPOCHS = NUM_EPOCHS,\n",
        "                                 BATCH_SIZE=BATCH_SIZE,\n",
        "                                 lr=lr)\n",
        "\n",
        "history = training_and_record(\n",
        "    model_class=MedViT_small,\n",
        "    model_name= model_name,\n",
        "    NUM_EPOCHS=NUM_EPOCHS,\n",
        "    lr=lr,\n",
        "    momentum=0.9,\n",
        "    train_loader=train_loader,\n",
        "    train_loader_at_eval=train_loader_at_eval,\n",
        "    test_loader=test_loader,\n",
        "    n_classes = n_classes,\n",
        "    task = task,\n",
        "    steps = len(train_loader)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZn5fKBBV1qf",
        "outputId": "3cfa9337-fa8f-4264-f019-a9a88c00b543"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 38.2M/38.2M [00:03<00:00, 11.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "\n",
            "Epoch [1/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:46<00:00,  1.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished in 47.26 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [2/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 finished in 46.59 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [3/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:46<00:00,  1.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 finished in 47.34 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [4/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:46<00:00,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 finished in 46.88 seconds\n",
            "\n",
            "Epoch [5/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 finished in 46.56 seconds\n",
            "\n",
            "Epoch [6/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 finished in 46.57 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [7/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:46<00:00,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 finished in 46.90 seconds\n",
            "\n",
            "Epoch [8/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:46<00:00,  1.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 finished in 47.11 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [9/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 finished in 46.73 seconds\n",
            "\n",
            "Epoch [10/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 finished in 46.64 seconds\n",
            "\n",
            "Epoch [11/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:46<00:00,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 finished in 46.90 seconds\n",
            "\n",
            "Epoch [12/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:46<00:00,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 finished in 46.95 seconds\n",
            "\n",
            "Epoch [13/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:46<00:00,  1.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 finished in 47.04 seconds\n",
            "\n",
            "Epoch [14/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:46<00:00,  1.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 finished in 47.00 seconds\n",
            "\n",
            "Epoch [15/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 finished in 46.54 seconds\n",
            "\n",
            "Epoch [16/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 finished in 46.70 seconds\n",
            "\n",
            "Epoch [17/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 finished in 46.71 seconds\n",
            "\n",
            "Epoch [18/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 finished in 46.55 seconds\n",
            "\n",
            "Epoch [19/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 finished in 46.58 seconds\n",
            "\n",
            "Epoch [20/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 finished in 46.60 seconds\n",
            "âœ… Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # [tissuemnist, pathmnist, dermamnist, octmnist,\n",
        "# # pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "data_flag = \"organcmnist\"\n",
        "med3d = False\n",
        "model_name = f\"MedViT2D_{data_flag}\"\n",
        "(data_flag,\n",
        " NUM_EPOCHS,\n",
        " BATCH_SIZE,\n",
        " lr,\n",
        " task,\n",
        " train_loader,\n",
        " train_loader_at_eval,\n",
        " test_loader,\n",
        " n_classes) = data_input_loading(data_flag=data_flag,\n",
        "                                 med3d = False,\n",
        "                                 NUM_EPOCHS = NUM_EPOCHS,\n",
        "                                 BATCH_SIZE=BATCH_SIZE,\n",
        "                                 lr=lr)\n",
        "\n",
        "history = training_and_record(\n",
        "    model_class=MedViT_small,\n",
        "    model_name= model_name,\n",
        "    NUM_EPOCHS=NUM_EPOCHS,\n",
        "    lr=lr,\n",
        "    momentum=0.9,\n",
        "    train_loader=train_loader,\n",
        "    train_loader_at_eval=train_loader_at_eval,\n",
        "    test_loader=test_loader,\n",
        "    n_classes = n_classes,\n",
        "    task = task,\n",
        "    steps = len(train_loader)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-f891YJrdo3",
        "outputId": "07652b9f-6e53-44f7-901e-358918da5a2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15.5M/15.5M [00:01<00:00, 7.89MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "\n",
            "Epoch [1/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished in 46.79 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [2/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 finished in 46.32 seconds\n",
            "\n",
            "Epoch [3/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 finished in 46.49 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [4/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 finished in 46.59 seconds\n",
            "\n",
            "Epoch [5/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 finished in 46.42 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [6/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 finished in 46.79 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [7/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 finished in 46.53 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [8/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 finished in 46.61 seconds\n",
            "\n",
            "Epoch [9/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 finished in 46.86 seconds\n",
            "\n",
            "Epoch [10/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 finished in 46.54 seconds\n",
            "\n",
            "Epoch [11/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 finished in 46.60 seconds\n",
            "\n",
            "Epoch [12/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 finished in 46.28 seconds\n",
            "\n",
            "Epoch [13/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 finished in 46.17 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [14/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 finished in 46.49 seconds\n",
            "\n",
            "Epoch [15/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:44<00:00,  1.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 finished in 46.09 seconds\n",
            "\n",
            "Epoch [16/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 finished in 46.40 seconds\n",
            "\n",
            "Epoch [17/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 finished in 46.55 seconds\n",
            "\n",
            "Epoch [18/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:46<00:00,  1.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 finished in 47.32 seconds\n",
            "\n",
            "Epoch [19/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 finished in 46.46 seconds\n",
            "\n",
            "Epoch [20/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 finished in 46.50 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "âœ… Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # [tissuemnist, pathmnist, dermamnist, octmnist,\n",
        "# # pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "data_flag = \"organsmnist\"\n",
        "med3d = False\n",
        "model_name = f\"MedViT2D_{data_flag}\"\n",
        "(data_flag,\n",
        " NUM_EPOCHS,\n",
        " BATCH_SIZE,\n",
        " lr,\n",
        " task,\n",
        " train_loader,\n",
        " train_loader_at_eval,\n",
        " test_loader,\n",
        " n_classes) = data_input_loading(data_flag=data_flag,\n",
        "                                 med3d = False,\n",
        "                                 NUM_EPOCHS = NUM_EPOCHS,\n",
        "                                 BATCH_SIZE=BATCH_SIZE,\n",
        "                                 lr=lr)\n",
        "\n",
        "history = training_and_record(\n",
        "    model_class=MedViT_small,\n",
        "    model_name= model_name,\n",
        "    NUM_EPOCHS=NUM_EPOCHS,\n",
        "    lr=lr,\n",
        "    momentum=0.9,\n",
        "    train_loader=train_loader,\n",
        "    train_loader_at_eval=train_loader_at_eval,\n",
        "    test_loader=test_loader,\n",
        "    n_classes = n_classes,\n",
        "    task = task,\n",
        "    steps = len(train_loader)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz0o-1YWrdiG",
        "outputId": "19e2746a-fd1e-4603-e8a8-8c738c54abe0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16.5M/16.5M [00:01<00:00, 8.95MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "\n",
            "Epoch [1/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 finished in 46.60 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [2/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 finished in 46.34 seconds\n",
            "\n",
            "Epoch [3/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:44<00:00,  1.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 finished in 46.10 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [4/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 finished in 46.43 seconds\n",
            "\n",
            "Epoch [5/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:44<00:00,  1.56it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 finished in 46.09 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [6/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 finished in 46.69 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [7/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 finished in 46.36 seconds\n",
            "\n",
            "Epoch [8/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 finished in 46.58 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [9/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 finished in 46.55 seconds\n",
            "\n",
            "Epoch [10/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 finished in 46.78 seconds\n",
            "\n",
            "Epoch [11/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 finished in 46.76 seconds\n",
            "\n",
            "Epoch [12/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 finished in 46.44 seconds\n",
            "\n",
            "Epoch [13/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 finished in 46.42 seconds\n",
            "\n",
            "Epoch [14/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 finished in 46.25 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [15/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 finished in 46.92 seconds\n",
            "\n",
            "Epoch [16/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 finished in 46.41 seconds\n",
            "\n",
            "Epoch [17/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 finished in 46.37 seconds\n",
            "\n",
            "Epoch [18/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 finished in 46.36 seconds\n",
            "\n",
            "Epoch [19/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 finished in 46.28 seconds\n",
            "ğŸ“Œ New best AUC â€” saving model\n",
            "\n",
            "Epoch [20/20]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70/70 [00:45<00:00,  1.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 finished in 46.22 seconds\n",
            "âœ… Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7CWaRBwgrda2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CP39VaImrdP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89HqFIIi7ARz"
      },
      "outputs": [],
      "source": [
        "## Grad CAM for model explanation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QXuzYhhSEo8q",
        "outputId": "091e86f9-db26-4ac2-b4cb-61ce85117e85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchcam\n",
            "  Downloading torchcam-0.4.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchcam) (2.6.0+cu124)\n",
            "Collecting numpy<2.0.0,>=1.17.2 (from torchcam)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow!=9.2.0,>=8.4.0 in /usr/local/lib/python3.11/dist-packages (from torchcam) (11.3.0)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from torchcam) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0.0,>=2.0.0->torchcam)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0.0,>=2.0.0->torchcam)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0.0,>=2.0.0->torchcam)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0.0,>=2.0.0->torchcam)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0.0,>=2.0.0->torchcam)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0.0,>=2.0.0->torchcam)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0.0,>=2.0.0->torchcam)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0.0,>=2.0.0->torchcam)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0.0,>=2.0.0->torchcam)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0.0,>=2.0.0->torchcam)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0.0,>=2.0.0->torchcam) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.7.0->torchcam) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0.0,>=2.0.0->torchcam) (3.0.2)\n",
            "Downloading torchcam-0.4.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchcam\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchcam-0.4.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "e45e90151441496fa9e2833aa76c037c",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting captum\n",
            "  Downloading captum-0.8.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from captum) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.11/dist-packages (from captum) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from captum) (25.0)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.11/dist-packages (from captum) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from captum) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10->captum) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10->captum) (3.0.2)\n",
            "Downloading captum-0.8.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: captum\n",
            "Successfully installed captum-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchcam\n",
        "# OR\n",
        "!pip install captum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfQ6I5mK8W1n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kcpLxy6CGIQ"
      },
      "outputs": [],
      "source": [
        "from torchcam.methods import GradCAM\n",
        "from torchcam.utils import overlay_mask\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "cam_extractor = GradCAM(model, target_layer=\"ltb1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sin1HsuxFsWI"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "# Select a sample from test loader\n",
        "inputs, targets = next(iter(test_loader))\n",
        "inputs = inputs.to(device)\n",
        "targets = targets.squeeze().long().to(device)\n",
        "\n",
        "# Forward pass and CAM extraction\n",
        "with torch.no_grad():\n",
        "    output = model(inputs)\n",
        "    pred_class = output.argmax(dim=1)\n",
        "\n",
        "# Extract CAM for the first image\n",
        "cam = cam_extractor(pred_class[0].item(), output)  # Automatically registers and removes hooks\n",
        "\n",
        "# Process image and heatmap\n",
        "input_image = inputs[0].cpu().squeeze().numpy()  # [D, H, W]\n",
        "slice_idx = input_image.shape[0] // 2\n",
        "slice_img = input_image[slice_idx]\n",
        "slice_cam = cam[0][slice_idx]\n",
        "\n",
        "# Normalize and overlay\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from torchcam.utils import overlay_mask\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "norm_slice = (slice_img - slice_img.min()) / (slice_img.max() - slice_img.min())\n",
        "norm_cam = (slice_cam - slice_cam.min()) / (slice_cam.max() - slice_cam.min())\n",
        "\n",
        "overlay = overlay_mask(to_pil_image(norm_slice), to_pil_image(norm_cam), alpha=0.6)\n",
        "\n",
        "plt.imshow(overlay)\n",
        "plt.title(f\"Grad-CAM (Pred: {pred_class[0].item()}, True: {targets[0].item()})\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "_zEnJK3uDlxo",
        "outputId": "4764d851-99be-4127-b733-7d2b110f1e65"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAH4CAYAAAB9k1VdAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAANbhJREFUeJzt3Wd8lGXe/v9j0hsJXarSazQUkV1pFhARFX4rRVHaclvxVtyliCC9SHEVu64IKFVAEbGAJQioi6ggKCji0kSUoKGFkHr+H/hP1pCQDH6znuu9n/frxQNmrmOubyaTOXJdM5Mz4JxzAgAAv7kQ3wMAAPDfihIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIuRQMGDFCtWrV8j/Ffxed9npubq8TERE2ePPmsckXNHAgENG7cuNIbzpPrr79evXr1Cnr7uXPnKhAI/BsnKj3jxo373cwaCAQ0d+5c32MgCP8nSnj37t2688471aBBA8XExCgmJkZNmjTR4MGDtXXrVt/jndGxY8c0fvx4JSUlKS4uTtHR0UpMTNSIESP03XffFZnp1auXAoGARowYUeT1a9euVSAQUCAQ0Pz584vcpk2bNgoEAkpMTAx61lWrVunKK69UhQoVFBUVpQYNGmjo0KH68ccfg76N/2sWLVqk/fv368477/Q9yq/y0Ucf6Y477lDLli0VHh4edMFs2LAh/zF2+PDhAteNGDFCy5cv12effVbq8+btMxAIKCQkRNWqVdMVV1yhtWvXlvq+/h3WrFmjQYMGKTExUaGhocX+8pibm6vp06erdu3aioqK0gUXXKBFixb922Zbv369evXqperVqysiIkIJCQlq3bq1JkyYoB9++EFSwfu/uH9n8/1YsmSJbrrpJtWvX1+BQECXXHLJGbfNyMjQiBEjVK1aNUVHR6t169Z66623jF+5f2G+B7BatWqVevfurbCwMN14441KSkpSSEiIvvzyS7300kt68skntXv3bp133nm+Ry3gn//8pzp27Kh9+/apZ8+euuWWWxQREaGtW7dq9uzZevnll7Vz584CmWPHjunVV19VrVq1tGjRIj3wwANnfOKMiorSwoULddNNNxW4fM+ePfrggw8UFRUV9KxDhw7Vgw8+qKSkJI0YMULly5fXp59+qscee0yLFy/WO++8o4YNG579nfA7N2PGDF1//fVKSEgw31Z6errCwn7bH8fXX39dzz77rC644ALVqVOn0OOtKLm5ufrf//1fxcbGKi0trdD1zZs314UXXqgHH3xQzz//fKnP3KlTJ/Xr10/OOe3evVtPPPGELrvsMr322mvq0qVLqe+vNC1cuFBLlixRixYtVK1atWK3HTVqlB544AHdfPPNatWqlV555RX16dNHgUBA119/fanONWbMGE2cOFF16tTRgAEDVKdOHZ06dUqffPKJHnzwQc2bN0/ffPONXnjhhQK5559/Xm+99Vahyxs3bhz0vp988kl98sknatWqVYm/0A8YMEDLli3TkCFDVL9+fc2dO1dXXXWVkpOT1bZt2+C/4P807nds165dLjY21jVu3Nh99913ha7Pyspys2bNcvv27Sv2dk6cOFEq8/Tv39+dd955JW6XlZXlkpKSXExMjFu/fn2h648ePeruu+++Qpc/99xzLjw83L377rtOklu7dm2hbZKTk50k96c//cmFhYW5lJSUAtdPnjzZnXPOOa5t27auadOmJc66cOFCJ8n17t3bZWdnF7hu48aNLiYmxp1//vkuKyurxNsqTXnfs2Dv89L26aefOknu7bffPuusr5lP9/3337uTJ08655wbPHiwC+bp4Mknn3QVKlRwd999t5NU6PHlnHMzZ850sbGx7vjx4yXe3pw5c4Lar3POSXKDBw8ucNnWrVudJHfFFVecMZeenu5ycnKC2kdxxo4dG/SsRTlw4IDLzMx0zjnXtWvXMz4Gvv32WxceHl7ga83NzXXt2rVzNWrUKPRzWBRJbs6cOSVut3jxYifJ9erVy2VkZBS6/siRI27s2LFFZoN9zBRn3759+d+bpk2bug4dOhS53caNG50kN2PGjPzL0tPTXd26dd0f//hH0wy+/a5PR0+fPl1paWmaM2eOqlatWuj6sLAw3XXXXapZs2b+ZQMGDFBcXJy++eYbXXXVVSpTpoxuvPFGST+fkunZs6fOPfdcRUZGqmbNmrrnnnuUnp5e6LZXrFihxMRERUVFKTExUS+//HLQc+edrhs1alSRv8HFx8cX+TrjggUL1KlTJ1166aVq3LixFixYcMZ9dOvWTZGRkVq6dGmByxcuXKhevXopNDQ0qFnHjx+vcuXK6ZlnnimUueiiizRixAht27ZNy5YtkyTdeeediouL08mTJwvd1g033KAqVaooJycn/7I33nhD7dq1U2xsrMqUKaOuXbvqiy++KJAr7ntWlJkzZ+riiy9WhQoVFB0drZYtW+bPl6dDhw5KSkoqMt+wYUN17ty52PtlxYoVioiIUPv27Qtcfvz4cQ0ZMkS1atVSZGSkKleurE6dOunTTz8t9vaKek34wIEDGjRokKpVq6bIyEjVrl1bt99+uzIzM/O3OXLkiIYMGaKaNWsqMjJS9erV07Rp05Sbm1vs/iTpnHPOUXR0dInb5fnpp580evRoTZgwQWXLlj3jdp06dVJaWtpvcqrw/PPPV8WKFbV7925J/3o5ZvHixRo9erSqV6+umJgYHTt2TJK0ceNGXXnllUpISFBMTIw6dOig999/v9DtbtiwQa1atVJUVJTq1q2rp59+usj9Hz58WF9++WWRj/fTVatWTeHh4SVu98orrygrK0t33HFH/mWBQEC33367vv32W3344Ycl3kawxowZo4oVK2r27NmKiIgodH1CQsJZv1fh4MGD+vLLL5WVlVXitjVr1lRISMk1tGzZMoWGhuqWW27JvywqKkqDBg3Shx9+qP3795/VjP9JftclvGrVKtWrV0+tW7c+q1x2drY6d+6sypUra+bMmbruuuskSUuXLtXJkyd1++2369FHH1Xnzp316KOPql+/fgXya9as0XXXXadAIKCpU6eqe/fuGjhwoD7++OOg9r9y5UpJUt++fYOe+bvvvlNycrJuuOEGST8X2rJlywo8If9STEyMunXrVuB1pM8++0xffPGF+vTpE9Q+v/76a3311Vfq1q2b4uPji9wm775ZtWqVJKl3795KS0vTa6+9VmC7kydP6tVXX1WPHj3yy/yFF15Q165dFRcXp2nTpun+++/X9u3b1bZtW+3Zs6dA/kzfs6LMmjVLzZs314QJEzRlyhSFhYWpZ8+eBWbq27evtm7dqs8//7xAdtOmTdq5c2eh0/in++CDD5SYmFjoSfW2227Tk08+qeuuu05PPPGEhg4dqujoaO3YsaPY2zvdd999p4suukiLFy9W79699cgjj6hv375677338p/wT548qQ4dOmj+/Pnq16+fHnnkEbVp00YjR47UX/7yl7PaXzDuv/9+ValSRbfeemux2zVp0kTR0dFFlltpS01NVWpqqipUqFDg8okTJ+q1117T0KFDNWXKFEVEROjdd99V+/btdezYMY0dO1ZTpkzRkSNHdNlll+mjjz7Kz27btk1XXHGFDh06pHHjxmngwIEaO3Zskb9oP/bYY2rcuHGBvNXmzZsVGxtb6LTuRRddlH99adi5c6d27typ7t27Ky4urlRuU5JGjhypxo0b68CBA6V2m5s3b1aDBg0KPQ/l3SdbtmwptX395nwfiv9aR48edZJc9+7dC12XmprqUlJS8v/lnXJz7udTgZLcvffeWyj3y+3yTJ061QUCAbd37978y5o1a+aqVq3qjhw5kn/ZmjVrnKSgTjM2b97cJSQklLjdL82cOdNFR0e7Y8eOOeec27lzp5PkXn755QLb5Z2OXrp0qVu1apULBAL5p+OHDRvm6tSp45xzrkOHDiWejl6xYoWT5B566KFit4uPj3ctWrRwzv182qx69eruuuuuK7DNiy++6CS5devWOeecO378uCtbtqy7+eabC2z3/fffu4SEhAKXF/c9K+rU7unfx8zMTJeYmOguu+yy/MuOHDnioqKi3IgRIwpse9ddd7nY2NgSX6KoUaNGoa/ROecSEhIKnTINZmZJBU779evXz4WEhLhNmzYVyufm5jrnnJs4caKLjY11O3fuLHD9vffe60JDQ0t8GeaXSjq1+Nlnn7nQ0FC3evVq59y/Ts0WdTraOecaNGjgunTpUuJ+z/Z09KBBg1xKSoo7dOiQ27hxo7v88sudJPfggw865/71+K9Tp06Bx0Fubq6rX7++69y5c/7959zPj5XatWu7Tp065V/WvXt3FxUVVeBnfvv27S40NLTQrHn3Q3JyclBfQ57iTkd37do1/+f0l9LS0s74c3A6BXE6+pVXXnGS3MMPP1zg8tzc3ALPnykpKUW+3HSmx0zez+vu3btLnPOXijsd3bRp0wI/v3m++OILJ8k99dRTZ7Wv/yS/2yPhvNNLRf0Gd8kll6hSpUr5/x5//PFC29x+++2FLvvlqbm0tDQdPnxYF198sZxz+b99Hjx4UFu2bFH//v0LvCGnU6dOatKkSdCzlylTJqht8yxYsEBdu3bNz9WvX18tW7Ys9pT0FVdcofLly2vx4sVyzmnx4sX5R9LBOH78uCSVOGuZMmXyvx+BQEA9e/bU66+/rhMnTuRvs2TJElWvXj3/9Ptbb72lI0eO6IYbbtDhw4fz/4WGhqp169ZKTk4utJ+ivmdF+eX3MTU1VUePHlW7du0KnBJOSEjIP1PgnJMk5eTkaMmSJerevbtiY2OL3cePP/6ocuXKFbq8bNmy2rhx4xnf3R6M3NxcrVixQtdcc40uvPDCQtfnvRlv6dKlateuncqVK1fgPuzYsaNycnK0bt26Xz3D6e666y516dJFV1xxRVDb581U2mbPnq1KlSqpcuXKat26td5//3395S9/0ZAhQwps179//wKPgy1btujrr79Wnz599OOPP+bfV2lpabr88su1bt065ebmKicnR6tXr1b37t117rnn5ucbN25c5EsU48aNk3Ou2Hf1nq309HRFRkYWujzvzZRFvTz2a5zpOfTo0aMFnj8rVap0Vkeac+fOlXOuVD86+FvdJz78bt8dnVcMv3yiz/P000/r+PHj+uGHH4o8rRgWFqYaNWoUunzfvn0aM2aMVq5cqdTU1ALXHT16VJK0d+9eST+X4OkaNmxY4Ik+JSWlwOufcXFxiouLU3x8vP75z38G82VKknbs2KHNmzerX79+2rVrV/7ll1xyiR5//HEdO3asyNPF4eHh6tmzpxYuXKiLLrpI+/fvD/pUtPSv+zivjM/k+PHjqly5cv7/e/furYcfflgrV65Unz59dOLECb3++uu69dZb8wvk66+/liRddtllRd7m6V/Pmb5nRVm1apUmTZqkLVu2KCMjI//y099J3q9fPy1ZskTr169X+/bt9fbbb+uHH34I+mWCvPL+penTp6t///6qWbOmWrZsqauuukr9+vVTnTp1grpN6efHzbFjx0r8CNnXX3+trVu3qlKlSkVef+jQoaD3WZwlS5bogw8+KHTqvjjOuX/LZ2q7deumO++8U4FAQGXKlFHTpk2L/IWpdu3aBf6f93jr37//GW/76NGjysjIUHp6+hl/vl9//XXjV1Cy6OjoAo/bPKdOncq/vjSc6Tk0Li4u//X8NWvWaMaMGaWyP4vf6j7x4XdbwgkJCapatWqRTwx5rxGf/rpinsjIyEJvBsjJyVGnTp30008/acSIEWrUqJFiY2N14MABDRgwIKg3upyuVatW+aUtSWPHjtW4cePUqFEjbd68Wfv37y/wprEzyfu87z333KN77rmn0PXLly/XwIEDi8z26dNHTz31lMaNG6ekpKSgj9alf33UoLjPWu/du1fHjh0rcLt/+MMfVKtWLb344ovq06ePXn31VaWnp6t379752+Tdny+88IKqVKlS6HZP/7hOUd+zoqxfv17XXnut2rdvryeeeEJVq1ZVeHi45syZo4ULFxbYtnPnzjrnnHM0f/58tW/fXvPnz1eVKlXUsWPHEvdToUKFQr+oST9/jrtdu3Z6+eWX85/Apk2bppdeeqnUP0KTm5urTp06afjw4UVe36BBg1LZz7Bhw9SzZ09FRETk/0wdOXJEkrR//35lZmYW+shNampqkUVmVaNGjaC+P6c/Kec93mbMmKFmzZoVmYmLiyvyif63VrVqVSUnJxf6RebgwYOSVOLHm4LVqFEjSSr0HBoWFpZ/H3/77belsi+rqlWrFvkac2nfJz78bktYkrp27apnn31WH330Uf4L9L/Wtm3btHPnTs2bN6/AG7FOf4dn3ueN836z/qWvvvqqwP8XLFhQ4DRJ3tHQNddco0WLFmn+/PkaOXJksXM557Rw4UJdeumlBd4tmWfixIlasGDBGUu4bdu2Ovfcc7V27VpNmzat2H2drkGDBmrQoIFWrFihWbNmFXlaOu+zoFdffXWBy3v16qVZs2bp2LFjWrJkiWrVqqU//OEP+dfXrVtXklS5cuWgnlSDtXz5ckVFRWn16tUFTl/NmTOn0LahoaHq06eP5s6dq2nTpmnFihW6+eabg3rneKNGjfLfkXu6qlWr6o477tAdd9yhQ4cOqUWLFpo8eXLQJVypUiXFx8eXeORZt25dnThxolTvv6Ls379fCxcuLPRLjCS1aNFCSUlJBU5XZmdna//+/br22mv/rXOdjbzHW3x8fLH3V6VKlRQdHR3Uz/e/S7NmzfTss89qx44dBX653bhxY/71paFhw4aqX7++VqxYoYcffrjEl2B8atasmZKTkwud9Svt+8SH3+1rwpI0fPhwxcTE6M9//nP+X3X5paJOF55J3hPvLzPOOc2aNavAdlWrVlWzZs00b968/FPU0s9lvX379gLbtmnTRh07dsz/l1fCPXr00Pnnn6/JkycX+XGD48ePa9SoUZKk999/X3v27NHAgQPVo0ePQv969+6t5OTkM74GGQgE9Mgjj2js2LFn9W7sPGPGjFFqaqpuu+22AqfWJemTTz7RtGnTlJiYWOjdyr1791ZGRobmzZunN998s9CfMuzcubPi4+M1ZcqUIj/KkJKSctazSj9/HwOBQIFZ9+zZoxUrVhS5fd++fZWamqpbb71VJ06cKPFd0Xn++Mc/6vPPPy9w5JSTk1PgMSH9/EtGtWrVzuoIKyQkRN27d9err75a5Dvu8x6jvXr10ocffqjVq1cX2ubIkSPKzs4Oep/Fefnllwv9yzur8fzzz+uhhx4qsP327dt16tQpXXzxxaWy/9LQsmVL1a1bVzNnzizyJay8x1toaKg6d+6sFStWaN++ffnX79ixo8j7+Ww+ohSsbt26KTw8XE888UT+Zc45PfXUU6pevXqp3q/jxo3T4cOHdfPNNxf5c3g2z6F5zuYjSsHq0aOHcnJy9Mwzz+RflpGRoTlz5qh169ZBnVH8T/W7PhKuX7++Fi5cqBtuuEENGzbM/4tZ7v//azoLFy5USEhIUK8lNmrUSHXr1tXQoUN14MABxcfHa/ny5UWecpw6daq6du2qtm3b6s9//rN++uknPfroo2ratGmRP+CnCw8P10svvaSOHTuqffv26tWrl9q0aaPw8HB98cUXWrhwocqVK6fJkydrwYIFCg0NVdeuXYu8rWuvvVajRo3S4sWLz/ixlG7duqlbt24lzlWUG2+8UZs2bdKsWbO0fft23XjjjSpXrpw+/fRTPffcc6pQoYKWLVtW6KM6LVq0UL169TRq1ChlZGQUOBUt/XxE8uSTT6pv375q0aKFrr/+elWqVEn79u3Ta6+9pjZt2uixxx4763m7du2qv/3tb7ryyivVp08fHTp0SI8//rjq1atX5Gn15s2bKzExUUuXLlXjxo3VokWLoPbTrVs3TZw4Ue+9917+m5WOHz+uGjVqqEePHvl/ivTtt9/Wpk2b9OCDD57V1zFlyhStWbNGHTp00C233KLGjRvr4MGDWrp0qTZs2KCyZctq2LBhWrlypa6++moNGDBALVu2VFpaWv7ntvfs2aOKFSuecR979+7N/2tHeWU/adIkST+f8cn7pa179+6FsnlHvl26dCm0j7feeksxMTHq1KnTWX3N/04hISF69tln1aVLFzVt2lQDBw5U9erVdeDAASUnJys+Pl6vvvqqpJ8/G//mm2+qXbt2uuOOO5SdnZ3/8336Y+ixxx7T+PHjlZycXOKbs7Zu3Zr/8cRdu3bp6NGj+fd3UlKSrrnmGkk/n3IfMmSIZsyYoaysLLVq1UorVqzQ+vXr858PSkufPn30+eefa+rUqfroo490/fXXq3bt2kpLS9Pnn3+uRYsWqUyZMkW+CfFMRo4cqXnz5mn37t0lvjlr3bp1+W8gTElJUVpaWv590r59+/zP4bdu3Vo9e/bUyJEjdejQIdWrV0/z5s3Tnj17NHv27F/3xf+n+O3fkF36du3a5W6//XZXr149FxUV5aKjo12jRo3cbbfd5rZs2VJg2/79+7vY2Ngib2f79u2uY8eOLi4uzlWsWNHdfPPN7rPPPivy7f7Lly93jRs3dpGRka5JkybupZdeOuu/hJSamurGjBnjzj//fBcTE+OioqJcYmKiGzlypDt48KDLzMx0FSpUcO3atSv2dmrXru2aN2/unCv4EaXiBPMRpV9asWKF69SpkytXrpyLjIx09erVc3/961/P+BEV55wbNWqUk+Tq1at3xm2Sk5Nd586dXUJCgouKinJ169Z1AwYMcB9//HH+NsV9z4q6z2fPnu3q16/vIiMjXaNGjdycOXOK/WtH06dPd5LclClTirkHCrvgggvcoEGD8v+fkZHhhg0b5pKSklyZMmVcbGysS0pKck888USJM+u0jyg559zevXtdv379XKVKlVxkZKSrU6eOGzx4cIG/bHT8+HE3cuRIV69ePRcREeEqVqzoLr74Yjdz5sz8v850JnmPlaL+nemjInmK+4hS69at3U033VRsPo/1L2adrqTH/+bNm92f/vQnV6FCBRcZGenOO+8816tXL/fOO+8U2O69995zLVu2dBEREa5OnTruqaeeKvIxdDYfUcr7Wov6179//wLb5uTkuClTprjzzjvPRUREuKZNm7r58+eXuI88RT1nFWft2rWuR48ermrVqi48PNzFx8e7Cy+80I0dO9YdPHiwyExpfEQp7/4r6t/pPw/p6elu6NChrkqVKi4yMtK1atXKvfnmm0F/jf+pAs79ivMNwP8hs2bN0j333KM9e/YU+FhKSV544QUNHjxY+/btK/YvSP032bJli1q0aKFPP/00qNfp5s6dq4EDB/6q0544s0AgoDlz5mjAgAG+R0EJftevCQNWzjnNnj1bHTp0OKsCln4+VX/uuecW+Tn0/1YPPPCAevTo8bt+owzwW/pdvyYM/FppaWlauXKlkpOTtW3bNr3yyitnfRshISFn9dnZ/waLFy/2PQLwu0IJ479SSkqK+vTpo7Jly+q+++77j/o4DYD/HrwmDACAJ7wmDACAJ5QwAACeUMIAAHgS9BuzOo3YYNrRDz/YV3TJ2vhWyRsVI3JYLfMMNTK/NOU/+7CteYZ7N0wx5WcNv9k8Q1etMuWXvHf2f0LzdBN+nGi7gcLrRpy1UxsKL692Nh66ZJx5hmEXjzXl85aDs7AuW7h/bKZ5huVjpprybcNfNc9Q1HJ7Z6NlzibzDBWXxpjyjXsFv8jLmaTs+nV/djZP8sKi/y772cgcW8uUDwTsx6gzbym5NzkSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADwJej3hnJxc046ys7NMeUlyzpnyIaH23zli42JN+UAgYJ4h/dQpUz6yFNaPzU2zPR5KY63OMmXKmPKZkfY1bNNzbfdDenq6eYbwiHBT/sSJE+YZKlaqaMpnV7Hdj5L9OSoyLsI8g/XnOzzc9r2UpLS0k6Z8RIT9foiMtN1Gaczw/U+ppnzZsmXNMwSDI2EAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPwoLdcOAPA207Cg96V2f03PBrTPltY22LwEvSnX9dacp/vN6+iPu399cy5U9N+tw8QyD3B1N+woCJ5hmGbB9lu4H3nXmGEblTTXnrIvCSlJmZacofmWFfQH3WpbbvxX0h95tnyP3YdkzxzvvNzDNIu0zp9ZG3mCcYXv5R2wytWppnWLS/lSm/MyPZPMPw+GdtN5BzxDxDMDgSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADwJOOeCWlS1/fwpph2lnzplyktS56iNpvzCMXXNM2RmNzflJ3W13Y+StDWpqilfK+KweYbt96fZZphS3TxDZGSkKX/guP130Lnv9TTl71g/wzzD3+8cbsoPrLTMPMNPqcdM+df+1sQ8w/AJH5nye7MqmmdYOvlKU77LpO3mGd6Z0MyUbz7Rtm67JNWNe8yUb/zGavMMw5bZ1kUOshqLdejQ0hK34UgYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAk4ALcuXiKlXuNO0oMzPTlJek8uVt+aTR9t85GgR2mfIvft7fPMO9iRNM+Sn/GGWeIfL8vaZ89t9SzDNYJdxfy3wb369LMOX/553J5hmeuPUeUz5kXYR5hqyNb5ny/ctvNc9gfY5Z0Wm0eYbQrDBTPsdlm2dIOM/2mGzypS0vSYMjp5ryB65NNc+Qctj2HBMSsPfF3XccKHk/5r0AAIBfhRIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE+CXvxy0sgVph2FhNj7Pmx2uCk/K/MG8wzvv5tkysd9XPL6kiVJSLXdD0OTJ5pnCN150pSfnHG5eYaku2zrhe5Y19o8w9Suj5ryp9ra1p+VJH1vi9/7hW3tV0n69oFapnxcbrR5htzcSFM+/Fn7usrXDnralH9xov3nYtqgN0z5WUeGmWeYcqltnexbvrrVPMOeirVN+VyXa54hGBwJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeBL0iuIrKw807SgkxN732cOyTfl+x+aYZ4j4OseUfyBrsHmGDZ1amfIxbb41z/Bajm3x8XY5m80zBAIJpnxYWKh5hqnr/2rKZ9Y7aZ5hyqf3224gyv6z+eLE80z5YbW+MM/gnDPlsw+9bZ5Bzvb8cNXkHeYR/jb/L6Z8dttK5hnObbfHlI97M848Q25urvk2fgscCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeBFyQi3D2eKiTaUcJCWVNeUl6e30XUz7t1dfMMzx0/Wem/LvNLjDPEBdnW2sz5qR9PeFTk/aY8plTLjPPUK5cOVN+zaEq5hnap68w5RPf3WeeYeJG2305ovkb5hl0dYwpvj+0lnmEOauvN+UzVn9jniEm5jtTPhCob56hYcPGpnxGVnnzDG2nbDXlPxnfzDzDN9+8ZMpnZ9vWr5ekPXueLHEbjoQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPCEEgYAwBNKGAAATyhhAAA8CTjnXDAb1rj276YdZWZmmfKSdEuf5aZ8pRNfmmf4JLSVKX/R+g3mGbZd0dGUX7XUtgi8JP2/rZNN+a3n3WaeISwszJRvccMq8wwvvtbflM+IzjDPEP3hj6Z8kE8BxRpZ6QlTPvzuePMM1sfDfavuNs8Quv6QKT+u9zPmGRZtXWjK59yxwzxD+gPHTPnY2GbmGQ7UTzHlS6Ozvpndt8RtOBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPAl6Ac6KJyqadpSSctiUl6Q3wq8z5feuyDHPMKn3Q6b85PeuNM/QpZNtncvSWD/2nBlJpnzlF5ubZzh82PaYavLBbvMMf7riaVO+6SffmmeY1GGiKX9Vc9tawJI0/RHb47pv2A/mGT44VNaUv/GyReYZEmP2mvJxH5Q1z9Bk3FpTPvmvueYZXGQTU370hfeaZxhX1/aYtD9LBocjYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8CLsgV3icv727aUWhIqCkvSX//vqUpP3iyffHyqX8cacrPP3e+eYY7V3Y35UeE2O+Hh+6925RvcOxy8wy55+8w5b/8u33Z7iM6YsoHkg+aZ5hY7jlTftVfbIufS9K2h9qZ8lnHN5hnCA+3fT/Dw88xz5AT3tiUr3h1RfMM4Z+EmfIp+1eZZ0i4v5Yp/9M/KplnuHfNKFM+PCLcPEO/bV+XuA1HwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnQS88efLkSdOOMjMzTXlJCltX25RPndrIPEPUmkhTfk/TQ+YZhl/wrCn/eVoV8ww9ot425atHzjXP8PBztvVCp5471TzD7DY3m/I7ouuZZxi1qq0pH2e/G5SVtcWUDw09zzzDqVO255j09FTzDJGR75ryoeurm2c4/NNPpvzxrGbmGeqnfWjKH1qVa55h6B+GmPLly1cwz9AviG04EgYAwBNKGAAATyhhAAA8oYQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPAkLNgNl4y/zLSjjIwMU16SIkeeMuWrpH9tniE8PMKU35VTzTyDy3amfFiYLS9JS9cPMOVvenu0eYaY+I9M+UeuusE8ww9jK5ny4RfZFy+ffs0/TPmcpBzzDNuja5vyX+XWNc9wKO4CU/6HXbavQZJC9oaa8plflzfPkHbOIdsMrdPNM+Tm2B7X91/yrnmGrPdXm/KhYUHXYzH6lrgFR8IAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ0EvmHjqqgqmHQUC9r7/y8Z7TfmwNNtan5IUWs72dYSEhZtnCA+33caL6/qbZ5iUO96Ur3JzTfMMzUM3mPJ3zL7dPENoy0xTPvONveYZxoX8jylf5w8/mmf4855XTfn5z11vnmFWzUdN+ZMnT5pniG4fZcpnN7av7Zx9QZYpHxFhWzNdkraEVjfll7W61DxDfMd4U740Hg/B/GRyJAwAgCeUMAAAnlDCAAB4QgkDAOAJJQwAgCeUMAAAnlDCAAB4QgkDAOAJJQwAgCeUMAAAnlDCAAB4QgkDAOAJJQwAgCeUMAAAnlDCAAB4QgkDAOBJWLAbnpNoW3w8K9O2+LkkhT5sW8x+ctat5hm6THrdlF+w+gbzDOXLVzDl69a3LbgtSTV22G5jW6tzzTPM+KCDKZ+9z/6YnJn2sCl/dPIp8wzZ49NMefemfSH5UedOMuWnxE8wz/DYncEsoX5mx48fN89Qr149W/7AIvMMb2dfbMqHBALmGSLCI035/RurmWeIiYk25bOysswzBIMjYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMCTgHPOBbPheZc+Z92VMS+V75diyh+b9JV5htGRyab8uM73m2eo+qFt/ddlkzaaZ8h8OcOU7xF5nXmGw8s+M+VvGL/WPMOaR2xfx/+7903zDDXnbTXlU7flmmeIaZVtyodcG2ufYZftOSZtcbp5hpUNHzflt1c+Yp7h7gtHmvJjPx5mniH+7U9M+ekdPzbPMP5D2/rS4eG29esladu2u0vchiNhAAA8oYQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPCEEgYAwBNKGAAAT8KC3TD9i6OmHZUtm2DKS9LhMV+b8qGhtc0zrBllW3w8dGyoeYYaLS405aed18Q8Q8qPO035yL22BdglKSyilim/eN1N5hlmXfaoKb82o5Z5hqe29Dflp7daZJ5B39h+nx+99V7zCJmL95ryFz3kzDOMfOMxU773movNM8xYc4kp/9C0p80zfL/qR1N++KdTzTNUvf+4KR8ZEW6eIRgcCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeBL2ecG7wmxbppyMnTXlJevDad0z5e3cMN8+waew+Uz402v57T/mycaZ86vit5hliRla35ddEmmdoX3auKV/72HrzDBMW9DXl72n7vnmGpV2uMuXfu7SNeYZNamm7gdFrzTM0Gl/elE955ALzDKvvP2LKh7ia5hn6vf2sKT990jXmGU6Wa2XK9xr+hnmGtz/qY8ofSU83z6CeJW/CkTAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnYcFu2GTCTtOOAoGAKS9JGTOzTPnonI3mGRLGNTXlU8ftM8+QnX2RKd9j9HbzDKuORZryo/842zzDrl27TPlZZYaYZ0j5sZwp/+WxLeYZJn041ZSf8MFY8wxRd+815dNvv9A8w7jUl0356Ktsz3GStOaur035sPNbmGeof2W4KR/6j4bmGe4c9XdTfkONe80zDCy/1JT/KfUn8wzSjSVuwZEwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4EnQ6wn3m2tbq7M0LB7Z25QfMvZ58wzjVzc35ae3f8Q8w4XZm0z5XTn29ULLhZ0y5beG/NE8w+Mf3GTKR/9hv3kGnTpgilce8415hB/S0035nLLZ5hn+5+uZpvyz3z9jnmFaswdM+QEthplnWFJloCmfO8G+3vjmic1M+XtTHjPPcN99F5vyA6Y8bp5Bx78wxSsGfptjVI6EAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPAk451wwG/Z5/GrTjipXrmzKS9LyDbaFosdvmmCeIWRwnCl/32t3m2e4ov9JUz7t2SbmGa6rMcSU/6RDO/MM5931iin/zNgh5hkO37/LlI8eXcc8Q/qkz035kJjLzTOEZX9vyj/T93XzDM9dO86U3/w/h80zpP2405QPP6e2eYbut/zdlA8LCZhnWJLW15S/JNr+eHh3ou25OhCw3w/7979Q4jYcCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeBL2ecI1+tjUqY2NjTXlJSk1NNeUjI6PMM0hB3V1n1PmS1aUwg22dy/entzZPkH57gik/OmG6eYbNR8ua8uuiu5tnuDBiuykfPfo98wxLooaZ8jGKMc/QferHpvznX1xvnuHU2gxT/rvvDphnCL08zJRv1+xl8wzvTEgy5cfXfM48g3Up3sxBtvuxNJw6dcp8G0MGf1fiNhwJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeBJwzgW1Sv3CAQ1NO0pNTTXlJSk0NNSUj4yMNM8w9v0/m/LR0dHmGU6cOGHKB/5axTzDmPIPmvLT1o81z9Cz3VxTPnPyPvMMS09dasqPGrjSPEPEpghT/rGjj5lnqFTmn6Z808HfmGcISfvelF/+4wXmGU6llzPlkyrvN8+QmPUPU77l/h/MM0x48VZTPjUpyjzD+Z1tj6nc3FzzDO8M+luJ23AkDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHgSFuyGI5sPNe3o1KlTprwkhTx8yJTv93SKeYaITXtN+Q732dYC/lnAlE7+oIF5gimrB5jyg0LHmWdI71DHlH+pzCjzDLfe+4gpvzOqjXmGj/8x2JR/arhtbWhJSkuzPa6/3fGteYadNeqb8umvVzTPEChnO67ZHdfMPEOTFh+Y8qNeGGCeYcykv5vyo4f3Ms9Q60rbeuGhEUHXowlHwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ4EnHMumA3/WtG24HVMTIwpL0l/v3OYKX/OwRrmGX5attWUz2pT2TxDdHS0KZ8dn22eIepUlCmf1TTdPINLti26HX7FQfMMIZtrmfK19x4yz3DdlBRTvv6XG8wzLPzrV6Z88ti7zDPkvlPdlA/vFDDP0D7yNVN+9ZjzzTOMv+FZU35e3W7mGXZ9bvs6Ql9ZZ57h8jFppnx4eIR5hqf7LSpxG46EAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE+CXpA1d2J9045OhYWa8pI0Kme6KR/2RaZ5hlcmDTDlt62zrYErSS48qCWgz5z/0TyC2l+2wpR/Y3QT8wzTKi425Y/H2r8XqVvjTflNtZ4yz/Dt0SWm/APv/Nk8w4ncVaZ8H7fSPENSuG196A3hF9lnyNxoyrfu+b55htDXbOuNDyhr/17ofNttDE+/wTxCjfHzTfmQkFI4Ru0XxH7sewEAAL8GJQwAgCeUMAAAnlDCAAB4QgkDAOAJJQwAgCeUMAAAnlDCAAB4QgkDAOAJJQwAgCeUMAAAnlDCAAB4QgkDAOAJJQwAgCeUMAAAnlDCAAB4EvSq5omzbAtml4ajg7NM+ZiICPMM2+6LMeUnlp1oniFgXGw613Y3SpKGR//VlC8TcdQ8Q0ZGhikfEmJ/PCSfO8OUT6+bYp4hNTXVlA8NDTXPEHZ1J1P+negE8wxZ17xqyidOXmWeYdbFj5nyE6pNMs9QoUolUz41cNg8w/BTw035ydOnmGf4JreOKW99fgkWR8IAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ0GvJ1ymTBnTjo4eta8fGxFpW/81oax9zdKcnBxT3jlnniFgzQestyCFh4eb8hGlsLZzWlqaKR8p22Nakr788ktT3oXbHw/t2saa8tafbUk6kmL7+T52zP78kBZz0pSvWrWKeYbQ0KCfUosUFxdnnqFp06am/K6fdppnyMqyLVruZP+5sKpYseJvsh+OhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADwJuNJYZR4AAJw1joQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPDk/wO47L1OeNuGPQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from torchcam.methods import GradCAM\n",
        "from torchcam.utils import overlay_mask\n",
        "\n",
        "# === Setup ===\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.eval().to(device)\n",
        "\n",
        "# === Choose target layer for GradCAM ===\n",
        "target_layer = 'ltb3.conv.0'  # Change if needed\n",
        "cam_extractor = GradCAM(model, target_layer=target_layer)\n",
        "\n",
        "# === Load 1 test sample ===\n",
        "inputs, targets = next(iter(test_loader))\n",
        "input_tensor = inputs[0].unsqueeze(0).to(device)  # [1, 1, D, H, W]\n",
        "true_label = targets[0].item()\n",
        "\n",
        "# === Forward pass & CAM extraction ===\n",
        "with torch.set_grad_enabled(True):\n",
        "    scores = model(input_tensor)\n",
        "    pred_class = scores.argmax(dim=1).item()\n",
        "    cams = cam_extractor(pred_class, scores)  # list of CAMs\n",
        "\n",
        "# === Get the CAM tensor ===\n",
        "cam = cams[0]  # Could be [1, D, H, W] or [D, H, W]\n",
        "if cam.dim() == 3:\n",
        "    cam = cam.unsqueeze(0).unsqueeze(0)  # â†’ [1, 1, D, H, W]\n",
        "elif cam.dim() == 4:\n",
        "    cam = cam.unsqueeze(0)               # â†’ [1, 1, D, H, W]\n",
        "# Else: already fine\n",
        "\n",
        "# === Interpolate CAM to input shape ===\n",
        "target_shape = input_tensor.shape[2:]  # [D, H, W]\n",
        "cam_upsampled = F.interpolate(cam, size=target_shape, mode=\"trilinear\", align_corners=False)\n",
        "\n",
        "cam_volume = cam_upsampled.squeeze().cpu()  # [D, H, W]\n",
        "\n",
        "# === Get input volume ===\n",
        "input_volume = input_tensor.squeeze().cpu()  # [D, H, W]\n",
        "\n",
        "# === Pick a middle slice ===\n",
        "slice_idx = input_volume.shape[0] // 2\n",
        "input_slice = input_volume[slice_idx]  # [H, W]\n",
        "cam_slice = cam_volume[slice_idx]      # [H, W]\n",
        "\n",
        "# === Normalize both slices ===\n",
        "input_norm = (input_slice - input_slice.min()) / (input_slice.max() - input_slice.min() + 1e-6)\n",
        "cam_norm = (cam_slice - cam_slice.min()) / (cam_slice.max() - cam_slice.min() + 1e-6)\n",
        "\n",
        "# === Convert to PIL images ===\n",
        "input_pil = to_pil_image(input_slice)\n",
        "cam_pil = to_pil_image(cam_slice)\n",
        "\n",
        "# Convert grayscale input to RGB for overlay\n",
        "input_pil = input_pil.convert(\"RGB\")\n",
        "\n",
        "# === Overlay CAM ===\n",
        "overlay = overlay_mask(input_pil, cam_pil, alpha=0.5)\n",
        "\n",
        "# === Plot ===\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(overlay)\n",
        "plt.title(f\"Grad-CAM Overlay (slice {slice_idx}) | Pred: {pred_class} | GT: {target_class}\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "Y-eeHmrDD3N9",
        "outputId": "1edd4a61-d082-488f-c309-3d533d6c3e74"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from torchcam.methods import GradCAM\n",
        "from torchcam.utils import overlay_mask\n",
        "\n",
        "# === Prepare your model ===\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Choose a target layer name from your model â€” ltb3 is good\n",
        "target_layer = \"ltb3\"\n",
        "\n",
        "# Initialize GradCAM\n",
        "cam_extractor = GradCAM(model, target_layer=target_layer)\n",
        "\n",
        "# === Pick one test sample ===\n",
        "inputs, targets = next(iter(test_loader))\n",
        "inputs = inputs.to(device)\n",
        "input_tensor = inputs[0].unsqueeze(0)  # [1, C, D, H, W]\n",
        "target_class = targets[0].item()\n",
        "\n",
        "# === Forward pass and CAM generation ===\n",
        "output = model(input_tensor)\n",
        "pred_class = output.argmax(dim=1).item()\n",
        "\n",
        "# Generate CAM\n",
        "cams = cam_extractor(pred_class, output)\n",
        "cam = cams[0]\n",
        "\n",
        "if cam.dim() == 3:\n",
        "    cam = cam.unsqueeze(0).unsqueeze(0)  # â†’ [1, 1, D, H, W]\n",
        "elif cam.dim() == 4:\n",
        "    cam = cam.unsqueeze(0)               # â†’ [1, 1, D, H, W]\n",
        "# === Interpolate CAM to match input size ===\n",
        "target_shape = input_tensor.shape[2:]  # [D, H, W]\n",
        "cam_upsampled = F.interpolate(cam, size=target_shape, mode=\"trilinear\", align_corners=False)\n",
        "\n",
        "cam_volume = cam_upsampled.squeeze().cpu()  # [D, H, W]\n",
        "\n",
        "\n",
        "# === Normalize input volume ===\n",
        "input_volume = input_tensor.squeeze().cpu()  # [D, H, W]\n",
        "input_volume = (input_volume - input_volume.min()) / (input_volume.max() - input_volume.min())\n",
        "\n",
        "# === Choose center slice ===\n",
        "slice_idx = input_volume.shape[0] // 2\n",
        "input_slice = input_volume[slice_idx]  # [H, W]\n",
        "cam_slice = cam_volume[slice_idx]      # [H, W]\n",
        "\n",
        "# Normalize CAM slice\n",
        "cam_slice = (cam_slice - cam_slice.min()) / (cam_slice.max() - cam_slice.min())\n",
        "\n",
        "# Convert grayscale input to RGB for overlay\n",
        "input_pil = input_pil.convert(\"RGB\")\n",
        "\n",
        "# === Overlay CAM ===\n",
        "overlay = overlay_mask(input_pil, cam_pil, alpha=0.5)\n",
        "\n",
        "# === Plot result ===\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(overlay)\n",
        "plt.title(f\"Grad-CAM (target: {target_class}, pred: {pred_class})\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAxSMlFfBlU5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}