{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2155d5e7"
      },
      "source": [
        "Now you can run the previous cell to import `torch` and `make_dot`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAI9r5x9Mjhw"
      },
      "source": [
        "Replicate original script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qe8mtlWoU9yI"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "## reduce GPU\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "for gpu in gpus:\n",
        "    tf.config.experimental.set_memory_growth(gpu, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFtychH7MlvN",
        "outputId": "55d48d94-4efd-426f-c470-bc34cc67ebb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting medmnist==3.0.1\n",
            "  Downloading medmnist-3.0.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting torchattacks\n",
            "  Downloading torchattacks-3.5.1-py3-none-any.whl.metadata (927 bytes)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (0.25.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (4.67.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (11.3.0)\n",
            "Collecting fire (from medmnist==3.0.1)\n",
            "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from medmnist==3.0.1) (0.21.0+cu124)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from torchattacks) (1.16.1)\n",
            "Collecting requests~=2.25.1 (from torchattacks)\n",
            "  Downloading requests-2.25.1-py2.py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting chardet<5,>=3.0.2 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading chardet-4.0.0-py2.py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting idna<3,>=2.5 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl.metadata (9.1 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1 (from requests~=2.25.1->torchattacks)\n",
            "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests~=2.25.1->torchattacks) (2025.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->medmnist==3.0.1)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->medmnist==3.0.1) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->medmnist==3.0.1) (1.3.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from fire->medmnist==3.0.1) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist==3.0.1) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist==3.0.1) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->medmnist==3.0.1) (2025.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist==3.0.1) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist==3.0.1) (2025.6.11)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist==3.0.1) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->medmnist==3.0.1) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist==3.0.1) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->medmnist==3.0.1) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->medmnist==3.0.1) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->medmnist==3.0.1) (3.0.2)\n",
            "Downloading medmnist-3.0.1-py3-none-any.whl (25 kB)\n",
            "Downloading torchattacks-3.5.1-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.0/142.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.25.1-py2.py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chardet-4.0.0-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114249 sha256=2152e79489be2cb23efa32a38a70c1032cc1ca0907f3e5d3951710d6efb6e66f\n",
            "  Stored in directory: /root/.cache/pip/wheels/46/54/24/1624fd5b8674eb1188623f7e8e17cdf7c0f6c24b609dfb8a89\n",
            "Successfully built fire\n",
            "Installing collected packages: urllib3, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, idna, fire, chardet, requests, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchattacks, medmnist\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.3, but you have requests 2.25.1 which is incompatible.\n",
            "yfinance 0.2.65 requires requests>=2.31, but you have requests 2.25.1 which is incompatible.\n",
            "tiktoken 0.10.0 requires requests>=2.26.0, but you have requests 2.25.1 which is incompatible.\n",
            "datasets 4.0.0 requires requests>=2.32.2, but you have requests 2.25.1 which is incompatible.\n",
            "sphinx 8.2.3 requires requests>=2.30.0, but you have requests 2.25.1 which is incompatible.\n",
            "libpysal 4.13.0 requires requests>=2.27, but you have requests 2.25.1 which is incompatible.\n",
            "google-genai 1.28.0 requires requests<3.0.0,>=2.28.1, but you have requests 2.25.1 which is incompatible.\n",
            "tweepy 4.16.0 requires requests<3,>=2.27.0, but you have requests 2.25.1 which is incompatible.\n",
            "bigframes 2.13.0 requires requests>=2.27.1, but you have requests 2.25.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed chardet-4.0.0 fire-0.7.0 idna-2.10 medmnist-3.0.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 requests-2.25.1 torchattacks-3.5.1 urllib3-1.26.20\n"
          ]
        }
      ],
      "source": [
        "!pip install medmnist==3.0.1 \\\n",
        "    torchattacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "_aD3CYXqM06G"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "\n",
        "import torchvision.utils\n",
        "from torchvision import models\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary\n",
        "\n",
        "from tqdm import tqdm\n",
        "import medmnist\n",
        "from medmnist import INFO, Evaluator\n",
        "\n",
        "import torchattacks\n",
        "from torchattacks import PGD, FGSM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2CsEux3TNGoi",
        "outputId": "b4ec31fd-7b24-4971-8f84-7c3f5852ab66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch 2.6.0+cu124\n",
            "Torchvision 0.21.0+cu124\n",
            "Torchattacks 3.5.1\n",
            "Numpy 2.0.2\n",
            "Medmnist 3.0.1\n"
          ]
        }
      ],
      "source": [
        "print(\"PyTorch\", torch.__version__)\n",
        "print(\"Torchvision\", torchvision.__version__)\n",
        "print(\"Torchattacks\", torchattacks.__version__)\n",
        "print(\"Numpy\", np.__version__)\n",
        "print(\"Medmnist\", medmnist.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZfjcPbQNdfi"
      },
      "source": [
        "##Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torchvision.transforms.transforms import Resize\n",
        "# # [tissuemnist, pathmnist, chestmnist, dermamnist, octmnist,\n",
        "# # pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "# # --- Helper to create a single batch with all classes ---\n",
        "# def get_one_batch_with_all_classes(dataset, num_classes, batch_size=32):\n",
        "#     loader = data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False)\n",
        "#     all_inputs, all_targets = [], []\n",
        "#     seen_classes = set()\n",
        "\n",
        "#     for x, y in loader:\n",
        "#         all_inputs.append(x)\n",
        "#         all_targets.append(y)\n",
        "#         seen_classes.update(y.squeeze().tolist())\n",
        "\n",
        "#         if len(seen_classes) == num_classes:\n",
        "#             # Combine into one batch\n",
        "#             all_inputs = torch.cat(all_inputs, dim=0)\n",
        "#             all_targets = torch.cat(all_targets, dim=0)\n",
        "#             return [(all_inputs, all_targets)]\n",
        "#     raise ValueError(f\"Could not find all {num_classes} classes in the dataset.\")\n",
        "# def data_input_loading(data_flag = 'pathmnist', BATCH_SIZE = 15,\n",
        "#                        lr = 0.0005, NUM_EPOCHS = 5, ):\n",
        "#   data_flag = data_flag\n",
        "#   download = True\n",
        "#   NUM_EPOCHS = NUM_EPOCHS\n",
        "#   BATCH_SIZE = BATCH_SIZE\n",
        "#   lr = lr\n",
        "#   info = INFO[data_flag]\n",
        "#   task = info['task']\n",
        "#   n_channels = info['n_channels']\n",
        "#   n_classes = len(info['label'])\n",
        "#   DataClass = getattr(medmnist, info['python_class'])\n",
        "#   # preprocessing\n",
        "#   train_transform = transforms.Compose([\n",
        "#       transforms.Resize(224),\n",
        "#       transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "#       torchvision.transforms.AugMix(),\n",
        "#       transforms.ToTensor(),\n",
        "#       transforms.Normalize(mean=[.5], std=[.5])\n",
        "#   ])\n",
        "#   test_transform = transforms.Compose([\n",
        "#       transforms.Resize(224),\n",
        "#       transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "#       transforms.ToTensor(),\n",
        "#       transforms.Normalize(mean=[.5], std=[.5])\n",
        "#   ])\n",
        "\n",
        "#   # load the data\n",
        "#   train_dataset = DataClass(split='train', transform=train_transform, download=download)\n",
        "#   test_dataset = DataClass(split='test', transform=test_transform, download=download)\n",
        "#   # encapsulate data into dataloader form\n",
        "#   train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "#   # evaluation loaders (only one batch with all classes)\n",
        "#   train_loader_at_eval = get_one_batch_with_all_classes(train_dataset, n_classes, batch_size=2*BATCH_SIZE)\n",
        "#   test_loader = get_one_batch_with_all_classes(test_dataset, n_classes, batch_size=2*BATCH_SIZE)\n",
        "#   return data_flag, NUM_EPOCHS, BATCH_SIZE, lr, task, train_loader, train_loader_at_eval, test_loader, n_classes"
      ],
      "metadata": {
        "id": "wiR6wvLdjmht"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# data_flag = 'pathmnist'\n",
        "# BATCH_SIZE = 15\n",
        "# lr = 0.0005\n",
        "# NUM_EPOCHS = 5\n",
        "# data_flag, NUM_EPOCHS, BATCH_SIZE, lr, task, train_loader, train_loader_at_eval, test_loader, n_classes = data_input_loading(data_flag, BATCH_SIZE, lr, NUM_EPOCHS)"
      ],
      "metadata": {
        "id": "ODKWp3uEjv28"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# len(train_loader), len(train_loader_at_eval), len(test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeVnHTHPj7GT",
        "outputId": "d1ae9a03-d05f-4c9d-aa24-167680c19d5b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6000, 1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### lower down sample: 1000 sample\n",
        "from torch.utils.data import Subset, random_split, DataLoader\n",
        "from torchvision import transforms\n",
        "import torchvision\n",
        "import random\n",
        "import torch\n",
        "import medmnist\n",
        "from medmnist import INFO\n",
        "\n",
        "# --- Helper to create a single batch with all classes ---\n",
        "def get_one_batch_with_all_classes(dataset, num_classes, batch_size=32):\n",
        "    loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False)\n",
        "    all_inputs, all_targets = [], []\n",
        "    seen_classes = set()\n",
        "\n",
        "    for x, y in loader:\n",
        "        all_inputs.append(x)\n",
        "        all_targets.append(y)\n",
        "        seen_classes.update(y.squeeze().tolist())\n",
        "\n",
        "        if len(seen_classes) == num_classes:\n",
        "            all_inputs = torch.cat(all_inputs, dim=0)\n",
        "            all_targets = torch.cat(all_targets, dim=0)\n",
        "            return [(all_inputs, all_targets)]\n",
        "    raise ValueError(f\"Could not find all {num_classes} classes in the dataset.\")\n",
        "\n",
        "def data_input_loading(data_flag='pathmnist', BATCH_SIZE=15, lr=0.0005, NUM_EPOCHS=5, total_samples=1000):\n",
        "    download = True\n",
        "    info = INFO[data_flag]\n",
        "    task = info['task']\n",
        "    n_channels = info['n_channels']\n",
        "    n_classes = len(info['label'])\n",
        "    DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "    # preprocessing\n",
        "    train_transform = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "        torchvision.transforms.AugMix(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[.5], std=[.5])\n",
        "    ])\n",
        "    test_transform = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.Lambda(lambda image: image.convert('RGB')),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[.5], std=[.5])\n",
        "    ])\n",
        "\n",
        "    # Load full dataset first (train + test combined)\n",
        "    full_dataset = DataClass(split='train', transform=train_transform, download=download)\n",
        "    test_dataset_full = DataClass(split='test', transform=test_transform, download=download)\n",
        "    combined_dataset = torch.utils.data.ConcatDataset([full_dataset, test_dataset_full])\n",
        "\n",
        "    # ✅ Randomly select only total_samples items\n",
        "    indices = random.sample(range(len(combined_dataset)), total_samples)\n",
        "    small_dataset = Subset(combined_dataset, indices)\n",
        "\n",
        "    # ✅ Split into train / val / test (e.g., 70/15/15 split)\n",
        "    train_size = int(0.7 * total_samples)\n",
        "    val_size = int(0.15 * total_samples)\n",
        "    test_size = total_samples - train_size - val_size\n",
        "    train_dataset, val_dataset, test_dataset = random_split(small_dataset, [train_size, val_size, test_size])\n",
        "\n",
        "    # Dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    train_loader_at_eval = get_one_batch_with_all_classes(train_dataset, n_classes, batch_size=2*BATCH_SIZE)\n",
        "    test_loader = get_one_batch_with_all_classes(test_dataset, n_classes, batch_size=2*BATCH_SIZE)\n",
        "\n",
        "    return data_flag, NUM_EPOCHS, BATCH_SIZE, lr, task, train_loader, train_loader_at_eval, test_loader, n_classes\n"
      ],
      "metadata": {
        "id": "j15SWM--OOp4"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEcZP5e2O18E"
      },
      "source": [
        "## Model loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ny4ySw8G2Xyq",
        "outputId": "0369902a-079c-4e7f-c4d3-250004d34408"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device = torch.device(\"cpu\")\n",
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zez5UZctOatI",
        "outputId": "324c474b-cd06-4e1a-845d-a9f911def270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "from MedViT import MedViT_small\n",
        "\n",
        "# model = MedViT_small(num_classes = n_classes).to(device)\n",
        "# model = MedViT_small(num_classes = n_classes).cuda()\n",
        "#model = MedViT_base(num_classes = n_classes).cuda()\n",
        "#model = MedViT_large(num_classes = n_classes).cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EwqJwVrPm0V"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a72X8QrUq1Bk"
      },
      "source": [
        "### Team7: Modify script to continue train by loading history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "5PGUehVkwl4y"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "import pandas as pd\n",
        "\n",
        "# evaluation\n",
        "def getAUC(y_true, y_score, task):\n",
        "    \"\"\"AUC metric.\n",
        "    :param y_true: the ground truth labels, shape: (n_samples, n_labels) or (n_samples,) if n_labels==1\n",
        "    :param y_score: the predicted score of each class,\n",
        "    shape: (n_samples, n_labels) or (n_samples, n_classes) or (n_samples,) if n_labels==1 or n_classes==1\n",
        "    :param task: the task of current dataset\n",
        "    \"\"\"\n",
        "    y_true = y_true.squeeze()\n",
        "    y_score = y_score.squeeze()\n",
        "\n",
        "    if task == \"multi-label, binary-class\":\n",
        "        auc = 0\n",
        "        for i in range(y_score.shape[1]):\n",
        "            label_auc = roc_auc_score(y_true[:, i], y_score[:, i])\n",
        "            auc += label_auc\n",
        "        ret = auc / y_score.shape[1]\n",
        "    elif task == \"binary-class\":\n",
        "        if y_score.ndim == 2:\n",
        "            y_score = y_score[:, -1]\n",
        "        else:\n",
        "            assert y_score.ndim == 1\n",
        "        ret = roc_auc_score(y_true, y_score)\n",
        "    else:\n",
        "        auc = 0\n",
        "        for i in range(y_score.shape[1]):\n",
        "            y_true_binary = (y_true == i).astype(float)\n",
        "            y_score_binary = y_score[:, i]\n",
        "            auc += roc_auc_score(y_true_binary, y_score_binary)\n",
        "        ret = auc / y_score.shape[1]\n",
        "\n",
        "    return ret\n",
        "\n",
        "\n",
        "def getACC(y_true, y_score, task, threshold=0.5):\n",
        "    \"\"\"Accuracy metric.\n",
        "    :param y_true: the ground truth labels, shape: (n_samples, n_labels) or (n_samples,) if n_labels==1\n",
        "    :param y_score: the predicted score of each class,\n",
        "    shape: (n_samples, n_labels) or (n_samples, n_classes) or (n_samples,) if n_labels==1 or n_classes==1\n",
        "    :param task: the task of current dataset\n",
        "    :param threshold: the threshold for multilabel and binary-class tasks\n",
        "    \"\"\"\n",
        "    y_true = y_true.squeeze()\n",
        "    y_score = y_score.squeeze()\n",
        "\n",
        "    if task == \"multi-label, binary-class\":\n",
        "        y_pre = y_score > threshold\n",
        "        acc = 0\n",
        "        for label in range(y_true.shape[1]):\n",
        "            label_acc = accuracy_score(y_true[:, label], y_pre[:, label])\n",
        "            acc += label_acc\n",
        "        ret = acc / y_true.shape[1]\n",
        "    elif task == \"binary-class\":\n",
        "        if y_score.ndim == 2:\n",
        "            y_score = y_score[:, -1]\n",
        "        else:\n",
        "            assert y_score.ndim == 1\n",
        "        ret = accuracy_score(y_true, y_score > threshold)\n",
        "    else:\n",
        "        ret = accuracy_score(y_true, np.argmax(y_score, axis=-1))\n",
        "\n",
        "    return ret\n",
        "\n",
        "def test(data_loader, model, criterion, task):\n",
        "    model.eval()\n",
        "    y_true = torch.tensor([]).to(device)\n",
        "    y_score = torch.tensor([]).to(device)\n",
        "    data_loader = data_loader\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in data_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            if task == 'multi-label, binary-class':\n",
        "                targets = targets.to(torch.float32)\n",
        "                loss = criterion(outputs, targets)\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "            else:\n",
        "                targets = targets.squeeze().long()\n",
        "                loss = criterion(outputs, targets)\n",
        "                outputs = outputs.softmax(dim=-1)\n",
        "                targets = targets.float().resize_(len(targets), 1)\n",
        "\n",
        "            y_true = torch.cat((y_true, targets), 0)\n",
        "            y_score = torch.cat((y_score, outputs), 0)\n",
        "            total_loss += loss.item()\n",
        "            num_batches += 1\n",
        "\n",
        "        y_true = y_true.cpu().numpy()\n",
        "        y_score = y_score.detach().cpu().numpy()\n",
        "\n",
        "        auc = getAUC(y_true, y_score, task)\n",
        "        acc = getACC(y_true, y_score, task)\n",
        "        avg_loss = total_loss / num_batches\n",
        "\n",
        "        return auc, acc ,avg_loss #, y_true, y_score\n",
        "\n",
        "\n",
        "def load_or_initialize_model(model_class, model_name, optimizer_class, lr, momentum, n_classes, task):\n",
        "    model_dir = \"./history_record\"\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    model_path = os.path.join(model_dir, f\"{model_name}.pth\")\n",
        "    history_path = os.path.join(model_dir, f\"{model_name}.csv\")\n",
        "\n",
        "\n",
        "    model = MedViT_small(num_classes = n_classes).to(device)\n",
        "\n",
        "    optimizer = optimizer_class(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "    start_epoch = 0\n",
        "    best_val_auc = 0\n",
        "    history = {\n",
        "        \"train_auc\": [], \"train_acc\": [],\n",
        "        \"val_auc\": [], \"val_acc\": [],\n",
        "        \"train_loss\": [], \"val_loss\": []\n",
        "    }\n",
        "\n",
        "    if os.path.exists(model_path) and os.path.exists(history_path):\n",
        "        print(f\"Loading existing model: {model_name}\")\n",
        "        checkpoint = torch.load(model_path, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        history = pd.read_csv(history_path).to_dict(orient='list')\n",
        "        start_epoch = len(history[\"train_loss\"])\n",
        "        best_val_auc = max(history[\"val_auc\"]) if history[\"val_auc\"] else 0\n",
        "\n",
        "    return model, optimizer, history, start_epoch, best_val_auc\n",
        "def training_and_record(model_class,\n",
        "                        model_name,\n",
        "                        NUM_EPOCHS, lr,\n",
        "                        momentum, train_loader,\n",
        "                        train_loader_at_eval,\n",
        "                        test_loader,\n",
        "                        n_classes,\n",
        "                        task,\n",
        "                        steps):\n",
        "    model, optimizer, history, start_epoch, best_val_auc = load_or_initialize_model(\n",
        "        model_class, model_name, optimizer_class=torch.optim.SGD, lr=lr, momentum=momentum, n_classes = n_classes,\n",
        "        task = task\n",
        "    )\n",
        "    if task == \"multi-label, binary-class\":\n",
        "        criterion = nn.BCEWithLogitsLoss()\n",
        "    else:\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "    total_loss = 0\n",
        "    step_count = 0  # counter for batch steps\n",
        "    for epoch in range(start_epoch, start_epoch + NUM_EPOCHS):\n",
        "        print(f'\\nEpoch [{epoch + 1}/{start_epoch + NUM_EPOCHS}]')\n",
        "        model.train()\n",
        "\n",
        "        for inputs, targets in tqdm(train_loader):\n",
        "            step_count += 1\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            unique_classes = np.unique(targets.cpu().numpy())\n",
        "            # print(f\"Unique class in target data batch is: {unique_classes.tolist()}  | Count: {len(unique_classes)}\")\n",
        "            if task == 'multi-label, binary-class':\n",
        "                # print(\"Going to multi-label, bunary-class branch\")\n",
        "                # Ensure targets become [B, n_classes] float\n",
        "                targets = torch.nn.functional.one_hot(\n",
        "                    targets.squeeze().long(), num_classes=n_classes\n",
        "                ).float().to(device)\n",
        "                # print(\"target shape of original data before loss \", targets.shape)\n",
        "                # print(\"output shape after model, before loss: \", outputs.shape)\n",
        "                loss = criterion(outputs, targets)\n",
        "            else:\n",
        "                # print(\"going to ther branch\")\n",
        "                targets = targets.squeeze().long()  # labels become long\n",
        "                # print(\"target shape of original data before loss \", targets.shape)\n",
        "                # print(\"output shape after model, before loss: \", outputs.shape)\n",
        "                loss = criterion(outputs, targets)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "            # stop after 20 steps per epoch\n",
        "            # if step_count >= steps:\n",
        "            #     print(f\"Breaking after {step_count} steps in this epoch.\")\n",
        "            #     break\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Logging\n",
        "        train_loss = total_loss / len(train_loader)\n",
        "        # validation loss\n",
        "        val_auc, val_acc, val_loss = test(test_loader, model, criterion, task)\n",
        "        # train loss\n",
        "        train_auc, train_acc, train_loss = test( train_loader_at_eval, model, criterion, task)\n",
        "\n",
        "\n",
        "        history[\"train_auc\"].append(train_auc)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"val_auc\"].append(val_auc)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "        history[\"val_loss\"].append(val_loss)\n",
        "\n",
        "\n",
        "        # Save best model\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "            print(\"📌 New best AUC — saving model\")\n",
        "            torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict()\n",
        "            }, f\"./history_record/{model_name}.pth\")\n",
        "\n",
        "        pd.DataFrame(history).to_csv(f\"./history_record/{model_name}.csv\", index=False)\n",
        "\n",
        "    print(\"✅ Training complete.\")\n",
        "    return history\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_flag = 'pathmnist'\n",
        "BATCH_SIZE = 15\n",
        "lr = 0.0005\n",
        "NUM_EPOCHS = 5\n",
        "data_flag, NUM_EPOCHS, BATCH_SIZE, lr, task, train_loader, train_loader_at_eval, test_loader, n_classes = data_input_loading(data_flag, BATCH_SIZE, lr, NUM_EPOCHS)"
      ],
      "metadata": {
        "id": "mFIgGrnlnuLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b56cf8b-515e-474e-f140-f12294a85a0a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 206M/206M [00:11<00:00, 18.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_loader), len(train_loader_at_eval), len(test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dB0x7-o42bnM",
        "outputId": "cd87c22e-a505-4b85-a0b0-782d53927015"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(47, 1, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGWMTlYm0BQj",
        "outputId": "23f8a55a-7df4-41c0-ebd4-e01d0f8e512c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "\n",
            "Epoch [1/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 47/47 [14:43<00:00, 18.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 New best AUC — saving model\n",
            "\n",
            "Epoch [2/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 47/47 [14:51<00:00, 18.98s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 New best AUC — saving model\n",
            "\n",
            "Epoch [3/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 47/47 [14:36<00:00, 18.66s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 New best AUC — saving model\n",
            "\n",
            "Epoch [4/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 47/47 [14:32<00:00, 18.56s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [5/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 47/47 [14:45<00:00, 18.84s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [6/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 47/47 [14:51<00:00, 18.97s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [7/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 18/47 [06:15<10:04, 20.85s/it]"
          ]
        }
      ],
      "source": [
        "\n",
        "history = training_and_record(\n",
        "    model_class=MedViT_small,\n",
        "    model_name=f\"MedViT2D_{data_flag}\",\n",
        "    NUM_EPOCHS=10,\n",
        "    lr=lr,\n",
        "    momentum=0.9,\n",
        "    train_loader=train_loader,\n",
        "    train_loader_at_eval=train_loader_at_eval,\n",
        "    test_loader=test_loader,\n",
        "    n_classes = n_classes,\n",
        "    task = task,\n",
        "    steps = len(train_loader)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hTQSecNogUM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#[tissuemnist, pathmnist, chestmnist, dermamnist, octmnist,\n",
        "# pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "data_flag = 'dermamnist'\n",
        "BATCH_SIZE = 15\n",
        "lr = 0.0005\n",
        "NUM_EPOCHS = 5\n",
        "data_flag, NUM_EPOCHS, BATCH_SIZE, lr, task, train_loader, train_loader_at_eval, test_loader, n_classes = data_input_loading(data_flag, BATCH_SIZE, lr, NUM_EPOCHS)"
      ],
      "metadata": {
        "id": "pWnKwzxk1X92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "215e9e41-1906-4f19-b11e-2cb6418ec85a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 19.7M/19.7M [00:01<00:00, 14.9MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_flag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "AEdYpwJ7DMAP",
        "outputId": "7fb596e9-ba39-48df-a499-874688860712"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'dermamnist'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = training_and_record(\n",
        "    model_class=MedViT_small,\n",
        "    model_name=f\"MedViT2D_{data_flag}\",\n",
        "    NUM_EPOCHS=NUM_EPOCHS,\n",
        "    lr=lr,\n",
        "    momentum=0.9,\n",
        "    train_loader=train_loader,\n",
        "    train_loader_at_eval=train_loader_at_eval,\n",
        "    test_loader=test_loader,\n",
        "    n_classes = n_classes,\n",
        "    task = task,\n",
        "    step_count = 40\n",
        ")\n"
      ],
      "metadata": {
        "id": "0cbx0qKjewd1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42864a9f-3921-4a50-f0ca-a69b1bfd2d93"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initialize_weights...\n",
            "\n",
            "Epoch [1/5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/468 [00:26<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Breaking after 1 steps in this epoch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 New best AUC — saving model\n",
            "\n",
            "Epoch [2/5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/468 [00:19<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Breaking after 2 steps in this epoch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 New best AUC — saving model\n",
            "\n",
            "Epoch [3/5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/468 [00:21<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Breaking after 3 steps in this epoch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 New best AUC — saving model\n",
            "\n",
            "Epoch [4/5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/468 [00:18<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Breaking after 4 steps in this epoch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 New best AUC — saving model\n",
            "\n",
            "Epoch [5/5]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/468 [00:18<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Breaking after 5 steps in this epoch.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a4apYoaTewVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YOJFv2kwewL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TyZlhrPLewGi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P3RO75Kmev90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AHKZjtuOevwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSafnt9RVYe-"
      },
      "source": [
        "## Team7: Now fit into our dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S-mh35j731F"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6_Waxo6Uqm8",
        "outputId": "742d940b-2acb-447b-9366-7bb3b54b66a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(<torch.utils.data.dataloader.DataLoader at 0x7b513964e450>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7b5139677050>,\n",
              " <torch.utils.data.dataloader.DataLoader at 0x7b5139677110>)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# from step1Preprocessing import DATALOAD\n",
        "# xu = DATALOAD(\"mri\", load_mode= \"pytorch\", train_control_sample=100,val_control_sample=20 )\n",
        "# xu.train_ds, xu.val_ds, xu.train_loader_at_eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bW2swY5dVIyb"
      },
      "outputs": [],
      "source": [
        "# # define loss function and optimizer\n",
        "# data_flag = 'retinamnist'\n",
        "# # [tissuemnist, pathmnist, chestmnist, dermamnist, octmnist,\n",
        "# # pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "# download = True\n",
        "\n",
        "# NUM_EPOCHS = 10\n",
        "# BATCH_SIZE = 5\n",
        "# lr = 0.005\n",
        "\n",
        "# info = INFO[data_flag]\n",
        "# task = info['task']\n",
        "\n",
        "# if task == \"multi-label, binary-class\":\n",
        "#     criterion = nn.BCEWithLogitsLoss()\n",
        "# else:\n",
        "#     criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYMEiKZcVhRS",
        "outputId": "683eed9d-4e70-40bf-e97a-45c0e0b1f998"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(10, 10, 1)"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# len(xu.train_ds), len(xu.val_ds), len(xu.train_loader_at_eval)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0SsRHbmp4eP",
        "outputId": "33f2a83b-73bf-4633-c38e-668cde5b1a00"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# n_classes = len(xu.train_ds.dataset.dataset.classes)\n",
        "# n_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCikFuqErA7d",
        "outputId": "bc1740ef-479f-46f9-d99a-0672d44dc9a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initialize_weights...\n"
          ]
        }
      ],
      "source": [
        "# from MedViT import MedViT_small, MedViT_base, MedViT_large\n",
        "# model = MedViT_small(num_classes = n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAtLoK7Cs7CL"
      },
      "outputs": [],
      "source": [
        "# def load_or_initialize_model(model_class, model_name, optimizer_class, lr, momentum):\n",
        "#     model_dir = \"./history_record\"\n",
        "#     os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "#     model_path = os.path.join(model_dir, f\"{model_name}.pth\")\n",
        "#     history_path = os.path.join(model_dir, f\"{model_name}.csv\")\n",
        "\n",
        "#     model = model_class().to(device)\n",
        "#     optimizer = optimizer_class(model.parameters(), lr=lr, momentum=momentum)\n",
        "#     start_epoch = 0\n",
        "#     best_val_auc = 0\n",
        "#     history = {\n",
        "#         \"train_auc\": [], \"train_acc\": [],\n",
        "#         \"val_auc\": [], \"val_acc\": [],\n",
        "#         \"train_loss\": []\n",
        "#     }\n",
        "\n",
        "#     if os.path.exists(model_path) and os.path.exists(history_path):\n",
        "#         print(f\"Loading existing model: {model_name}\")\n",
        "#         checkpoint = torch.load(model_path, map_location=device)\n",
        "#         model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#         optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "#         history = pd.read_csv(history_path).to_dict(orient='list')\n",
        "#         start_epoch = len(history[\"train_loss\"])\n",
        "#         best_val_auc = max(history[\"val_auc\"]) if history[\"val_auc\"] else 0\n",
        "\n",
        "#     return model, optimizer, history, start_epoch, best_val_auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JK6cEwDSjgKi"
      },
      "outputs": [],
      "source": [
        "# ## define new test function: Have to\n",
        "# from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "# from collections import namedtuple\n",
        "# from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "# from collections import namedtuple\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Metrics = namedtuple(\"Metrics\", [\"AUC\", \"ACC\"])\n",
        "\n",
        "# def evaluate_custom(y_true, y_score):\n",
        "#     Metrics = namedtuple(\"Metrics\", [\"AUC\", \"ACC\"])\n",
        "#     y_true = np.array(y_true).reshape(-1)\n",
        "#     if y_score.shape[0] != y_true.shape[0]:\n",
        "#         raise ValueError(\"Mismatch between number of predictions and true labels\")\n",
        "#     y_pred = y_score.argmax(axis=1)\n",
        "#     acc = accuracy_score(y_true, y_pred)\n",
        "#     unique_classes = np.unique(y_true)\n",
        "#     if len(unique_classes) < 2:\n",
        "#         print(\"Skipping AUC: Only one class in ground truth.\")\n",
        "#         auc = -1  # or float('nan')\n",
        "#     else:\n",
        "#         auc = roc_auc_score(y_true, y_score, multi_class='ovr')\n",
        "\n",
        "#     return Metrics(AUC=auc, ACC=acc)\n",
        "\n",
        "# def test(split, train_loader_at_eval, test_loader):\n",
        "#     model.eval()\n",
        "#     y_true = torch.tensor([]).to(device)\n",
        "#     y_score = torch.tensor([]).to(device)\n",
        "\n",
        "#     data_loader = train_loader_at_eval if split == 'train' else test_loader\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for inputs, targets in data_loader:\n",
        "#             inputs, targets = inputs.to(device), targets.to(device)\n",
        "#             outputs = model(inputs)\n",
        "\n",
        "#             if task == 'multi-label, binary-class':\n",
        "#                 targets = targets.to(torch.float32)\n",
        "#                 outputs = outputs.softmax(dim=-1)\n",
        "#             else:\n",
        "#                 targets = targets.squeeze().long()\n",
        "#                 outputs = outputs.softmax(dim=-1)\n",
        "#                 targets = targets.float().resize_(len(targets), 1)\n",
        "\n",
        "#             y_true = torch.cat((y_true, targets), 0)\n",
        "#             y_score = torch.cat((y_score, outputs), 0)\n",
        "\n",
        "#         y_true = y_true.cpu().numpy()\n",
        "#         y_score = y_score.detach().cpu().numpy()\n",
        "\n",
        "#         metrics = evaluate_custom(y_true, y_score)\n",
        "#         print('%s  auc: %.3f  acc:%.3f' % (split, *metrics))\n",
        "#         return metrics #, y_true, y_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JNgywgXDjouC"
      },
      "outputs": [],
      "source": [
        "# def training_and_record(model_class, model_name, NUM_EPOCHS, lr, momentum, train_loader, train_loader_at_eval, test_loader):\n",
        "#     model, optimizer, history, start_epoch, best_val_auc = load_or_initialize_model(\n",
        "#         model_class, model_name, optimizer_class=torch.optim.SGD, lr=lr, momentum=momentum\n",
        "#     )\n",
        "\n",
        "#     for epoch in range(start_epoch, start_epoch + NUM_EPOCHS):\n",
        "#         print(f'\\nEpoch [{epoch + 1}/{start_epoch + NUM_EPOCHS}]')\n",
        "#         model.train()\n",
        "\n",
        "#         for inputs, targets in tqdm(train_loader):\n",
        "#             inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "#             optimizer.zero_grad()\n",
        "#             outputs = model(inputs)\n",
        "\n",
        "#             if task == 'multi-label, binary-class':\n",
        "#                 targets = targets.float()\n",
        "#                 loss = criterion(outputs, targets)\n",
        "#             else:\n",
        "#                 targets = targets.squeeze().long()\n",
        "#                 loss = criterion(outputs, targets)\n",
        "\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "\n",
        "#         torch.cuda.empty_cache()\n",
        "\n",
        "#         # Logging\n",
        "#         train_metrics = test('train', train_loader_at_eval, test_loader)\n",
        "#         val_metrics = test('test', train_loader_at_eval, test_loader)\n",
        "\n",
        "#         history[\"train_auc\"].append(train_metrics.AUC)\n",
        "#         history[\"train_acc\"].append(train_metrics.ACC)\n",
        "#         history[\"val_auc\"].append(val_metrics.AUC)\n",
        "#         history[\"val_acc\"].append(val_metrics.ACC)\n",
        "#         history[\"train_loss\"].append(loss.item())\n",
        "\n",
        "#         # Save best model\n",
        "#         if val_metrics.AUC > best_val_auc:\n",
        "#             best_val_auc = val_metrics.AUC\n",
        "#             print(\"📌 New best AUC — saving model\")\n",
        "#             torch.save({\n",
        "#                 'model_state_dict': model.state_dict(),\n",
        "#                 'optimizer_state_dict': optimizer.state_dict()\n",
        "#             }, f\"./history_record/{model_name}.pth\")\n",
        "\n",
        "#         pd.DataFrame(history).to_csv(f\"./history_record/{model_name}.csv\", index=False)\n",
        "\n",
        "#     print(\"✅ Training complete.\")\n",
        "#     return history\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4O4Am58DVvgr",
        "outputId": "899fe3ae-4e0a-45e7-d0c0-b3d53afb1c40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "initialize_weights...\n",
            "Loading existing model: MedViT_mri\n",
            "\n",
            "Epoch [3/4]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [01:52<00:00, 11.25s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train  auc: 0.430  acc:0.150\n",
            "test  auc: 0.463  acc:0.140\n",
            "\n",
            "Epoch [4/4]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [01:51<00:00, 11.12s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train  auc: 0.430  acc:0.150\n",
            "test  auc: 0.463  acc:0.140\n",
            "✅ Training complete.\n"
          ]
        }
      ],
      "source": [
        "# history = training_and_record(\n",
        "#     model_class=MedViT_small,\n",
        "#     model_name=\"MedViT_mri\",\n",
        "#     NUM_EPOCHS=2,\n",
        "#     lr=0.001,\n",
        "#     momentum=0.9,\n",
        "#     train_loader=xu.train_ds,\n",
        "#     train_loader_at_eval=xu.train_loader_at_eval,\n",
        "#     test_loader=xu.val_ds\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDGis148YeZV"
      },
      "source": [
        "**bold text**## MedVit3D\n",
        "```\n",
        "# This is formatted as code\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmBgSJ8_AN8B",
        "outputId": "6a829a75-0e81-48ee-a645-0158d7503c36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of channels :  1\n",
            "number of classes :  11\n"
          ]
        }
      ],
      "source": [
        "data_flag = 'organmnist3d'\n",
        "# [tissuemnist, pathmnist, chestmnist, dermamnist, octmnist,\n",
        "# pnemoniamnist, retinamnist, breastmnist, bloodmnist, tissuemnist, organamnist, organcmnist, organsmnist]\n",
        "download = True\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "BATCH_SIZE = 15\n",
        "lr = 0.005\n",
        "\n",
        "info = INFO[data_flag]\n",
        "task = info['task']\n",
        "n_channels = info['n_channels']\n",
        "n_classes = len(info['label'])\n",
        "\n",
        "DataClass = getattr(medmnist, info['python_class'])\n",
        "\n",
        "print(\"number of channels : \", n_channels)\n",
        "print(\"number of classes : \", n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RRqLeV7QIy1L"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "md2Z0wF-8RfK"
      },
      "outputs": [],
      "source": [
        "from torchvision.transforms.transforms import Resize\n",
        "# preprocessing\n",
        "transform = lambda x: torch.from_numpy(x).squeeze(1).float()\n",
        "train_dataset = DataClass(split='train', transform=transform, download=True)\n",
        "val_dataset = DataClass(split='val', transform=transform, download=True)\n",
        "test_dataset = DataClass(split='test', transform=transform, download=True)\n",
        "\n",
        "\n",
        "# pil_dataset = DataClass(split='train', download=download)\n",
        "\n",
        "# encapsulate data into dataloader form\n",
        "train_loader = data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "train_loader_at_eval = data.DataLoader(dataset=train_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n",
        "test_loader = data.DataLoader(dataset=test_dataset, batch_size=2*BATCH_SIZE, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0y9S9zC-zTS",
        "outputId": "f0e09c4f-f71e-4a7c-88c2-24814b4b0dd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "len(train_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVOgku87rL2F",
        "outputId": "85c41035-0da5-445e-efe2-3f91a29a580a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "n_classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "PFWoDxaC2BUo"
      },
      "outputs": [],
      "source": [
        "from MedVit3D import MedViT3D_small\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MedViT3D_small(num_classes = n_classes).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwZ2Cf5V-6Xi",
        "outputId": "8fba2acd-a8e0-4b4c-cd73-8e8bb53f18d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loss: 2.3220160007476807\n"
          ]
        }
      ],
      "source": [
        "# import torch.nn as nn\n",
        "# import torch.optim as optim\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# model.train()\n",
        "# for inputs, targets in train_loader:\n",
        "#     inputs = inputs.to(device)\n",
        "#     targets = targets.squeeze()  # Remove extra dimension\n",
        "#     if targets.ndim != 1:\n",
        "#         targets = targets.view(-1)  # Ensure shape is [B]\n",
        "#     targets = targets.long().to(device)\n",
        "\n",
        "#     optimizer.zero_grad()\n",
        "#     outputs = model(inputs)  # Shape: [B, num_classes]\n",
        "#     loss = criterion(outputs, targets)  # targets: [B]\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "\n",
        "#     print(\"Loss:\", loss.item())\n",
        "#     break  # Only run 1 batch for testing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmEg0ooyZiZ0",
        "outputId": "a867cae8-8c4c-4688-b95c-47ccc0daacd7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.1131\n"
          ]
        }
      ],
      "source": [
        "# model.eval()\n",
        "# all_preds = []\n",
        "# all_labels = []\n",
        "# from sklearn.metrics import accuracy_score\n",
        "\n",
        "# with torch.no_grad():\n",
        "#     for inputs, targets in test_loader:\n",
        "#         inputs = inputs.to(device)\n",
        "#         targets = targets.squeeze()\n",
        "#         if targets.ndim != 1:\n",
        "#             targets = targets.view(-1)\n",
        "#         targets = targets.long().to(device)\n",
        "\n",
        "#         outputs = model(inputs)  # logits\n",
        "#         preds = torch.argmax(outputs, dim=1)\n",
        "\n",
        "#         all_preds.extend(preds.cpu().numpy())\n",
        "#         all_labels.extend(targets.cpu().numpy())\n",
        "\n",
        "# # ✅ Calculate Accuracy\n",
        "# acc = accuracy_score(all_labels, all_preds)\n",
        "# print(f\"Test Accuracy: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "5womIG9paWU3",
        "outputId": "ab9197b6-0d39-476f-96a6-15c131eeb71e"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-414791072.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtotal_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Train AUC: {train_auc:.4f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-414791072.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, loader, device)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/MedVit3D.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [B, D, C, H, W] -> [B, C, D, H, W]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mltb1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mltb2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/MedVit3D.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mPatchEmbed3D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    718\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m             )\n\u001b[0;32m--> 720\u001b[0;31m         return F.conv3d(\n\u001b[0m\u001b[1;32m    721\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# ## train full batch\n",
        "# from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "# import numpy as np\n",
        "# import torch\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# def evaluate(model, loader, device):\n",
        "#     model.eval()\n",
        "#     total_loss = 0\n",
        "#     all_labels = []\n",
        "#     all_outputs = []\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for inputs, targets in loader:\n",
        "#             inputs = inputs.to(device)\n",
        "#             targets = targets.squeeze().long().to(device)\n",
        "\n",
        "#             outputs = model(inputs)\n",
        "#             loss = criterion(outputs, targets)\n",
        "#             total_loss += loss.item()\n",
        "\n",
        "#             all_outputs.append(outputs.softmax(dim=1).cpu().numpy())\n",
        "#             all_labels.append(targets.cpu().numpy())\n",
        "\n",
        "#     # Flatten\n",
        "#     all_preds = np.concatenate(all_outputs, axis=0)\n",
        "#     all_labels = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "#     # Metrics\n",
        "#     acc = accuracy_score(all_labels, all_preds.argmax(axis=1))\n",
        "#     try:\n",
        "#         auc = roc_auc_score(all_labels, all_preds, multi_class='ovr')\n",
        "#     except:\n",
        "#         auc = -1  # fallback if AUC fails (e.g., single class present)\n",
        "\n",
        "#     avg_loss = total_loss / len(loader)\n",
        "#     return avg_loss, acc, auc\n",
        "# model.train()\n",
        "# total_loss = 0\n",
        "\n",
        "# for inputs, targets in train_loader:\n",
        "#     inputs = inputs.to(device)\n",
        "#     targets = targets.squeeze().long().to(device)\n",
        "\n",
        "#     optimizer.zero_grad()\n",
        "#     outputs = model(inputs)\n",
        "#     loss = criterion(outputs, targets)\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "\n",
        "#     total_loss += loss.item()\n",
        "\n",
        "# train_loss = total_loss / len(train_loader)\n",
        "# val_loss, val_acc, val_auc = evaluate(model, test_loader, device)\n",
        "# _, train_acc, train_auc = evaluate(model, train_loader, device)\n",
        "\n",
        "# print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f} | Train AUC: {train_auc:.4f}\")\n",
        "# print(f\"Val Loss:   {val_loss:.4f} | Val Acc:   {val_acc:.4f} | Val AUC:   {val_auc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rTlH_sYlCPx"
      },
      "outputs": [],
      "source": [
        "## train multiple epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "BJRP5e30lCDW"
      },
      "outputs": [],
      "source": [
        "def load_or_initialize_model(model_class, model_name, optimizer_class, lr, momentum, n_classes):\n",
        "    model_dir = \"./history_record\"\n",
        "    os.makedirs(model_dir, exist_ok=True)\n",
        "\n",
        "    model_path = os.path.join(model_dir, f\"{model_name}.pth\")\n",
        "    history_path = os.path.join(model_dir, f\"{model_name}.csv\")\n",
        "\n",
        "    model = MedViT3D_small(num_classes = n_classes).to(device)\n",
        "    optimizer = optimizer_class(model.parameters(), lr=lr, momentum=momentum)\n",
        "    start_epoch = 0\n",
        "    best_val_auc = 0\n",
        "    history = {\n",
        "        \"train_auc\": [], \"train_acc\": [],\n",
        "        \"val_auc\": [], \"val_acc\": [],\n",
        "        \"train_loss\": []\n",
        "    }\n",
        "\n",
        "    if os.path.exists(model_path) and os.path.exists(history_path):\n",
        "        print(f\"Loading existing model: {model_name}\")\n",
        "        checkpoint = torch.load(model_path, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        history = pd.read_csv(history_path).to_dict(orient='list')\n",
        "        start_epoch = len(history[\"train_loss\"])\n",
        "        best_val_auc = max(history[\"val_auc\"]) if history[\"val_auc\"] else 0\n",
        "\n",
        "    return model, optimizer, history, start_epoch, best_val_auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9uRNjKrqcqPs"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "def training_and_record(model_class, model_name, NUM_EPOCHS, lr, momentum, train_loader, train_loader_at_eval, test_loader, n_classes):\n",
        "    model, optimizer, history, start_epoch, best_val_auc = load_or_initialize_model(\n",
        "        model_class, model_name, optimizer_class=torch.optim.SGD, lr=lr, momentum=momentum, n_classes= n_classes\n",
        "    )\n",
        "\n",
        "    for epoch in range(start_epoch, start_epoch + NUM_EPOCHS):\n",
        "        print(f'\\nEpoch [{epoch + 1}/{start_epoch + NUM_EPOCHS}]')\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for inputs, targets in tqdm(train_loader):\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.squeeze().long().to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            # print(\"Unique labels:\", targets.unique())\n",
        "            # print(\"Targets shape:\", targets.shape)\n",
        "            # print(\"Output shape:\", outputs.shape)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Logging\n",
        "        train_loss = total_loss / len(train_loader)\n",
        "        val_loss, val_acc, val_auc = evaluate(model, test_loader, device)\n",
        "        _, train_acc, train_auc = evaluate(model, train_loader, device)\n",
        "\n",
        "        history[\"train_auc\"].append(train_auc)\n",
        "        history[\"train_acc\"].append(train_acc)\n",
        "        history[\"val_auc\"].append(val_auc)\n",
        "        history[\"val_acc\"].append(val_acc)\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "\n",
        "        # Save best model\n",
        "        if val_auc > best_val_auc:\n",
        "            best_val_auc = val_auc\n",
        "            print(\"📌 New best AUC — saving model\")\n",
        "            torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict()\n",
        "            }, f\"./history_record/{model_name}.pth\")\n",
        "\n",
        "        pd.DataFrame(history).to_csv(f\"./history_record/{model_name}.csv\", index=False)\n",
        "\n",
        "    print(\"✅ Training complete.\")\n",
        "    return history, model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lr"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGDFXUQZJfPi",
        "outputId": "c8f76554-1c94-44f5-a7d3-c17f252ef0cb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.005"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6mm2Y5icqmB",
        "outputId": "3b394c73-08b7-49c5-9087-c09804a849be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [1/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65/65 [02:13<00:00,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 New best AUC — saving model\n",
            "\n",
            "Epoch [2/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65/65 [02:15<00:00,  2.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 New best AUC — saving model\n",
            "\n",
            "Epoch [3/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65/65 [02:18<00:00,  2.12s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 New best AUC — saving model\n",
            "\n",
            "Epoch [4/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65/65 [02:12<00:00,  2.03s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [5/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65/65 [02:20<00:00,  2.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 New best AUC — saving model\n",
            "\n",
            "Epoch [6/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65/65 [02:14<00:00,  2.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [7/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65/65 [02:13<00:00,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch [8/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65/65 [02:13<00:00,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 New best AUC — saving model\n",
            "\n",
            "Epoch [9/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65/65 [02:14<00:00,  2.07s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📌 New best AUC — saving model\n",
            "\n",
            "Epoch [10/10]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 65/65 [02:13<00:00,  2.06s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Training complete.\n"
          ]
        }
      ],
      "source": [
        "## Train môre epoch and recording.\n",
        "import os\n",
        "import pandas as pd\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
        "history, model = training_and_record(\n",
        "    model_class=MedViT3D_small,\n",
        "    model_name=\"MedViT3D_organmnist3d\",\n",
        "    NUM_EPOCHS=NUM_EPOCHS,\n",
        "    lr=lr,\n",
        "    momentum=0.9,\n",
        "    train_loader=train_loader,\n",
        "    train_loader_at_eval=train_loader_at_eval,\n",
        "    test_loader=test_loader,\n",
        "    n_classes = n_classes\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYjBAY7P1vTh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZ6juHEX2V2E"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYMNuK9o2a2B"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvVh56JV2fsY",
        "outputId": "652fa7d2-0781-4c25-fbd1-518815d563e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch [1/2]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 195/195 [01:44<00:00,  1.86it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Done first eopoch\n",
            "going to test function\n",
            "Done y_true,m and y_score\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RWBAzW43K8Q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89HqFIIi7ARz"
      },
      "outputs": [],
      "source": [
        "## Grad CAM for model explanation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QXuzYhhSEo8q",
        "outputId": "091e86f9-db26-4ac2-b4cb-61ce85117e85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchcam\n",
            "  Downloading torchcam-0.4.0-py3-none-any.whl.metadata (31 kB)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchcam) (2.6.0+cu124)\n",
            "Collecting numpy<2.0.0,>=1.17.2 (from torchcam)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Pillow!=9.2.0,>=8.4.0 in /usr/local/lib/python3.11/dist-packages (from torchcam) (11.3.0)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.7.0 in /usr/local/lib/python3.11/dist-packages (from torchcam) (3.10.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (25.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.0->torchcam) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch<3.0.0,>=2.0.0->torchcam)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch<3.0.0,>=2.0.0->torchcam)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch<3.0.0,>=2.0.0->torchcam)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch<3.0.0,>=2.0.0->torchcam)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch<3.0.0,>=2.0.0->torchcam)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch<3.0.0,>=2.0.0->torchcam)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch<3.0.0,>=2.0.0->torchcam)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch<3.0.0,>=2.0.0->torchcam)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch<3.0.0,>=2.0.0->torchcam)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch<3.0.0,>=2.0.0->torchcam)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch<3.0.0,>=2.0.0->torchcam) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch<3.0.0,>=2.0.0->torchcam) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.7.0->torchcam) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch<3.0.0,>=2.0.0->torchcam) (3.0.2)\n",
            "Downloading torchcam-0.4.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m117.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m83.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchcam\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 torchcam-0.4.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "e45e90151441496fa9e2833aa76c037c",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting captum\n",
            "  Downloading captum-0.8.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from captum) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.11/dist-packages (from captum) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from captum) (25.0)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.11/dist-packages (from captum) (2.6.0+cu124)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from captum) (4.67.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10->captum) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->captum) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.10->captum) (3.0.2)\n",
            "Downloading captum-0.8.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: captum\n",
            "Successfully installed captum-0.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchcam\n",
        "# OR\n",
        "!pip install captum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfQ6I5mK8W1n"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kcpLxy6CGIQ"
      },
      "outputs": [],
      "source": [
        "from torchcam.methods import GradCAM\n",
        "from torchcam.utils import overlay_mask\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "\n",
        "cam_extractor = GradCAM(model, target_layer=\"ltb1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sin1HsuxFsWI"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "\n",
        "# Select a sample from test loader\n",
        "inputs, targets = next(iter(test_loader))\n",
        "inputs = inputs.to(device)\n",
        "targets = targets.squeeze().long().to(device)\n",
        "\n",
        "# Forward pass and CAM extraction\n",
        "with torch.no_grad():\n",
        "    output = model(inputs)\n",
        "    pred_class = output.argmax(dim=1)\n",
        "\n",
        "# Extract CAM for the first image\n",
        "cam = cam_extractor(pred_class[0].item(), output)  # Automatically registers and removes hooks\n",
        "\n",
        "# Process image and heatmap\n",
        "input_image = inputs[0].cpu().squeeze().numpy()  # [D, H, W]\n",
        "slice_idx = input_image.shape[0] // 2\n",
        "slice_img = input_image[slice_idx]\n",
        "slice_cam = cam[0][slice_idx]\n",
        "\n",
        "# Normalize and overlay\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from torchcam.utils import overlay_mask\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "norm_slice = (slice_img - slice_img.min()) / (slice_img.max() - slice_img.min())\n",
        "norm_cam = (slice_cam - slice_cam.min()) / (slice_cam.max() - slice_cam.min())\n",
        "\n",
        "overlay = overlay_mask(to_pil_image(norm_slice), to_pil_image(norm_cam), alpha=0.6)\n",
        "\n",
        "plt.imshow(overlay)\n",
        "plt.title(f\"Grad-CAM (Pred: {pred_class[0].item()}, True: {targets[0].item()})\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "_zEnJK3uDlxo",
        "outputId": "4764d851-99be-4127-b733-7d2b110f1e65"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAH4CAYAAAB9k1VdAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAANbhJREFUeJzt3Wd8lGXe/v9j0hsJXarSazQUkV1pFhARFX4rRVHaclvxVtyliCC9SHEVu64IKFVAEbGAJQioi6ggKCji0kSUoKGFkHr+H/hP1pCQDH6znuu9n/frxQNmrmOubyaTOXJdM5Mz4JxzAgAAv7kQ3wMAAPDfihIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIuRQMGDFCtWrV8j/Ffxed9npubq8TERE2ePPmsckXNHAgENG7cuNIbzpPrr79evXr1Cnr7uXPnKhAI/BsnKj3jxo373cwaCAQ0d+5c32MgCP8nSnj37t2688471aBBA8XExCgmJkZNmjTR4MGDtXXrVt/jndGxY8c0fvx4JSUlKS4uTtHR0UpMTNSIESP03XffFZnp1auXAoGARowYUeT1a9euVSAQUCAQ0Pz584vcpk2bNgoEAkpMTAx61lWrVunKK69UhQoVFBUVpQYNGmjo0KH68ccfg76N/2sWLVqk/fv368477/Q9yq/y0Ucf6Y477lDLli0VHh4edMFs2LAh/zF2+PDhAteNGDFCy5cv12effVbq8+btMxAIKCQkRNWqVdMVV1yhtWvXlvq+/h3WrFmjQYMGKTExUaGhocX+8pibm6vp06erdu3aioqK0gUXXKBFixb922Zbv369evXqperVqysiIkIJCQlq3bq1JkyYoB9++EFSwfu/uH9n8/1YsmSJbrrpJtWvX1+BQECXXHLJGbfNyMjQiBEjVK1aNUVHR6t169Z66623jF+5f2G+B7BatWqVevfurbCwMN14441KSkpSSEiIvvzyS7300kt68skntXv3bp133nm+Ry3gn//8pzp27Kh9+/apZ8+euuWWWxQREaGtW7dq9uzZevnll7Vz584CmWPHjunVV19VrVq1tGjRIj3wwANnfOKMiorSwoULddNNNxW4fM+ePfrggw8UFRUV9KxDhw7Vgw8+qKSkJI0YMULly5fXp59+qscee0yLFy/WO++8o4YNG579nfA7N2PGDF1//fVKSEgw31Z6errCwn7bH8fXX39dzz77rC644ALVqVOn0OOtKLm5ufrf//1fxcbGKi0trdD1zZs314UXXqgHH3xQzz//fKnP3KlTJ/Xr10/OOe3evVtPPPGELrvsMr322mvq0qVLqe+vNC1cuFBLlixRixYtVK1atWK3HTVqlB544AHdfPPNatWqlV555RX16dNHgUBA119/fanONWbMGE2cOFF16tTRgAEDVKdOHZ06dUqffPKJHnzwQc2bN0/ffPONXnjhhQK5559/Xm+99Vahyxs3bhz0vp988kl98sknatWqVYm/0A8YMEDLli3TkCFDVL9+fc2dO1dXXXWVkpOT1bZt2+C/4P807nds165dLjY21jVu3Nh99913ha7Pyspys2bNcvv27Sv2dk6cOFEq8/Tv39+dd955JW6XlZXlkpKSXExMjFu/fn2h648ePeruu+++Qpc/99xzLjw83L377rtOklu7dm2hbZKTk50k96c//cmFhYW5lJSUAtdPnjzZnXPOOa5t27auadOmJc66cOFCJ8n17t3bZWdnF7hu48aNLiYmxp1//vkuKyurxNsqTXnfs2Dv89L26aefOknu7bffPuusr5lP9/3337uTJ08655wbPHiwC+bp4Mknn3QVKlRwd999t5NU6PHlnHMzZ850sbGx7vjx4yXe3pw5c4Lar3POSXKDBw8ucNnWrVudJHfFFVecMZeenu5ycnKC2kdxxo4dG/SsRTlw4IDLzMx0zjnXtWvXMz4Gvv32WxceHl7ga83NzXXt2rVzNWrUKPRzWBRJbs6cOSVut3jxYifJ9erVy2VkZBS6/siRI27s2LFFZoN9zBRn3759+d+bpk2bug4dOhS53caNG50kN2PGjPzL0tPTXd26dd0f//hH0wy+/a5PR0+fPl1paWmaM2eOqlatWuj6sLAw3XXXXapZs2b+ZQMGDFBcXJy++eYbXXXVVSpTpoxuvPFGST+fkunZs6fOPfdcRUZGqmbNmrrnnnuUnp5e6LZXrFihxMRERUVFKTExUS+//HLQc+edrhs1alSRv8HFx8cX+TrjggUL1KlTJ1166aVq3LixFixYcMZ9dOvWTZGRkVq6dGmByxcuXKhevXopNDQ0qFnHjx+vcuXK6ZlnnimUueiiizRixAht27ZNy5YtkyTdeeediouL08mTJwvd1g033KAqVaooJycn/7I33nhD7dq1U2xsrMqUKaOuXbvqiy++KJAr7ntWlJkzZ+riiy9WhQoVFB0drZYtW+bPl6dDhw5KSkoqMt+wYUN17ty52PtlxYoVioiIUPv27Qtcfvz4cQ0ZMkS1atVSZGSkKleurE6dOunTTz8t9vaKek34wIEDGjRokKpVq6bIyEjVrl1bt99+uzIzM/O3OXLkiIYMGaKaNWsqMjJS9erV07Rp05Sbm1vs/iTpnHPOUXR0dInb5fnpp580evRoTZgwQWXLlj3jdp06dVJaWtpvcqrw/PPPV8WKFbV7925J/3o5ZvHixRo9erSqV6+umJgYHTt2TJK0ceNGXXnllUpISFBMTIw6dOig999/v9DtbtiwQa1atVJUVJTq1q2rp59+usj9Hz58WF9++WWRj/fTVatWTeHh4SVu98orrygrK0t33HFH/mWBQEC33367vv32W3344Ycl3kawxowZo4oVK2r27NmKiIgodH1CQsJZv1fh4MGD+vLLL5WVlVXitjVr1lRISMk1tGzZMoWGhuqWW27JvywqKkqDBg3Shx9+qP3795/VjP9JftclvGrVKtWrV0+tW7c+q1x2drY6d+6sypUra+bMmbruuuskSUuXLtXJkyd1++2369FHH1Xnzp316KOPql+/fgXya9as0XXXXadAIKCpU6eqe/fuGjhwoD7++OOg9r9y5UpJUt++fYOe+bvvvlNycrJuuOEGST8X2rJlywo8If9STEyMunXrVuB1pM8++0xffPGF+vTpE9Q+v/76a3311Vfq1q2b4uPji9wm775ZtWqVJKl3795KS0vTa6+9VmC7kydP6tVXX1WPHj3yy/yFF15Q165dFRcXp2nTpun+++/X9u3b1bZtW+3Zs6dA/kzfs6LMmjVLzZs314QJEzRlyhSFhYWpZ8+eBWbq27evtm7dqs8//7xAdtOmTdq5c2eh0/in++CDD5SYmFjoSfW2227Tk08+qeuuu05PPPGEhg4dqujoaO3YsaPY2zvdd999p4suukiLFy9W79699cgjj6hv375677338p/wT548qQ4dOmj+/Pnq16+fHnnkEbVp00YjR47UX/7yl7PaXzDuv/9+ValSRbfeemux2zVp0kTR0dFFlltpS01NVWpqqipUqFDg8okTJ+q1117T0KFDNWXKFEVEROjdd99V+/btdezYMY0dO1ZTpkzRkSNHdNlll+mjjz7Kz27btk1XXHGFDh06pHHjxmngwIEaO3Zskb9oP/bYY2rcuHGBvNXmzZsVGxtb6LTuRRddlH99adi5c6d27typ7t27Ky4urlRuU5JGjhypxo0b68CBA6V2m5s3b1aDBg0KPQ/l3SdbtmwptX395nwfiv9aR48edZJc9+7dC12XmprqUlJS8v/lnXJz7udTgZLcvffeWyj3y+3yTJ061QUCAbd37978y5o1a+aqVq3qjhw5kn/ZmjVrnKSgTjM2b97cJSQklLjdL82cOdNFR0e7Y8eOOeec27lzp5PkXn755QLb5Z2OXrp0qVu1apULBAL5p+OHDRvm6tSp45xzrkOHDiWejl6xYoWT5B566KFit4uPj3ctWrRwzv182qx69eruuuuuK7DNiy++6CS5devWOeecO378uCtbtqy7+eabC2z3/fffu4SEhAKXF/c9K+rU7unfx8zMTJeYmOguu+yy/MuOHDnioqKi3IgRIwpse9ddd7nY2NgSX6KoUaNGoa/ROecSEhIKnTINZmZJBU779evXz4WEhLhNmzYVyufm5jrnnJs4caKLjY11O3fuLHD9vffe60JDQ0t8GeaXSjq1+Nlnn7nQ0FC3evVq59y/Ts0WdTraOecaNGjgunTpUuJ+z/Z09KBBg1xKSoo7dOiQ27hxo7v88sudJPfggw865/71+K9Tp06Bx0Fubq6rX7++69y5c/7959zPj5XatWu7Tp065V/WvXt3FxUVVeBnfvv27S40NLTQrHn3Q3JyclBfQ57iTkd37do1/+f0l9LS0s74c3A6BXE6+pVXXnGS3MMPP1zg8tzc3ALPnykpKUW+3HSmx0zez+vu3btLnPOXijsd3bRp0wI/v3m++OILJ8k99dRTZ7Wv/yS/2yPhvNNLRf0Gd8kll6hSpUr5/x5//PFC29x+++2FLvvlqbm0tDQdPnxYF198sZxz+b99Hjx4UFu2bFH//v0LvCGnU6dOatKkSdCzlylTJqht8yxYsEBdu3bNz9WvX18tW7Ys9pT0FVdcofLly2vx4sVyzmnx4sX5R9LBOH78uCSVOGuZMmXyvx+BQEA9e/bU66+/rhMnTuRvs2TJElWvXj3/9Ptbb72lI0eO6IYbbtDhw4fz/4WGhqp169ZKTk4utJ+ivmdF+eX3MTU1VUePHlW7du0KnBJOSEjIP1PgnJMk5eTkaMmSJerevbtiY2OL3cePP/6ocuXKFbq8bNmy2rhx4xnf3R6M3NxcrVixQtdcc40uvPDCQtfnvRlv6dKlateuncqVK1fgPuzYsaNycnK0bt26Xz3D6e666y516dJFV1xxRVDb581U2mbPnq1KlSqpcuXKat26td5//3395S9/0ZAhQwps179//wKPgy1btujrr79Wnz599OOPP+bfV2lpabr88su1bt065ebmKicnR6tXr1b37t117rnn5ucbN25c5EsU48aNk3Ou2Hf1nq309HRFRkYWujzvzZRFvTz2a5zpOfTo0aMFnj8rVap0Vkeac+fOlXOuVD86+FvdJz78bt8dnVcMv3yiz/P000/r+PHj+uGHH4o8rRgWFqYaNWoUunzfvn0aM2aMVq5cqdTU1ALXHT16VJK0d+9eST+X4OkaNmxY4Ik+JSWlwOufcXFxiouLU3x8vP75z38G82VKknbs2KHNmzerX79+2rVrV/7ll1xyiR5//HEdO3asyNPF4eHh6tmzpxYuXKiLLrpI+/fvD/pUtPSv+zivjM/k+PHjqly5cv7/e/furYcfflgrV65Unz59dOLECb3++uu69dZb8wvk66+/liRddtllRd7m6V/Pmb5nRVm1apUmTZqkLVu2KCMjI//y099J3q9fPy1ZskTr169X+/bt9fbbb+uHH34I+mWCvPL+penTp6t///6qWbOmWrZsqauuukr9+vVTnTp1grpN6efHzbFjx0r8CNnXX3+trVu3qlKlSkVef+jQoaD3WZwlS5bogw8+KHTqvjjOuX/LZ2q7deumO++8U4FAQGXKlFHTpk2L/IWpdu3aBf6f93jr37//GW/76NGjysjIUHp6+hl/vl9//XXjV1Cy6OjoAo/bPKdOncq/vjSc6Tk0Li4u//X8NWvWaMaMGaWyP4vf6j7x4XdbwgkJCapatWqRTwx5rxGf/rpinsjIyEJvBsjJyVGnTp30008/acSIEWrUqJFiY2N14MABDRgwIKg3upyuVatW+aUtSWPHjtW4cePUqFEjbd68Wfv37y/wprEzyfu87z333KN77rmn0PXLly/XwIEDi8z26dNHTz31lMaNG6ekpKSgj9alf33UoLjPWu/du1fHjh0rcLt/+MMfVKtWLb344ovq06ePXn31VaWnp6t379752+Tdny+88IKqVKlS6HZP/7hOUd+zoqxfv17XXnut2rdvryeeeEJVq1ZVeHi45syZo4ULFxbYtnPnzjrnnHM0f/58tW/fXvPnz1eVKlXUsWPHEvdToUKFQr+oST9/jrtdu3Z6+eWX85/Apk2bppdeeqnUP0KTm5urTp06afjw4UVe36BBg1LZz7Bhw9SzZ09FRETk/0wdOXJEkrR//35lZmYW+shNampqkUVmVaNGjaC+P6c/Kec93mbMmKFmzZoVmYmLiyvyif63VrVqVSUnJxf6RebgwYOSVOLHm4LVqFEjSSr0HBoWFpZ/H3/77belsi+rqlWrFvkac2nfJz78bktYkrp27apnn31WH330Uf4L9L/Wtm3btHPnTs2bN6/AG7FOf4dn3ueN836z/qWvvvqqwP8XLFhQ4DRJ3tHQNddco0WLFmn+/PkaOXJksXM557Rw4UJdeumlBd4tmWfixIlasGDBGUu4bdu2Ovfcc7V27VpNmzat2H2drkGDBmrQoIFWrFihWbNmFXlaOu+zoFdffXWBy3v16qVZs2bp2LFjWrJkiWrVqqU//OEP+dfXrVtXklS5cuWgnlSDtXz5ckVFRWn16tUFTl/NmTOn0LahoaHq06eP5s6dq2nTpmnFihW6+eabg3rneKNGjfLfkXu6qlWr6o477tAdd9yhQ4cOqUWLFpo8eXLQJVypUiXFx8eXeORZt25dnThxolTvv6Ls379fCxcuLPRLjCS1aNFCSUlJBU5XZmdna//+/br22mv/rXOdjbzHW3x8fLH3V6VKlRQdHR3Uz/e/S7NmzfTss89qx44dBX653bhxY/71paFhw4aqX7++VqxYoYcffrjEl2B8atasmZKTkwud9Svt+8SH3+1rwpI0fPhwxcTE6M9//nP+X3X5paJOF55J3hPvLzPOOc2aNavAdlWrVlWzZs00b968/FPU0s9lvX379gLbtmnTRh07dsz/l1fCPXr00Pnnn6/JkycX+XGD48ePa9SoUZKk999/X3v27NHAgQPVo0ePQv969+6t5OTkM74GGQgE9Mgjj2js2LFn9W7sPGPGjFFqaqpuu+22AqfWJemTTz7RtGnTlJiYWOjdyr1791ZGRobmzZunN998s9CfMuzcubPi4+M1ZcqUIj/KkJKSctazSj9/HwOBQIFZ9+zZoxUrVhS5fd++fZWamqpbb71VJ06cKPFd0Xn++Mc/6vPPPy9w5JSTk1PgMSH9/EtGtWrVzuoIKyQkRN27d9err75a5Dvu8x6jvXr10ocffqjVq1cX2ubIkSPKzs4Oep/Fefnllwv9yzur8fzzz+uhhx4qsP327dt16tQpXXzxxaWy/9LQsmVL1a1bVzNnzizyJay8x1toaKg6d+6sFStWaN++ffnX79ixo8j7+Ww+ohSsbt26KTw8XE888UT+Zc45PfXUU6pevXqp3q/jxo3T4cOHdfPNNxf5c3g2z6F5zuYjSsHq0aOHcnJy9Mwzz+RflpGRoTlz5qh169ZBnVH8T/W7PhKuX7++Fi5cqBtuuEENGzbM/4tZ7v//azoLFy5USEhIUK8lNmrUSHXr1tXQoUN14MABxcfHa/ny5UWecpw6daq6du2qtm3b6s9//rN++uknPfroo2ratGmRP+CnCw8P10svvaSOHTuqffv26tWrl9q0aaPw8HB98cUXWrhwocqVK6fJkydrwYIFCg0NVdeuXYu8rWuvvVajRo3S4sWLz/ixlG7duqlbt24lzlWUG2+8UZs2bdKsWbO0fft23XjjjSpXrpw+/fRTPffcc6pQoYKWLVtW6KM6LVq0UL169TRq1ChlZGQUOBUt/XxE8uSTT6pv375q0aKFrr/+elWqVEn79u3Ta6+9pjZt2uixxx4763m7du2qv/3tb7ryyivVp08fHTp0SI8//rjq1atX5Gn15s2bKzExUUuXLlXjxo3VokWLoPbTrVs3TZw4Ue+9917+m5WOHz+uGjVqqEePHvl/ivTtt9/Wpk2b9OCDD57V1zFlyhStWbNGHTp00C233KLGjRvr4MGDWrp0qTZs2KCyZctq2LBhWrlypa6++moNGDBALVu2VFpaWv7ntvfs2aOKFSuecR979+7N/2tHeWU/adIkST+f8cn7pa179+6FsnlHvl26dCm0j7feeksxMTHq1KnTWX3N/04hISF69tln1aVLFzVt2lQDBw5U9erVdeDAASUnJys+Pl6vvvqqpJ8/G//mm2+qXbt2uuOOO5SdnZ3/8336Y+ixxx7T+PHjlZycXOKbs7Zu3Zr/8cRdu3bp6NGj+fd3UlKSrrnmGkk/n3IfMmSIZsyYoaysLLVq1UorVqzQ+vXr858PSkufPn30+eefa+rUqfroo490/fXXq3bt2kpLS9Pnn3+uRYsWqUyZMkW+CfFMRo4cqXnz5mn37t0lvjlr3bp1+W8gTElJUVpaWv590r59+/zP4bdu3Vo9e/bUyJEjdejQIdWrV0/z5s3Tnj17NHv27F/3xf+n+O3fkF36du3a5W6//XZXr149FxUV5aKjo12jRo3cbbfd5rZs2VJg2/79+7vY2Ngib2f79u2uY8eOLi4uzlWsWNHdfPPN7rPPPivy7f7Lly93jRs3dpGRka5JkybupZdeOuu/hJSamurGjBnjzj//fBcTE+OioqJcYmKiGzlypDt48KDLzMx0FSpUcO3atSv2dmrXru2aN2/unCv4EaXiBPMRpV9asWKF69SpkytXrpyLjIx09erVc3/961/P+BEV55wbNWqUk+Tq1at3xm2Sk5Nd586dXUJCgouKinJ169Z1AwYMcB9//HH+NsV9z4q6z2fPnu3q16/vIiMjXaNGjdycOXOK/WtH06dPd5LclClTirkHCrvgggvcoEGD8v+fkZHhhg0b5pKSklyZMmVcbGysS0pKck888USJM+u0jyg559zevXtdv379XKVKlVxkZKSrU6eOGzx4cIG/bHT8+HE3cuRIV69ePRcREeEqVqzoLr74Yjdz5sz8v850JnmPlaL+nemjInmK+4hS69at3U033VRsPo/1L2adrqTH/+bNm92f/vQnV6FCBRcZGenOO+8816tXL/fOO+8U2O69995zLVu2dBEREa5OnTruqaeeKvIxdDYfUcr7Wov6179//wLb5uTkuClTprjzzjvPRUREuKZNm7r58+eXuI88RT1nFWft2rWuR48ermrVqi48PNzFx8e7Cy+80I0dO9YdPHiwyExpfEQp7/4r6t/pPw/p6elu6NChrkqVKi4yMtK1atXKvfnmm0F/jf+pAs79ivMNwP8hs2bN0j333KM9e/YU+FhKSV544QUNHjxY+/btK/YvSP032bJli1q0aKFPP/00qNfp5s6dq4EDB/6q0544s0AgoDlz5mjAgAG+R0EJftevCQNWzjnNnj1bHTp0OKsCln4+VX/uuecW+Tn0/1YPPPCAevTo8bt+owzwW/pdvyYM/FppaWlauXKlkpOTtW3bNr3yyitnfRshISFn9dnZ/waLFy/2PQLwu0IJ479SSkqK+vTpo7Jly+q+++77j/o4DYD/HrwmDACAJ7wmDACAJ5QwAACeUMIAAHgS9BuzOo3YYNrRDz/YV3TJ2vhWyRsVI3JYLfMMNTK/NOU/+7CteYZ7N0wx5WcNv9k8Q1etMuWXvHf2f0LzdBN+nGi7gcLrRpy1UxsKL692Nh66ZJx5hmEXjzXl85aDs7AuW7h/bKZ5huVjpprybcNfNc9Q1HJ7Z6NlzibzDBWXxpjyjXsFv8jLmaTs+nV/djZP8sKi/y772cgcW8uUDwTsx6gzbym5NzkSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADwJej3hnJxc046ys7NMeUlyzpnyIaH23zli42JN+UAgYJ4h/dQpUz6yFNaPzU2zPR5KY63OMmXKmPKZkfY1bNNzbfdDenq6eYbwiHBT/sSJE+YZKlaqaMpnV7Hdj5L9OSoyLsI8g/XnOzzc9r2UpLS0k6Z8RIT9foiMtN1Gaczw/U+ppnzZsmXNMwSDI2EAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPwoLdcOAPA207Cg96V2f03PBrTPltY22LwEvSnX9dacp/vN6+iPu399cy5U9N+tw8QyD3B1N+woCJ5hmGbB9lu4H3nXmGEblTTXnrIvCSlJmZacofmWFfQH3WpbbvxX0h95tnyP3YdkzxzvvNzDNIu0zp9ZG3mCcYXv5R2wytWppnWLS/lSm/MyPZPMPw+GdtN5BzxDxDMDgSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADwJOOeCWlS1/fwpph2lnzplyktS56iNpvzCMXXNM2RmNzflJ3W13Y+StDWpqilfK+KweYbt96fZZphS3TxDZGSkKX/guP130Lnv9TTl71g/wzzD3+8cbsoPrLTMPMNPqcdM+df+1sQ8w/AJH5nye7MqmmdYOvlKU77LpO3mGd6Z0MyUbz7Rtm67JNWNe8yUb/zGavMMw5bZ1kUOshqLdejQ0hK34UgYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAk4ALcuXiKlXuNO0oMzPTlJek8uVt+aTR9t85GgR2mfIvft7fPMO9iRNM+Sn/GGWeIfL8vaZ89t9SzDNYJdxfy3wb369LMOX/553J5hmeuPUeUz5kXYR5hqyNb5ny/ctvNc9gfY5Z0Wm0eYbQrDBTPsdlm2dIOM/2mGzypS0vSYMjp5ryB65NNc+Qctj2HBMSsPfF3XccKHk/5r0AAIBfhRIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE+CXvxy0sgVph2FhNj7Pmx2uCk/K/MG8wzvv5tkysd9XPL6kiVJSLXdD0OTJ5pnCN150pSfnHG5eYaku2zrhe5Y19o8w9Suj5ryp9ra1p+VJH1vi9/7hW3tV0n69oFapnxcbrR5htzcSFM+/Fn7usrXDnralH9xov3nYtqgN0z5WUeGmWeYcqltnexbvrrVPMOeirVN+VyXa54hGBwJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeBL0iuIrKw807SgkxN732cOyTfl+x+aYZ4j4OseUfyBrsHmGDZ1amfIxbb41z/Bajm3x8XY5m80zBAIJpnxYWKh5hqnr/2rKZ9Y7aZ5hyqf3224gyv6z+eLE80z5YbW+MM/gnDPlsw+9bZ5Bzvb8cNXkHeYR/jb/L6Z8dttK5hnObbfHlI97M848Q25urvk2fgscCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeBFyQi3D2eKiTaUcJCWVNeUl6e30XUz7t1dfMMzx0/Wem/LvNLjDPEBdnW2sz5qR9PeFTk/aY8plTLjPPUK5cOVN+zaEq5hnap68w5RPf3WeeYeJG2305ovkb5hl0dYwpvj+0lnmEOauvN+UzVn9jniEm5jtTPhCob56hYcPGpnxGVnnzDG2nbDXlPxnfzDzDN9+8ZMpnZ9vWr5ekPXueLHEbjoQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPCEEgYAwBNKGAAATyhhAAA8CTjnXDAb1rj276YdZWZmmfKSdEuf5aZ8pRNfmmf4JLSVKX/R+g3mGbZd0dGUX7XUtgi8JP2/rZNN+a3n3WaeISwszJRvccMq8wwvvtbflM+IzjDPEP3hj6Z8kE8BxRpZ6QlTPvzuePMM1sfDfavuNs8Quv6QKT+u9zPmGRZtXWjK59yxwzxD+gPHTPnY2GbmGQ7UTzHlS6Ozvpndt8RtOBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPAl6Ac6KJyqadpSSctiUl6Q3wq8z5feuyDHPMKn3Q6b85PeuNM/QpZNtncvSWD/2nBlJpnzlF5ubZzh82PaYavLBbvMMf7riaVO+6SffmmeY1GGiKX9Vc9tawJI0/RHb47pv2A/mGT44VNaUv/GyReYZEmP2mvJxH5Q1z9Bk3FpTPvmvueYZXGQTU370hfeaZxhX1/aYtD9LBocjYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8CLsgV3icv727aUWhIqCkvSX//vqUpP3iyffHyqX8cacrPP3e+eYY7V3Y35UeE2O+Hh+6925RvcOxy8wy55+8w5b/8u33Z7iM6YsoHkg+aZ5hY7jlTftVfbIufS9K2h9qZ8lnHN5hnCA+3fT/Dw88xz5AT3tiUr3h1RfMM4Z+EmfIp+1eZZ0i4v5Yp/9M/KplnuHfNKFM+PCLcPEO/bV+XuA1HwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnQS88efLkSdOOMjMzTXlJCltX25RPndrIPEPUmkhTfk/TQ+YZhl/wrCn/eVoV8ww9ot425atHzjXP8PBztvVCp5471TzD7DY3m/I7ouuZZxi1qq0pH2e/G5SVtcWUDw09zzzDqVO255j09FTzDJGR75ryoeurm2c4/NNPpvzxrGbmGeqnfWjKH1qVa55h6B+GmPLly1cwz9AviG04EgYAwBNKGAAATyhhAAA8oYQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPAkLNgNl4y/zLSjjIwMU16SIkeeMuWrpH9tniE8PMKU35VTzTyDy3amfFiYLS9JS9cPMOVvenu0eYaY+I9M+UeuusE8ww9jK5ny4RfZFy+ffs0/TPmcpBzzDNuja5vyX+XWNc9wKO4CU/6HXbavQZJC9oaa8plflzfPkHbOIdsMrdPNM+Tm2B7X91/yrnmGrPdXm/KhYUHXYzH6lrgFR8IAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ0EvmHjqqgqmHQUC9r7/y8Z7TfmwNNtan5IUWs72dYSEhZtnCA+33caL6/qbZ5iUO96Ur3JzTfMMzUM3mPJ3zL7dPENoy0xTPvONveYZxoX8jylf5w8/mmf4855XTfn5z11vnmFWzUdN+ZMnT5pniG4fZcpnN7av7Zx9QZYpHxFhWzNdkraEVjfll7W61DxDfMd4U740Hg/B/GRyJAwAgCeUMAAAnlDCAAB4QgkDAOAJJQwAgCeUMAAAnlDCAAB4QgkDAOAJJQwAgCeUMAAAnlDCAAB4QgkDAOAJJQwAgCeUMAAAnlDCAAB4QgkDAOBJWLAbnpNoW3w8K9O2+LkkhT5sW8x+ctat5hm6THrdlF+w+gbzDOXLVzDl69a3LbgtSTV22G5jW6tzzTPM+KCDKZ+9z/6YnJn2sCl/dPIp8wzZ49NMefemfSH5UedOMuWnxE8wz/DYncEsoX5mx48fN89Qr149W/7AIvMMb2dfbMqHBALmGSLCI035/RurmWeIiYk25bOysswzBIMjYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMCTgHPOBbPheZc+Z92VMS+V75diyh+b9JV5htGRyab8uM73m2eo+qFt/ddlkzaaZ8h8OcOU7xF5nXmGw8s+M+VvGL/WPMOaR2xfx/+7903zDDXnbTXlU7flmmeIaZVtyodcG2ufYZftOSZtcbp5hpUNHzflt1c+Yp7h7gtHmvJjPx5mniH+7U9M+ekdPzbPMP5D2/rS4eG29esladu2u0vchiNhAAA8oYQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPCEEgYAwBNKGAAAT8KC3TD9i6OmHZUtm2DKS9LhMV+b8qGhtc0zrBllW3w8dGyoeYYaLS405aed18Q8Q8qPO035yL22BdglKSyilim/eN1N5hlmXfaoKb82o5Z5hqe29Dflp7daZJ5B39h+nx+99V7zCJmL95ryFz3kzDOMfOMxU773movNM8xYc4kp/9C0p80zfL/qR1N++KdTzTNUvf+4KR8ZEW6eIRgcCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeBL2ecG7wmxbppyMnTXlJevDad0z5e3cMN8+waew+Uz402v57T/mycaZ86vit5hliRla35ddEmmdoX3auKV/72HrzDBMW9DXl72n7vnmGpV2uMuXfu7SNeYZNamm7gdFrzTM0Gl/elE955ALzDKvvP2LKh7ia5hn6vf2sKT990jXmGU6Wa2XK9xr+hnmGtz/qY8ofSU83z6CeJW/CkTAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnYcFu2GTCTtOOAoGAKS9JGTOzTPnonI3mGRLGNTXlU8ftM8+QnX2RKd9j9HbzDKuORZryo/842zzDrl27TPlZZYaYZ0j5sZwp/+WxLeYZJn041ZSf8MFY8wxRd+815dNvv9A8w7jUl0356Ktsz3GStOaur035sPNbmGeof2W4KR/6j4bmGe4c9XdTfkONe80zDCy/1JT/KfUn8wzSjSVuwZEwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4EnQ6wn3m2tbq7M0LB7Z25QfMvZ58wzjVzc35ae3f8Q8w4XZm0z5XTn29ULLhZ0y5beG/NE8w+Mf3GTKR/9hv3kGnTpgilce8415hB/S0035nLLZ5hn+5+uZpvyz3z9jnmFaswdM+QEthplnWFJloCmfO8G+3vjmic1M+XtTHjPPcN99F5vyA6Y8bp5Bx78wxSsGfptjVI6EAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPAk451wwG/Z5/GrTjipXrmzKS9LyDbaFosdvmmCeIWRwnCl/32t3m2e4ov9JUz7t2SbmGa6rMcSU/6RDO/MM5931iin/zNgh5hkO37/LlI8eXcc8Q/qkz035kJjLzTOEZX9vyj/T93XzDM9dO86U3/w/h80zpP2405QPP6e2eYbut/zdlA8LCZhnWJLW15S/JNr+eHh3ou25OhCw3w/7979Q4jYcCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeBL2ecI1+tjUqY2NjTXlJSk1NNeUjI6PMM0hB3V1n1PmS1aUwg22dy/entzZPkH57gik/OmG6eYbNR8ua8uuiu5tnuDBiuykfPfo98wxLooaZ8jGKMc/QferHpvznX1xvnuHU2gxT/rvvDphnCL08zJRv1+xl8wzvTEgy5cfXfM48g3Up3sxBtvuxNJw6dcp8G0MGf1fiNhwJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeBJwzgW1Sv3CAQ1NO0pNTTXlJSk0NNSUj4yMNM8w9v0/m/LR0dHmGU6cOGHKB/5axTzDmPIPmvLT1o81z9Cz3VxTPnPyPvMMS09dasqPGrjSPEPEpghT/rGjj5lnqFTmn6Z808HfmGcISfvelF/+4wXmGU6llzPlkyrvN8+QmPUPU77l/h/MM0x48VZTPjUpyjzD+Z1tj6nc3FzzDO8M+luJ23AkDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHgSFuyGI5sPNe3o1KlTprwkhTx8yJTv93SKeYaITXtN+Q732dYC/lnAlE7+oIF5gimrB5jyg0LHmWdI71DHlH+pzCjzDLfe+4gpvzOqjXmGj/8x2JR/arhtbWhJSkuzPa6/3fGteYadNeqb8umvVzTPEChnO67ZHdfMPEOTFh+Y8qNeGGCeYcykv5vyo4f3Ms9Q60rbeuGhEUHXowlHwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ5QwgAAeEIJAwDgCSUMAIAnlDAAAJ4EnHMumA3/WtG24HVMTIwpL0l/v3OYKX/OwRrmGX5attWUz2pT2TxDdHS0KZ8dn22eIepUlCmf1TTdPINLti26HX7FQfMMIZtrmfK19x4yz3DdlBRTvv6XG8wzLPzrV6Z88ti7zDPkvlPdlA/vFDDP0D7yNVN+9ZjzzTOMv+FZU35e3W7mGXZ9bvs6Ql9ZZ57h8jFppnx4eIR5hqf7LSpxG46EAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE8oYQAAPKGEAQDwhBIGAMATShgAAE+CXpA1d2J9045OhYWa8pI0Kme6KR/2RaZ5hlcmDTDlt62zrYErSS48qCWgz5z/0TyC2l+2wpR/Y3QT8wzTKi425Y/H2r8XqVvjTflNtZ4yz/Dt0SWm/APv/Nk8w4ncVaZ8H7fSPENSuG196A3hF9lnyNxoyrfu+b55htDXbOuNDyhr/17ofNttDE+/wTxCjfHzTfmQkFI4Ru0XxH7sewEAAL8GJQwAgCeUMAAAnlDCAAB4QgkDAOAJJQwAgCeUMAAAnlDCAAB4QgkDAOAJJQwAgCeUMAAAnlDCAAB4QgkDAOAJJQwAgCeUMAAAnlDCAAB4EvSq5omzbAtml4ajg7NM+ZiICPMM2+6LMeUnlp1oniFgXGw613Y3SpKGR//VlC8TcdQ8Q0ZGhikfEmJ/PCSfO8OUT6+bYp4hNTXVlA8NDTXPEHZ1J1P+negE8wxZ17xqyidOXmWeYdbFj5nyE6pNMs9QoUolUz41cNg8w/BTw035ydOnmGf4JreOKW99fgkWR8IAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ5QwAACeUMIAAHhCCQMA4AklDACAJ0GvJ1ymTBnTjo4eta8fGxFpW/81oax9zdKcnBxT3jlnniFgzQestyCFh4eb8hGlsLZzWlqaKR8p22Nakr788ktT3oXbHw/t2saa8tafbUk6kmL7+T52zP78kBZz0pSvWrWKeYbQ0KCfUosUFxdnnqFp06am/K6fdppnyMqyLVruZP+5sKpYseJvsh+OhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADyhhAEA8IQSBgDAE0oYAABPKGEAADwJuNJYZR4AAJw1joQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPCEEgYAwBNKGAAATyhhAAA8oYQBAPDk/wO47L1OeNuGPQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from torchcam.methods import GradCAM\n",
        "from torchcam.utils import overlay_mask\n",
        "\n",
        "# === Setup ===\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.eval().to(device)\n",
        "\n",
        "# === Choose target layer for GradCAM ===\n",
        "target_layer = 'ltb3.conv.0'  # Change if needed\n",
        "cam_extractor = GradCAM(model, target_layer=target_layer)\n",
        "\n",
        "# === Load 1 test sample ===\n",
        "inputs, targets = next(iter(test_loader))\n",
        "input_tensor = inputs[0].unsqueeze(0).to(device)  # [1, 1, D, H, W]\n",
        "true_label = targets[0].item()\n",
        "\n",
        "# === Forward pass & CAM extraction ===\n",
        "with torch.set_grad_enabled(True):\n",
        "    scores = model(input_tensor)\n",
        "    pred_class = scores.argmax(dim=1).item()\n",
        "    cams = cam_extractor(pred_class, scores)  # list of CAMs\n",
        "\n",
        "# === Get the CAM tensor ===\n",
        "cam = cams[0]  # Could be [1, D, H, W] or [D, H, W]\n",
        "if cam.dim() == 3:\n",
        "    cam = cam.unsqueeze(0).unsqueeze(0)  # → [1, 1, D, H, W]\n",
        "elif cam.dim() == 4:\n",
        "    cam = cam.unsqueeze(0)               # → [1, 1, D, H, W]\n",
        "# Else: already fine\n",
        "\n",
        "# === Interpolate CAM to input shape ===\n",
        "target_shape = input_tensor.shape[2:]  # [D, H, W]\n",
        "cam_upsampled = F.interpolate(cam, size=target_shape, mode=\"trilinear\", align_corners=False)\n",
        "\n",
        "cam_volume = cam_upsampled.squeeze().cpu()  # [D, H, W]\n",
        "\n",
        "# === Get input volume ===\n",
        "input_volume = input_tensor.squeeze().cpu()  # [D, H, W]\n",
        "\n",
        "# === Pick a middle slice ===\n",
        "slice_idx = input_volume.shape[0] // 2\n",
        "input_slice = input_volume[slice_idx]  # [H, W]\n",
        "cam_slice = cam_volume[slice_idx]      # [H, W]\n",
        "\n",
        "# === Normalize both slices ===\n",
        "input_norm = (input_slice - input_slice.min()) / (input_slice.max() - input_slice.min() + 1e-6)\n",
        "cam_norm = (cam_slice - cam_slice.min()) / (cam_slice.max() - cam_slice.min() + 1e-6)\n",
        "\n",
        "# === Convert to PIL images ===\n",
        "input_pil = to_pil_image(input_slice)\n",
        "cam_pil = to_pil_image(cam_slice)\n",
        "\n",
        "# Convert grayscale input to RGB for overlay\n",
        "input_pil = input_pil.convert(\"RGB\")\n",
        "\n",
        "# === Overlay CAM ===\n",
        "overlay = overlay_mask(input_pil, cam_pil, alpha=0.5)\n",
        "\n",
        "# === Plot ===\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(overlay)\n",
        "plt.title(f\"Grad-CAM Overlay (slice {slice_idx}) | Pred: {pred_class} | GT: {target_class}\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "id": "Y-eeHmrDD3N9",
        "outputId": "1edd4a61-d082-488f-c309-3d533d6c3e74"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from torchcam.methods import GradCAM\n",
        "from torchcam.utils import overlay_mask\n",
        "\n",
        "# === Prepare your model ===\n",
        "model.eval()\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Choose a target layer name from your model — ltb3 is good\n",
        "target_layer = \"ltb3\"\n",
        "\n",
        "# Initialize GradCAM\n",
        "cam_extractor = GradCAM(model, target_layer=target_layer)\n",
        "\n",
        "# === Pick one test sample ===\n",
        "inputs, targets = next(iter(test_loader))\n",
        "inputs = inputs.to(device)\n",
        "input_tensor = inputs[0].unsqueeze(0)  # [1, C, D, H, W]\n",
        "target_class = targets[0].item()\n",
        "\n",
        "# === Forward pass and CAM generation ===\n",
        "output = model(input_tensor)\n",
        "pred_class = output.argmax(dim=1).item()\n",
        "\n",
        "# Generate CAM\n",
        "cams = cam_extractor(pred_class, output)\n",
        "cam = cams[0]\n",
        "\n",
        "if cam.dim() == 3:\n",
        "    cam = cam.unsqueeze(0).unsqueeze(0)  # → [1, 1, D, H, W]\n",
        "elif cam.dim() == 4:\n",
        "    cam = cam.unsqueeze(0)               # → [1, 1, D, H, W]\n",
        "# === Interpolate CAM to match input size ===\n",
        "target_shape = input_tensor.shape[2:]  # [D, H, W]\n",
        "cam_upsampled = F.interpolate(cam, size=target_shape, mode=\"trilinear\", align_corners=False)\n",
        "\n",
        "cam_volume = cam_upsampled.squeeze().cpu()  # [D, H, W]\n",
        "\n",
        "\n",
        "# === Normalize input volume ===\n",
        "input_volume = input_tensor.squeeze().cpu()  # [D, H, W]\n",
        "input_volume = (input_volume - input_volume.min()) / (input_volume.max() - input_volume.min())\n",
        "\n",
        "# === Choose center slice ===\n",
        "slice_idx = input_volume.shape[0] // 2\n",
        "input_slice = input_volume[slice_idx]  # [H, W]\n",
        "cam_slice = cam_volume[slice_idx]      # [H, W]\n",
        "\n",
        "# Normalize CAM slice\n",
        "cam_slice = (cam_slice - cam_slice.min()) / (cam_slice.max() - cam_slice.min())\n",
        "\n",
        "# Convert grayscale input to RGB for overlay\n",
        "input_pil = input_pil.convert(\"RGB\")\n",
        "\n",
        "# === Overlay CAM ===\n",
        "overlay = overlay_mask(input_pil, cam_pil, alpha=0.5)\n",
        "\n",
        "# === Plot result ===\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.imshow(overlay)\n",
        "plt.title(f\"Grad-CAM (target: {target_class}, pred: {pred_class})\")\n",
        "plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OAxSMlFfBlU5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}